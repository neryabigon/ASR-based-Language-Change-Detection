(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ python3 training_script.py 
2023-04-03 11:38:47.295555: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-03 11:38:47.507273: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-03 11:38:47.528607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-04-03 11:38:47.528633: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-04-03 11:38:48.296599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-04-03 11:38:48.296789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-04-03 11:38:48.296796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets complete. -----------------
----------------- Loading Datasets complete. -----------------


----------------- Extracting all characters... -----------------
Parameter 'function'=<function extract_all_chars at 0x7faa0d5cd310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 95/96 [13:07<00:08,  8.28s/ba]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 15/16 [02:01<00:08,  8.10s/ba]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'q': 0, 's': 1, 'y': 2, 'b': 3, 'v': 4, 'e': 5, 'z': 6, 'r': 7, 'u': 8, '?': 9, 'o': 10, '!': 11, 'n': 12, ' ': 13, 't': 14, 'i': 15, 'h': 16, 'j': 17, 'd': 18, 'w': 19, 'a': 20, 'g': 21, 'c': 22, 'f': 23, 'p': 24, 'm': 25, 'k': 26, 'l': 27, 'x': 28}
Vocab_len: 31
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/3047 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/3046 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   0%|                                                                                                                                    | 1/3047 [00:00<11:28,  4.42ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3046/3046 [08:27<00:00,  6.00ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [09:10<00:00,  5.54ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [09:13<00:00,  5.51ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [09:13<00:00,  5.50ex/s]
#0:   0%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0:   0%|â–Ž                                                                                                                                    | 1/500 [00:00<01:29,  5.60ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:36<00:00,  5.17ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:37<00:00,  5.13ex/s]
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:38<00:00,  5.09ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:38<00:00,  5.07ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:38<00:00,  4.52ex/s]
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [01:38<00:00,  5.64ex/s]
----------------- Preparing datasets complete. -----------------


----------------- Loading Metrics... -----------------
/home/or/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-/training_script.py:173: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.weight', 'quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'quantizer.codevectors', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 12187
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 7620
  Number of trainable parameters = 311260319
  0%|                                                                                                                                                | 0/7620 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 15.4857, 'learning_rate': 1.1999999999999999e-05, 'epoch': 0.01}                                                                                                     
{'loss': 16.0007, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.03}                                                                                                     
{'loss': 17.1016, 'learning_rate': 4.05e-05, 'epoch': 0.04}                                                                                                                   
{'loss': 17.7639, 'learning_rate': 5.399999999999999e-05, 'epoch': 0.05}                                                                                                      
{'loss': 13.92, 'learning_rate': 6.9e-05, 'epoch': 0.07}                                                                                                                      
{'loss': 6.0765, 'learning_rate': 8.4e-05, 'epoch': 0.08}                                                                                                                     
{'loss': 4.0002, 'learning_rate': 9.9e-05, 'epoch': 0.09}                                                                                                                     
{'loss': 3.3686, 'learning_rate': 0.00011399999999999999, 'epoch': 0.1}                                                                                                       
{'loss': 3.2015, 'learning_rate': 0.000129, 'epoch': 0.12}                                                                                                                    
{'loss': 2.9607, 'learning_rate': 0.00014399999999999998, 'epoch': 0.13}                                                                                                      
  1%|â–ˆâ–‹                                                                                                                                  | 100/7620 [04:51<4:07:49,  1.98s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.9126334190368652, 'eval_wer': 1.0, 'eval_cer': 0.9962046238292489, 'eval_runtime': 310.0735, 'eval_samples_per_second': 6.45, 'eval_steps_per_second': 0.806, 'epoch': 0.13}                                                                                                                                                                
{'loss': 2.9007, 'learning_rate': 0.000159, 'epoch': 0.14}                                                                                                                    
{'loss': 2.8553, 'learning_rate': 0.00017399999999999997, 'epoch': 0.16}                                                                                                      
{'loss': 2.8594, 'learning_rate': 0.00018899999999999999, 'epoch': 0.17}                                                                                                      
{'loss': 2.8367, 'learning_rate': 0.000204, 'epoch': 0.18}                                                                                                                    
{'loss': 2.8544, 'learning_rate': 0.00021899999999999998, 'epoch': 0.2}                                                                                                       
{'loss': 2.8671, 'learning_rate': 0.000234, 'epoch': 0.21}                                                                                                                    
{'loss': 2.8218, 'learning_rate': 0.000249, 'epoch': 0.22}                                                                                                                    
{'loss': 2.8337, 'learning_rate': 0.00026399999999999997, 'epoch': 0.24}                                                                                                      
{'loss': 2.8392, 'learning_rate': 0.000279, 'epoch': 0.25}                                                                                                                    
{'loss': 2.8662, 'learning_rate': 0.000294, 'epoch': 0.26}                                                                                                                    
  3%|â–ˆâ–ˆâ–ˆâ–                                                                                                                                | 200/7620 [15:05<5:46:51,  2.80s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.839130401611328, 'eval_wer': 1.0, 'eval_cer': 0.9962046238292489, 'eval_runtime': 388.8553, 'eval_samples_per_second': 5.143, 'eval_steps_per_second': 0.643, 'epoch': 0.26}                                                                                                                                                                
{'loss': 2.8338, 'learning_rate': 0.0002997574123989218, 'epoch': 0.28}                                                                                                       
{'loss': 2.8223, 'learning_rate': 0.0002993530997304582, 'epoch': 0.29}                                                                                                       
{'loss': 2.8283, 'learning_rate': 0.00029894878706199457, 'epoch': 0.3}                                                                                                       
{'loss': 2.8302, 'learning_rate': 0.000298544474393531, 'epoch': 0.31}                                                                                                        
{'loss': 2.8417, 'learning_rate': 0.0002981401617250673, 'epoch': 0.33}                                                                                                       
{'loss': 2.8591, 'learning_rate': 0.00029773584905660376, 'epoch': 0.34}                                                                                                      
{'loss': 2.8127, 'learning_rate': 0.00029733153638814014, 'epoch': 0.35}                                                                                                      
{'loss': 2.8213, 'learning_rate': 0.0002969272237196765, 'epoch': 0.37}                                                                                                       
{'loss': 2.8742, 'learning_rate': 0.0002965229110512129, 'epoch': 0.38}                                                                                                       
{'loss': 2.8455, 'learning_rate': 0.00029611859838274933, 'epoch': 0.39}                                                                                                      
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                              | 300/7620 [27:25<4:57:06,  2.44s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.846468687057495, 'eval_wer': 1.0, 'eval_cer': 0.9962046238292489, 'eval_runtime': 367.3517, 'eval_samples_per_second': 5.444, 'eval_steps_per_second': 0.681, 'epoch': 0.39}                                                                                                                                                                
{'loss': 2.8643, 'learning_rate': 0.0002957142857142857, 'epoch': 0.41}                                                                                                       
{'loss': 2.8001, 'learning_rate': 0.0002953099730458221, 'epoch': 0.42}                                                                                                       
{'loss': 2.8399, 'learning_rate': 0.00029490566037735847, 'epoch': 0.43}                                                                                                      
{'loss': 2.8258, 'learning_rate': 0.00029450134770889484, 'epoch': 0.45}                                                                                                      
{'loss': 2.8492, 'learning_rate': 0.0002940970350404312, 'epoch': 0.46}                                                                                                       
{'loss': 2.8307, 'learning_rate': 0.0002936927223719676, 'epoch': 0.47}                                                                                                       
{'loss': 2.7933, 'learning_rate': 0.00029328840970350403, 'epoch': 0.49}                                                                                                      
{'loss': 2.7965, 'learning_rate': 0.0002928840970350404, 'epoch': 0.5}                                                                                                        
{'loss': 2.8151, 'learning_rate': 0.0002924797843665768, 'epoch': 0.51}                                                                                                       
{'loss': 2.8078, 'learning_rate': 0.00029207547169811317, 'epoch': 0.52}                                                                                                      
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                             | 400/7620 [39:24<5:00:46,  2.50s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.788996934890747, 'eval_wer': 1.0, 'eval_cer': 0.9962046238292489, 'eval_runtime': 398.3067, 'eval_samples_per_second': 5.021, 'eval_steps_per_second': 0.628, 'epoch': 0.52}                                                                                                                                                                
{'loss': 2.796, 'learning_rate': 0.0002916711590296496, 'epoch': 0.54}                                                                                                        
{'loss': 2.8713, 'learning_rate': 0.00029126684636118593, 'epoch': 0.55}                                                                                                      
{'loss': 2.812, 'learning_rate': 0.00029086253369272236, 'epoch': 0.56}                                                                                                       
{'loss': 2.8141, 'learning_rate': 0.00029045822102425874, 'epoch': 0.58}                                                                                                      
{'loss': 2.8074, 'learning_rate': 0.0002900539083557951, 'epoch': 0.59}                                                                                                       
{'loss': 2.7921, 'learning_rate': 0.0002896495956873315, 'epoch': 0.6}                                                                                                        
{'loss': 2.7767, 'learning_rate': 0.0002892452830188679, 'epoch': 0.62}                                                                                                       
{'loss': 2.8026, 'learning_rate': 0.0002888409703504043, 'epoch': 0.63}                                                                                                       
{'loss': 2.7947, 'learning_rate': 0.0002884366576819407, 'epoch': 0.64}                                                                                                       
{'loss': 2.7938, 'learning_rate': 0.00028803234501347707, 'epoch': 0.66}                                                                                                      
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                           | 500/7620 [52:14<5:00:37,  2.53s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.7496705055236816, 'eval_wer': 1.0, 'eval_cer': 0.9962046238292489, 'eval_runtime': 397.1799, 'eval_samples_per_second': 5.036, 'eval_steps_per_second': 0.629, 'epoch': 0.66}                                                                                                                                                               
{'loss': 2.769, 'learning_rate': 0.00028762803234501345, 'epoch': 0.67}                                                                                                       
{'loss': 2.7595, 'learning_rate': 0.0002872237196765498, 'epoch': 0.68}                                                                                                       
{'loss': 2.7396, 'learning_rate': 0.0002868194070080862, 'epoch': 0.7}                                                                                                        
{'loss': 2.711, 'learning_rate': 0.00028641509433962264, 'epoch': 0.71}                                                                                                       
{'loss': 2.6841, 'learning_rate': 0.000286010781671159, 'epoch': 0.72}                                                                                                        
{'loss': 2.6365, 'learning_rate': 0.0002856064690026954, 'epoch': 0.73}                                                                                                       
{'loss': 2.5079, 'learning_rate': 0.00028520215633423177, 'epoch': 0.75}                                                                                                      
{'loss': 2.288, 'learning_rate': 0.00028479784366576815, 'epoch': 0.76}                                                                                                       
{'loss': 1.9938, 'learning_rate': 0.00028439353099730453, 'epoch': 0.77}                                                                                                      
{'loss': 1.8436, 'learning_rate': 0.00028398921832884096, 'epoch': 0.79}                                                                                                      
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                       | 600/7620 [1:05:05<5:17:24,  2.71s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 1.5290148258209229, 'eval_wer': 0.9941403296537124, 'eval_cer': 0.5431332938831868, 'eval_runtime': 461.1778, 'eval_samples_per_second': 4.337, 'eval_steps_per_second': 0.542, 'epoch': 0.79}                                                                                                                                                
{'loss': 1.5967, 'learning_rate': 0.00028358490566037734, 'epoch': 0.8}                                                                                                       
{'loss': 1.432, 'learning_rate': 0.0002831805929919137, 'epoch': 0.81}                                                                                                        
{'loss': 1.4212, 'learning_rate': 0.0002827762803234501, 'epoch': 0.83}                                                                                                       
{'loss': 1.3328, 'learning_rate': 0.0002823719676549865, 'epoch': 0.84}                                                                                                       
{'loss': 1.3399, 'learning_rate': 0.0002819676549865229, 'epoch': 0.85}                                                                                                       
{'loss': 1.2045, 'learning_rate': 0.00028156334231805924, 'epoch': 0.87}                                                                                                      
{'loss': 1.0836, 'learning_rate': 0.00028115902964959567, 'epoch': 0.88}                                                                                                      
{'loss': 1.0932, 'learning_rate': 0.00028075471698113205, 'epoch': 0.89}                                                                                                      
{'loss': 1.0636, 'learning_rate': 0.0002803504043126685, 'epoch': 0.91}                                                                                                       
{'loss': 1.1069, 'learning_rate': 0.0002799460916442048, 'epoch': 0.92}                                                                                                       
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                      | 700/7620 [1:18:15<5:11:18,  2.70s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.7750478982925415, 'eval_wer': 0.7432708301829729, 'eval_cer': 0.23189884438277525, 'eval_runtime': 390.0376, 'eval_samples_per_second': 5.128, 'eval_steps_per_second': 0.641, 'epoch': 0.92}                                                                                                                                               
{'loss': 0.9744, 'learning_rate': 0.00027954177897574124, 'epoch': 0.93}                                                                                                      
{'loss': 0.9172, 'learning_rate': 0.0002791374663072776, 'epoch': 0.94}                                                                                                       
{'loss': 0.9218, 'learning_rate': 0.000278733153638814, 'epoch': 0.96}                                                                                                        
{'loss': 0.8768, 'learning_rate': 0.0002783288409703504, 'epoch': 0.97}                                                                                                       
{'loss': 0.8339, 'learning_rate': 0.00027792452830188675, 'epoch': 0.98}                                                                                                      
{'loss': 0.9839, 'learning_rate': 0.0002775202156334232, 'epoch': 1.0}                                                                                                        
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                     | 761/7620 [1:28:31<6:22:45,  3.35s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-761
Configuration saved in spanish_portuguese_high_augmented/checkpoint-761/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-761/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-761/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.767, 'learning_rate': 0.0002771159029649595, 'epoch': 1.01}                                                                                                        
{'loss': 0.7663, 'learning_rate': 0.00027671159029649594, 'epoch': 1.02}                                                                                                      
{'loss': 0.7162, 'learning_rate': 0.0002763072776280323, 'epoch': 1.04}                                                                                                       
{'loss': 0.6995, 'learning_rate': 0.0002759029649595687, 'epoch': 1.05}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                    | 800/7620 [1:31:23<6:17:52,  3.32s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5279794931411743, 'eval_wer': 0.5796537123846968, 'eval_cer': 0.1654933648934506, 'eval_runtime': 413.8237, 'eval_samples_per_second': 4.833, 'eval_steps_per_second': 0.604, 'epoch': 1.05}                                                                                                                                                
{'loss': 0.7061, 'learning_rate': 0.0002754986522911051, 'epoch': 1.06}                                                                                                       
{'loss': 0.7161, 'learning_rate': 0.0002750943396226415, 'epoch': 1.08}                                                                                                       
{'loss': 0.7355, 'learning_rate': 0.0002746900269541779, 'epoch': 1.09}                                                                                                       
{'loss': 0.6956, 'learning_rate': 0.00027428571428571427, 'epoch': 1.1}                                                                                                       
{'loss': 0.7484, 'learning_rate': 0.00027388140161725065, 'epoch': 1.12}                                                                                                      
{'loss': 0.6697, 'learning_rate': 0.000273477088948787, 'epoch': 1.13}                                                                                                        
{'loss': 0.6739, 'learning_rate': 0.0002730727762803234, 'epoch': 1.14}                                                                                                       
{'loss': 0.627, 'learning_rate': 0.0002726684636118598, 'epoch': 1.15}                                                                                                        
{'loss': 0.5989, 'learning_rate': 0.0002722641509433962, 'epoch': 1.17}                                                                                                       
{'loss': 0.5331, 'learning_rate': 0.0002718598382749326, 'epoch': 1.18}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                  | 900/7620 [1:44:43<6:38:34,  3.56s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.4609329402446747, 'eval_wer': 0.5353470437017995, 'eval_cer': 0.15038667945395556, 'eval_runtime': 397.1077, 'eval_samples_per_second': 5.036, 'eval_steps_per_second': 0.63, 'epoch': 1.18}                                                                                                                                                
{'loss': 0.717, 'learning_rate': 0.000271455525606469, 'epoch': 1.19}                                                                                                         
{'loss': 0.6293, 'learning_rate': 0.00027105121293800535, 'epoch': 1.21}                                                                                                      
{'loss': 0.5674, 'learning_rate': 0.0002706469002695418, 'epoch': 1.22}                                                                                                       
{'loss': 0.603, 'learning_rate': 0.0002702425876010781, 'epoch': 1.23}                                                                                                        
{'loss': 0.5533, 'learning_rate': 0.00026983827493261454, 'epoch': 1.25}                                                                                                      
{'loss': 0.5178, 'learning_rate': 0.0002694339622641509, 'epoch': 1.26}                                                                                                       
{'loss': 0.6297, 'learning_rate': 0.0002690296495956873, 'epoch': 1.27}                                                                                                       
{'loss': 0.6576, 'learning_rate': 0.0002686253369272237, 'epoch': 1.29}                                                                                                       
{'loss': 0.5741, 'learning_rate': 0.0002682210242587601, 'epoch': 1.3}                                                                                                        
{'loss': 0.5807, 'learning_rate': 0.0002678167115902965, 'epoch': 1.31}                                                                                                       
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                | 1000/7620 [1:57:06<5:35:42,  3.04s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.43354088068008423, 'eval_wer': 0.43002419476788145, 'eval_cer': 0.1273083437060012, 'eval_runtime': 381.5255, 'eval_samples_per_second': 5.242, 'eval_steps_per_second': 0.655, 'epoch': 1.31}                                                                                                                                              
{'loss': 0.5263, 'learning_rate': 0.00026741239892183287, 'epoch': 1.33}                                                                                                      
{'loss': 0.5774, 'learning_rate': 0.00026700808625336925, 'epoch': 1.34}                                                                                                      
{'loss': 0.5321, 'learning_rate': 0.00026660377358490563, 'epoch': 1.35}                                                                                                      
{'loss': 0.5429, 'learning_rate': 0.000266199460916442, 'epoch': 1.36}                                                                                                        
{'loss': 0.5154, 'learning_rate': 0.0002657951482479784, 'epoch': 1.38}                                                                                                       
{'loss': 0.4284, 'learning_rate': 0.0002653908355795148, 'epoch': 1.39}                                                                                                       
{'loss': 0.5812, 'learning_rate': 0.0002649865229110512, 'epoch': 1.4}                                                                                                        
{'loss': 0.4734, 'learning_rate': 0.0002645822102425876, 'epoch': 1.42}                                                                                                       
{'loss': 0.5235, 'learning_rate': 0.00026417789757412396, 'epoch': 1.43}                                                                                                      
{'loss': 0.4551, 'learning_rate': 0.0002637735849056604, 'epoch': 1.44}                                                                                                       
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                              | 1100/7620 [2:09:48<5:44:08,  3.17s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3720914125442505, 'eval_wer': 0.38163465900499016, 'eval_cer': 0.1148611422857959, 'eval_runtime': 398.9959, 'eval_samples_per_second': 5.013, 'eval_steps_per_second': 0.627, 'epoch': 1.44}                                                                                                                                               
{'loss': 0.5059, 'learning_rate': 0.0002633692722371967, 'epoch': 1.46}                                                                                                       
{'loss': 0.5188, 'learning_rate': 0.00026296495956873315, 'epoch': 1.47}                                                                                                      
{'loss': 0.4859, 'learning_rate': 0.0002625606469002695, 'epoch': 1.48}                                                                                                       
{'loss': 0.5241, 'learning_rate': 0.0002621563342318059, 'epoch': 1.5}                                                                                                        
{'loss': 0.4822, 'learning_rate': 0.0002617520215633423, 'epoch': 1.51}                                                                                                       
{'loss': 0.5108, 'learning_rate': 0.00026134770889487866, 'epoch': 1.52}                                                                                                      
{'loss': 0.5291, 'learning_rate': 0.0002609433962264151, 'epoch': 1.54}                                                                                                       
{'loss': 0.4499, 'learning_rate': 0.0002605390835579514, 'epoch': 1.55}                                                                                                       
{'loss': 0.4635, 'learning_rate': 0.00026013477088948785, 'epoch': 1.56}                                                                                                      
{'loss': 0.4942, 'learning_rate': 0.00025973045822102423, 'epoch': 1.57}                                                                                                      
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                            | 1200/7620 [2:22:37<5:37:32,  3.15s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3327488899230957, 'eval_wer': 0.36745803719945563, 'eval_cer': 0.11217445126886635, 'eval_runtime': 399.8011, 'eval_samples_per_second': 5.002, 'eval_steps_per_second': 0.625, 'epoch': 1.57}                                                                                                                                              
{'loss': 0.4832, 'learning_rate': 0.00025932614555256066, 'epoch': 1.59}                                                                                                      
{'loss': 0.4691, 'learning_rate': 0.000258921832884097, 'epoch': 1.6}                                                                                                         
{'loss': 0.4619, 'learning_rate': 0.0002585175202156334, 'epoch': 1.61}                                                                                                       
{'loss': 0.4251, 'learning_rate': 0.0002581132075471698, 'epoch': 1.63}                                                                                                       
{'loss': 0.4357, 'learning_rate': 0.0002577088948787062, 'epoch': 1.64}                                                                                                       
{'loss': 0.4241, 'learning_rate': 0.00025730458221024256, 'epoch': 1.65}                                                                                                      
{'loss': 0.501, 'learning_rate': 0.00025690026954177894, 'epoch': 1.67}                                                                                                       
{'loss': 0.4251, 'learning_rate': 0.00025649595687331537, 'epoch': 1.68}                                                                                                      
{'loss': 0.4329, 'learning_rate': 0.00025609164420485175, 'epoch': 1.69}                                                                                                      
{'loss': 0.4132, 'learning_rate': 0.0002556873315363881, 'epoch': 1.71}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                           | 1300/7620 [2:35:57<6:16:29,  3.57s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3393728733062744, 'eval_wer': 0.3581203689702102, 'eval_cer': 0.10996388271063318, 'eval_runtime': 422.3085, 'eval_samples_per_second': 4.736, 'eval_steps_per_second': 0.592, 'epoch': 1.71}                                                                                                                                               
{'loss': 0.3702, 'learning_rate': 0.0002552830188679245, 'epoch': 1.72}                                                                                                       
{'loss': 0.4334, 'learning_rate': 0.0002548787061994609, 'epoch': 1.73}                                                                                                       
{'loss': 0.443, 'learning_rate': 0.00025447439353099726, 'epoch': 1.75}                                                                                                       
{'loss': 0.3697, 'learning_rate': 0.0002540700808625337, 'epoch': 1.76}                                                                                                       
{'loss': 0.4286, 'learning_rate': 0.0002536657681940701, 'epoch': 1.77}                                                                                                       
{'loss': 0.4438, 'learning_rate': 0.00025326145552560645, 'epoch': 1.78}                                                                                                      
{'loss': 0.4651, 'learning_rate': 0.00025285714285714283, 'epoch': 1.8}                                                                                                       
{'loss': 0.4467, 'learning_rate': 0.0002524528301886792, 'epoch': 1.81}                                                                                                       
{'loss': 0.4352, 'learning_rate': 0.0002520485175202156, 'epoch': 1.82}                                                                                                       
{'loss': 0.3838, 'learning_rate': 0.000251644204851752, 'epoch': 1.84}                                                                                                        
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                         | 1400/7620 [2:49:18<5:22:02,  3.11s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3251107335090637, 'eval_wer': 0.3345304702858007, 'eval_cer': 0.1036382557593813, 'eval_runtime': 381.8918, 'eval_samples_per_second': 5.237, 'eval_steps_per_second': 0.655, 'epoch': 1.84}                                                                                                                                                
{'loss': 0.3873, 'learning_rate': 0.0002512398921832884, 'epoch': 1.85}                                                                                                       
{'loss': 0.4084, 'learning_rate': 0.0002508355795148248, 'epoch': 1.86}                                                                                                       
{'loss': 0.2948, 'learning_rate': 0.00025043126684636116, 'epoch': 1.88}                                                                                                      
{'loss': 0.4335, 'learning_rate': 0.00025002695417789754, 'epoch': 1.89}                                                                                                      
{'loss': 0.427, 'learning_rate': 0.00024962264150943397, 'epoch': 1.9}                                                                                                        
{'loss': 0.4033, 'learning_rate': 0.0002492183288409703, 'epoch': 1.92}                                                                                                       
{'loss': 0.3869, 'learning_rate': 0.0002488140161725067, 'epoch': 1.93}                                                                                                       
{'loss': 0.3877, 'learning_rate': 0.0002484097035040431, 'epoch': 1.94}                                                                                                       
{'loss': 0.4019, 'learning_rate': 0.0002480053908355795, 'epoch': 1.96}                                                                                                       
{'loss': 0.3655, 'learning_rate': 0.00024760107816711586, 'epoch': 1.97}                                                                                                      
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                       | 1500/7620 [3:02:04<4:54:22,  2.89s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3271355926990509, 'eval_wer': 0.3333207318917284, 'eval_cer': 0.103679066255841, 'eval_runtime': 375.0085, 'eval_samples_per_second': 5.333, 'eval_steps_per_second': 0.667, 'epoch': 1.97}                                                                                                                                                 
{'loss': 0.3436, 'learning_rate': 0.0002471967654986523, 'epoch': 1.98}                                                                                                       
{'loss': 0.4228, 'learning_rate': 0.0002467924528301887, 'epoch': 1.99}                                                                                                       
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                       | 1522/7620 [3:09:38<6:28:50,  3.83s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-1522
Configuration saved in spanish_portuguese_high_augmented/checkpoint-1522/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-1522/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-1522/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3012, 'learning_rate': 0.00024638814016172505, 'epoch': 2.01}                                                                                                      
{'loss': 0.2925, 'learning_rate': 0.00024598382749326143, 'epoch': 2.02}                                                                                                      
{'loss': 0.2894, 'learning_rate': 0.0002455795148247978, 'epoch': 2.03}                                                                                                       
{'loss': 0.2764, 'learning_rate': 0.0002451752021563342, 'epoch': 2.05}                                                                                                       
{'loss': 0.3724, 'learning_rate': 0.00024477088948787057, 'epoch': 2.06}                                                                                                      
{'loss': 0.34, 'learning_rate': 0.000244366576819407, 'epoch': 2.07}                                                                                                          
{'loss': 0.3299, 'learning_rate': 0.00024396226415094338, 'epoch': 2.09}                                                                                                      
{'loss': 0.2882, 'learning_rate': 0.00024355795148247976, 'epoch': 2.1}                                                                                                       
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                      | 1600/7620 [3:15:00<6:13:07,  3.72s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.30121996998786926, 'eval_wer': 0.3234159987902616, 'eval_cer': 0.09863896994306935, 'eval_runtime': 330.8463, 'eval_samples_per_second': 6.045, 'eval_steps_per_second': 0.756, 'epoch': 2.1}                                                                                                                                               
{'loss': 0.3399, 'learning_rate': 0.00024315363881401614, 'epoch': 2.11}                                                                                                      
{'loss': 0.3032, 'learning_rate': 0.00024274932614555254, 'epoch': 2.13}                                                                                                      
{'loss': 0.287, 'learning_rate': 0.00024234501347708892, 'epoch': 2.14}                                                                                                       
{'loss': 0.3128, 'learning_rate': 0.0002419407008086253, 'epoch': 2.15}                                                                                                       
{'loss': 0.3057, 'learning_rate': 0.0002415363881401617, 'epoch': 2.17}                                                                                                       
{'loss': 0.294, 'learning_rate': 0.0002411320754716981, 'epoch': 2.18}                                                                                                        
{'loss': 0.2689, 'learning_rate': 0.00024072776280323446, 'epoch': 2.19}                                                                                                      
{'loss': 0.3398, 'learning_rate': 0.00024032345013477087, 'epoch': 2.2}                                                                                                       
{'loss': 0.3526, 'learning_rate': 0.00023991913746630728, 'epoch': 2.22}                                                                                                      
{'loss': 0.2821, 'learning_rate': 0.00023951482479784363, 'epoch': 2.23}                                                                                                      
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                    | 1700/7620 [3:26:29<5:37:53,  3.42s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3062809407711029, 'eval_wer': 0.3206562830787842, 'eval_cer': 0.09859135769719972, 'eval_runtime': 398.2117, 'eval_samples_per_second': 5.022, 'eval_steps_per_second': 0.628, 'epoch': 2.23}                                                                                                                                               
{'loss': 0.282, 'learning_rate': 0.00023911051212938003, 'epoch': 2.24}                                                                                                       
{'loss': 0.2896, 'learning_rate': 0.0002387061994609164, 'epoch': 2.26}                                                                                                       
{'loss': 0.2782, 'learning_rate': 0.00023830188679245282, 'epoch': 2.27}                                                                                                      
{'loss': 0.3465, 'learning_rate': 0.0002378975741239892, 'epoch': 2.28}                                                                                                       
{'loss': 0.3119, 'learning_rate': 0.00023749326145552558, 'epoch': 2.3}                                                                                                       
{'loss': 0.3326, 'learning_rate': 0.00023708894878706198, 'epoch': 2.31}                                                                                                      
{'loss': 0.2921, 'learning_rate': 0.00023668463611859836, 'epoch': 2.32}                                                                                                      
{'loss': 0.2803, 'learning_rate': 0.00023628032345013474, 'epoch': 2.34}                                                                                                      
{'loss': 0.2628, 'learning_rate': 0.00023587601078167115, 'epoch': 2.35}                                                                                                      
{'loss': 0.3635, 'learning_rate': 0.00023547169811320755, 'epoch': 2.36}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 1800/7620 [3:38:59<5:35:42,  3.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2948892116546631, 'eval_wer': 0.313171026765462, 'eval_cer': 0.09978166384394066, 'eval_runtime': 385.754, 'eval_samples_per_second': 5.185, 'eval_steps_per_second': 0.648, 'epoch': 2.36}                                                                                                                                                 
{'loss': 0.2681, 'learning_rate': 0.0002350673854447439, 'epoch': 2.38}                                                                                                       
{'loss': 0.2781, 'learning_rate': 0.0002346630727762803, 'epoch': 2.39}                                                                                                       
{'loss': 0.2743, 'learning_rate': 0.00023425876010781671, 'epoch': 2.4}                                                                                                       
{'loss': 0.2724, 'learning_rate': 0.00023385444743935307, 'epoch': 2.41}                                                                                                      
{'loss': 0.3189, 'learning_rate': 0.00023345013477088947, 'epoch': 2.43}                                                                                                      
{'loss': 0.249, 'learning_rate': 0.00023304582210242585, 'epoch': 2.44}                                                                                                       
{'loss': 0.2623, 'learning_rate': 0.00023264150943396226, 'epoch': 2.45}                                                                                                      
{'loss': 0.3134, 'learning_rate': 0.00023223719676549864, 'epoch': 2.47}                                                                                                      
{'loss': 0.3172, 'learning_rate': 0.00023183288409703501, 'epoch': 2.48}                                                                                                      
{'loss': 0.2752, 'learning_rate': 0.00023142857142857142, 'epoch': 2.49}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                | 1900/7620 [3:51:05<5:01:50,  3.17s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2833312749862671, 'eval_wer': 0.3213367609254499, 'eval_cer': 0.10068629651546378, 'eval_runtime': 374.1766, 'eval_samples_per_second': 5.345, 'eval_steps_per_second': 0.668, 'epoch': 2.49}                                                                                                                                               
{'loss': 0.2585, 'learning_rate': 0.00023102425876010777, 'epoch': 2.51}                                                                                                      
{'loss': 0.304, 'learning_rate': 0.00023061994609164418, 'epoch': 2.52}                                                                                                       
{'loss': 0.3849, 'learning_rate': 0.00023021563342318058, 'epoch': 2.53}                                                                                                      
{'loss': 0.3505, 'learning_rate': 0.000229811320754717, 'epoch': 2.55}                                                                                                        
{'loss': 0.3091, 'learning_rate': 0.00022940700808625334, 'epoch': 2.56}                                                                                                      
{'loss': 0.2835, 'learning_rate': 0.00022900269541778975, 'epoch': 2.57}                                                                                                      
{'loss': 0.2568, 'learning_rate': 0.00022859838274932613, 'epoch': 2.59}                                                                                                      
{'loss': 0.3055, 'learning_rate': 0.0002281940700808625, 'epoch': 2.6}                                                                                                        
{'loss': 0.2393, 'learning_rate': 0.0002277897574123989, 'epoch': 2.61}                                                                                                       
{'loss': 0.2435, 'learning_rate': 0.0002273854447439353, 'epoch': 2.62}                                                                                                       
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                               | 2000/7620 [4:02:54<4:56:53,  3.17s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2772548794746399, 'eval_wer': 0.29574323302585814, 'eval_cer': 0.09055849164405085, 'eval_runtime': 413.8067, 'eval_samples_per_second': 4.833, 'eval_steps_per_second': 0.604, 'epoch': 2.62}                                                                                                                                              
{'loss': 0.2874, 'learning_rate': 0.0002269811320754717, 'epoch': 2.64}                                                                                                       
{'loss': 0.2556, 'learning_rate': 0.00022657681940700805, 'epoch': 2.65}                                                                                                      
{'loss': 0.2917, 'learning_rate': 0.00022617250673854445, 'epoch': 2.66}                                                                                                      
{'loss': 0.291, 'learning_rate': 0.00022576819407008086, 'epoch': 2.68}                                                                                                       
{'loss': 0.3017, 'learning_rate': 0.0002253638814016172, 'epoch': 2.69}                                                                                                       
{'loss': 0.3036, 'learning_rate': 0.00022495956873315362, 'epoch': 2.7}                                                                                                       
{'loss': 0.242, 'learning_rate': 0.00022455525606469002, 'epoch': 2.72}                                                                                                       
{'loss': 0.241, 'learning_rate': 0.00022415094339622637, 'epoch': 2.73}                                                                                                       
{'loss': 0.3094, 'learning_rate': 0.00022374663072776278, 'epoch': 2.74}                                                                                                      
{'loss': 0.2419, 'learning_rate': 0.00022334231805929918, 'epoch': 2.76}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                             | 2100/7620 [4:15:50<5:06:34,  3.33s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2788582742214203, 'eval_wer': 0.2991834265840012, 'eval_cer': 0.09055168989464091, 'eval_runtime': 394.5242, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 0.634, 'epoch': 2.76}                                                                                                                                               
{'loss': 0.2503, 'learning_rate': 0.00022293800539083556, 'epoch': 2.77}                                                                                                      
{'loss': 0.2531, 'learning_rate': 0.00022253369272237194, 'epoch': 2.78}                                                                                                      
{'loss': 0.2702, 'learning_rate': 0.00022212938005390835, 'epoch': 2.8}                                                                                                       
{'loss': 0.2626, 'learning_rate': 0.00022172506738544473, 'epoch': 2.81}                                                                                                      
{'loss': 0.2743, 'learning_rate': 0.0002213207547169811, 'epoch': 2.82}                                                                                                       
{'loss': 0.2162, 'learning_rate': 0.00022091644204851748, 'epoch': 2.83}                                                                                                      
{'loss': 0.1755, 'learning_rate': 0.0002205121293800539, 'epoch': 2.85}                                                                                                       
{'loss': 0.2758, 'learning_rate': 0.0002201078167115903, 'epoch': 2.86}                                                                                                       
{'loss': 0.2511, 'learning_rate': 0.00021970350404312665, 'epoch': 2.87}                                                                                                      
{'loss': 0.2523, 'learning_rate': 0.00021929919137466305, 'epoch': 2.89}                                                                                                      
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 2200/7620 [4:28:23<5:14:21,  3.48s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2783879339694977, 'eval_wer': 0.29702858006955996, 'eval_cer': 0.09350364913855844, 'eval_runtime': 377.3508, 'eval_samples_per_second': 5.3, 'eval_steps_per_second': 0.663, 'epoch': 2.89}                                                                                                                                                
{'loss': 0.2253, 'learning_rate': 0.00021889487870619946, 'epoch': 2.9}                                                                                                       
{'loss': 0.2413, 'learning_rate': 0.0002184905660377358, 'epoch': 2.91}                                                                                                       
{'loss': 0.299, 'learning_rate': 0.00021808625336927222, 'epoch': 2.93}                                                                                                       
{'loss': 0.3036, 'learning_rate': 0.00021768194070080862, 'epoch': 2.94}                                                                                                      
{'loss': 0.2707, 'learning_rate': 0.000217277628032345, 'epoch': 2.95}                                                                                                        
{'loss': 0.2463, 'learning_rate': 0.00021687331536388138, 'epoch': 2.97}                                                                                                      
{'loss': 0.2153, 'learning_rate': 0.00021646900269541776, 'epoch': 2.98}                                                                                                      
{'loss': 0.2657, 'learning_rate': 0.00021606469002695416, 'epoch': 2.99}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                          | 2283/7620 [4:39:21<4:53:55,  3.30s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-2283
Configuration saved in spanish_portuguese_high_augmented/checkpoint-2283/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-2283/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-2283/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2803, 'learning_rate': 0.00021566037735849054, 'epoch': 3.01}                                                                                                      
{'loss': 0.2624, 'learning_rate': 0.00021525606469002692, 'epoch': 3.02}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                          | 2300/7620 [4:40:52<6:22:35,  4.31s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.27193644642829895, 'eval_wer': 0.2904506275517919, 'eval_cer': 0.09212969575774889, 'eval_runtime': 404.2513, 'eval_samples_per_second': 4.947, 'eval_steps_per_second': 0.618, 'epoch': 3.02}                                                                                                                                              
{'loss': 0.2316, 'learning_rate': 0.00021485175202156333, 'epoch': 3.03}                                                                                                      
{'loss': 0.224, 'learning_rate': 0.00021444743935309973, 'epoch': 3.04}                                                                                                       
{'loss': 0.2034, 'learning_rate': 0.00021404312668463609, 'epoch': 3.06}                                                                                                      
{'loss': 0.215, 'learning_rate': 0.0002136388140161725, 'epoch': 3.07}                                                                                                        
{'loss': 0.2127, 'learning_rate': 0.0002132345013477089, 'epoch': 3.08}                                                                                                       
{'loss': 0.2804, 'learning_rate': 0.00021283018867924525, 'epoch': 3.1}                                                                                                       
{'loss': 0.2421, 'learning_rate': 0.00021242587601078165, 'epoch': 3.11}                                                                                                      
{'loss': 0.192, 'learning_rate': 0.00021202156334231803, 'epoch': 3.12}                                                                                                       
{'loss': 0.1881, 'learning_rate': 0.00021161725067385444, 'epoch': 3.14}                                                                                                      
{'loss': 0.2242, 'learning_rate': 0.00021121293800539082, 'epoch': 3.15}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                        | 2400/7620 [4:53:49<5:46:25,  3.98s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2688042223453522, 'eval_wer': 0.28750189021624073, 'eval_cer': 0.09025241292060318, 'eval_runtime': 386.7456, 'eval_samples_per_second': 5.171, 'eval_steps_per_second': 0.646, 'epoch': 3.15}                                                                                                                                              
{'loss': 0.2205, 'learning_rate': 0.0002108086253369272, 'epoch': 3.16}                                                                                                       
{'loss': 0.1974, 'learning_rate': 0.0002104043126684636, 'epoch': 3.18}                                                                                                       
{'loss': 0.1944, 'learning_rate': 0.00020999999999999998, 'epoch': 3.19}                                                                                                      
{'loss': 0.215, 'learning_rate': 0.00020959568733153636, 'epoch': 3.2}                                                                                                        
{'loss': 0.2104, 'learning_rate': 0.00020919137466307277, 'epoch': 3.22}                                                                                                      
{'loss': 0.2521, 'learning_rate': 0.00020878706199460917, 'epoch': 3.23}                                                                                                      
{'loss': 0.1997, 'learning_rate': 0.00020838274932614552, 'epoch': 3.24}                                                                                                      
{'loss': 0.1728, 'learning_rate': 0.00020797843665768193, 'epoch': 3.25}                                                                                                      
{'loss': 0.2312, 'learning_rate': 0.0002075741239892183, 'epoch': 3.27}                                                                                                       
{'loss': 0.2006, 'learning_rate': 0.0002071698113207547, 'epoch': 3.28}                                                                                                       
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                      | 2500/7620 [5:06:31<5:16:10,  3.71s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2725360095500946, 'eval_wer': 0.284326326931801, 'eval_cer': 0.09074213887811945, 'eval_runtime': 343.0486, 'eval_samples_per_second': 5.83, 'eval_steps_per_second': 0.729, 'epoch': 3.28}                                                                                                                                                 
{'loss': 0.2486, 'learning_rate': 0.0002067654986522911, 'epoch': 3.29}                                                                                                       
{'loss': 0.2192, 'learning_rate': 0.00020636118598382747, 'epoch': 3.31}                                                                                                      
{'loss': 0.1702, 'learning_rate': 0.00020595687331536388, 'epoch': 3.32}                                                                                                      
{'loss': 0.2208, 'learning_rate': 0.00020555256064690026, 'epoch': 3.33}                                                                                                      
{'loss': 0.2156, 'learning_rate': 0.00020514824797843664, 'epoch': 3.35}                                                                                                      
{'loss': 0.2006, 'learning_rate': 0.00020474393530997304, 'epoch': 3.36}                                                                                                      
{'loss': 0.229, 'learning_rate': 0.0002043396226415094, 'epoch': 3.37}                                                                                                        
{'loss': 0.2081, 'learning_rate': 0.0002039353099730458, 'epoch': 3.39}                                                                                                       
{'loss': 0.1848, 'learning_rate': 0.0002035309973045822, 'epoch': 3.4}                                                                                                        
{'loss': 0.2453, 'learning_rate': 0.00020312668463611856, 'epoch': 3.41}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                     | 2600/7620 [5:17:45<5:18:10,  3.80s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2652134597301483, 'eval_wer': 0.29071525782549523, 'eval_cer': 0.09264662871290497, 'eval_runtime': 364.2798, 'eval_samples_per_second': 5.49, 'eval_steps_per_second': 0.686, 'epoch': 3.41}                                                                                                                                               
{'loss': 0.2442, 'learning_rate': 0.00020272237196765496, 'epoch': 3.43}                                                                                                      
{'loss': 0.1961, 'learning_rate': 0.00020231805929919137, 'epoch': 3.44}                                                                                                      
{'loss': 0.2187, 'learning_rate': 0.00020191374663072775, 'epoch': 3.45}                                                                                                      
{'loss': 0.1786, 'learning_rate': 0.00020150943396226413, 'epoch': 3.46}                                                                                                      
{'loss': 0.2434, 'learning_rate': 0.00020110512129380053, 'epoch': 3.48}                                                                                                      
{'loss': 0.1822, 'learning_rate': 0.0002007008086253369, 'epoch': 3.49}                                                                                                       
{'loss': 0.205, 'learning_rate': 0.0002002964959568733, 'epoch': 3.5}                                                                                                         
{'loss': 0.1953, 'learning_rate': 0.00019989218328840967, 'epoch': 3.52}                                                                                                      
{'loss': 0.2317, 'learning_rate': 0.00019948787061994607, 'epoch': 3.53}                                                                                                      
{'loss': 0.2646, 'learning_rate': 0.00019908355795148248, 'epoch': 3.54}                                                                                                      
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                   | 2700/7620 [5:29:32<5:08:51,  3.77s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.28659138083457947, 'eval_wer': 0.2895433237562377, 'eval_cer': 0.08804864611177995, 'eval_runtime': 364.8463, 'eval_samples_per_second': 5.482, 'eval_steps_per_second': 0.685, 'epoch': 3.54}                                                                                                                                              
{'loss': 0.2279, 'learning_rate': 0.00019867924528301883, 'epoch': 3.56}                                                                                                      
{'loss': 0.1696, 'learning_rate': 0.00019827493261455524, 'epoch': 3.57}                                                                                                      
{'loss': 0.1977, 'learning_rate': 0.00019787061994609164, 'epoch': 3.58}                                                                                                      
{'loss': 0.2298, 'learning_rate': 0.000197466307277628, 'epoch': 3.6}                                                                                                         
{'loss': 0.2164, 'learning_rate': 0.0001970619946091644, 'epoch': 3.61}                                                                                                       
{'loss': 0.1703, 'learning_rate': 0.0001966576819407008, 'epoch': 3.62}                                                                                                       
{'loss': 0.1775, 'learning_rate': 0.00019625336927223718, 'epoch': 3.64}                                                                                                      
{'loss': 0.2176, 'learning_rate': 0.00019584905660377356, 'epoch': 3.65}                                                                                                      
{'loss': 0.1941, 'learning_rate': 0.00019544474393530994, 'epoch': 3.66}                                                                                                      
{'loss': 0.2068, 'learning_rate': 0.00019504043126684635, 'epoch': 3.67}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                 | 2800/7620 [5:41:23<4:56:34,  3.69s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2828681766986847, 'eval_wer': 0.27793739603810674, 'eval_cer': 0.08603532828643527, 'eval_runtime': 364.8888, 'eval_samples_per_second': 5.481, 'eval_steps_per_second': 0.685, 'epoch': 3.67}                                                                                                                                              
{'loss': 0.2765, 'learning_rate': 0.00019463611859838273, 'epoch': 3.69}                                                                                                      
{'loss': 0.2009, 'learning_rate': 0.0001942318059299191, 'epoch': 3.7}                                                                                                        
{'loss': 0.1793, 'learning_rate': 0.0001938274932614555, 'epoch': 3.71}                                                                                                       
{'loss': 0.1963, 'learning_rate': 0.00019342318059299192, 'epoch': 3.73}                                                                                                      
{'loss': 0.1862, 'learning_rate': 0.00019301886792452827, 'epoch': 3.74}                                                                                                      
{'loss': 0.2004, 'learning_rate': 0.00019261455525606467, 'epoch': 3.75}                                                                                                      
{'loss': 0.179, 'learning_rate': 0.00019221024258760108, 'epoch': 3.77}                                                                                                       
{'loss': 0.1733, 'learning_rate': 0.00019180592991913743, 'epoch': 3.78}                                                                                                      
{'loss': 0.194, 'learning_rate': 0.00019140161725067384, 'epoch': 3.79}                                                                                                       
{'loss': 0.2197, 'learning_rate': 0.00019099730458221024, 'epoch': 3.81}                                                                                                      
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                | 2900/7620 [5:53:16<5:04:41,  3.87s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2570348083972931, 'eval_wer': 0.2810751549977317, 'eval_cer': 0.08731405717550554, 'eval_runtime': 373.0807, 'eval_samples_per_second': 5.361, 'eval_steps_per_second': 0.67, 'epoch': 3.81}                                                                                                                                                
{'loss': 0.1825, 'learning_rate': 0.00019059299191374662, 'epoch': 3.82}                                                                                                      
{'loss': 0.2487, 'learning_rate': 0.000190188679245283, 'epoch': 3.83}                                                                                                        
{'loss': 0.1633, 'learning_rate': 0.00018978436657681938, 'epoch': 3.85}                                                                                                      
{'loss': 0.2346, 'learning_rate': 0.00018938005390835579, 'epoch': 3.86}                                                                                                      
{'loss': 0.2033, 'learning_rate': 0.00018897574123989216, 'epoch': 3.87}                                                                                                      
{'loss': 0.174, 'learning_rate': 0.00018857142857142854, 'epoch': 3.88}                                                                                                       
{'loss': 0.1908, 'learning_rate': 0.00018816711590296495, 'epoch': 3.9}                                                                                                       
{'loss': 0.1622, 'learning_rate': 0.00018776280323450136, 'epoch': 3.91}                                                                                                      
{'loss': 0.2274, 'learning_rate': 0.0001873584905660377, 'epoch': 3.92}                                                                                                       
{'loss': 0.1798, 'learning_rate': 0.0001869541778975741, 'epoch': 3.94}                                                                                                       
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                              | 3000/7620 [6:05:00<4:47:54,  3.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26959219574928284, 'eval_wer': 0.27869348253440196, 'eval_cer': 0.08693996095795839, 'eval_runtime': 375.0831, 'eval_samples_per_second': 5.332, 'eval_steps_per_second': 0.667, 'epoch': 3.94}                                                                                                                                             
{'loss': 0.2162, 'learning_rate': 0.00018654986522911052, 'epoch': 3.95}                                                                                                      
{'loss': 0.1872, 'learning_rate': 0.00018614555256064687, 'epoch': 3.96}                                                                                                      
{'loss': 0.1779, 'learning_rate': 0.00018574123989218328, 'epoch': 3.98}                                                                                                      
{'loss': 0.2298, 'learning_rate': 0.00018533692722371965, 'epoch': 3.99}                                                                                                      
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                             | 3044/7620 [6:13:38<4:11:06,  3.29s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-3044
Configuration saved in spanish_portuguese_high_augmented/checkpoint-3044/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-3044/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-3044/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.128, 'learning_rate': 0.00018493261455525606, 'epoch': 4.0}                                                                                                        
{'loss': 0.1711, 'learning_rate': 0.00018452830188679244, 'epoch': 4.02}                                                                                                      
{'loss': 0.1818, 'learning_rate': 0.00018412398921832882, 'epoch': 4.03}                                                                                                      
{'loss': 0.1997, 'learning_rate': 0.00018371967654986522, 'epoch': 4.04}                                                                                                      
{'loss': 0.1804, 'learning_rate': 0.0001833153638814016, 'epoch': 4.06}                                                                                                       
{'loss': 0.1543, 'learning_rate': 0.00018291105121293798, 'epoch': 4.07}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 3100/7620 [6:17:02<5:04:14,  4.04s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.293448805809021, 'eval_wer': 0.27370331165885375, 'eval_cer': 0.08549118833363942, 'eval_runtime': 364.666, 'eval_samples_per_second': 5.484, 'eval_steps_per_second': 0.686, 'epoch': 4.07}                                                                                                                                                
{'loss': 0.1788, 'learning_rate': 0.0001825067385444744, 'epoch': 4.08}                                                                                                       
{'loss': 0.1796, 'learning_rate': 0.00018210242587601074, 'epoch': 4.09}                                                                                                      
{'loss': 0.1638, 'learning_rate': 0.00018169811320754714, 'epoch': 4.11}                                                                                                      
{'loss': 0.1492, 'learning_rate': 0.00018129380053908355, 'epoch': 4.12}                                                                                                      
{'loss': 0.1604, 'learning_rate': 0.00018088948787061993, 'epoch': 4.13}                                                                                                      
{'loss': 0.2058, 'learning_rate': 0.0001804851752021563, 'epoch': 4.15}                                                                                                       
{'loss': 0.2111, 'learning_rate': 0.00018008086253369271, 'epoch': 4.16}                                                                                                      
{'loss': 0.1333, 'learning_rate': 0.0001796765498652291, 'epoch': 4.17}                                                                                                       
{'loss': 0.1601, 'learning_rate': 0.00017927223719676547, 'epoch': 4.19}                                                                                                      
{'loss': 0.1621, 'learning_rate': 0.00017886792452830188, 'epoch': 4.2}                                                                                                       
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 3200/7620 [6:28:42<4:42:38,  3.84s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2690761983394623, 'eval_wer': 0.26584001209738395, 'eval_cer': 0.08305616204487794, 'eval_runtime': 369.0914, 'eval_samples_per_second': 5.419, 'eval_steps_per_second': 0.677, 'epoch': 4.2}                                                                                                                                               
{'loss': 0.1811, 'learning_rate': 0.00017846361185983826, 'epoch': 4.21}                                                                                                      
{'loss': 0.1669, 'learning_rate': 0.00017805929919137466, 'epoch': 4.23}                                                                                                      
{'loss': 0.1724, 'learning_rate': 0.000177654986522911, 'epoch': 4.24}                                                                                                        
{'loss': 0.1272, 'learning_rate': 0.00017725067385444742, 'epoch': 4.25}                                                                                                      
{'loss': 0.1851, 'learning_rate': 0.00017684636118598383, 'epoch': 4.27}                                                                                                      
{'loss': 0.1836, 'learning_rate': 0.00017644204851752018, 'epoch': 4.28}                                                                                                      
{'loss': 0.1447, 'learning_rate': 0.00017603773584905658, 'epoch': 4.29}                                                                                                      
{'loss': 0.145, 'learning_rate': 0.000175633423180593, 'epoch': 4.3}                                                                                                          
{'loss': 0.1211, 'learning_rate': 0.00017522911051212937, 'epoch': 4.32}                                                                                                      
{'loss': 0.1859, 'learning_rate': 0.00017482479784366575, 'epoch': 4.33}                                                                                                      
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                         | 3300/7620 [6:40:33<4:52:54,  4.07s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.27407974004745483, 'eval_wer': 0.2748752457281113, 'eval_cer': 0.08791941287299093, 'eval_runtime': 378.3116, 'eval_samples_per_second': 5.287, 'eval_steps_per_second': 0.661, 'epoch': 4.33}                                                                                                                                              
{'loss': 0.1769, 'learning_rate': 0.00017442048517520215, 'epoch': 4.34}                                                                                                      
{'loss': 0.1371, 'learning_rate': 0.00017401617250673853, 'epoch': 4.36}                                                                                                      
{'loss': 0.1666, 'learning_rate': 0.0001736118598382749, 'epoch': 4.37}                                                                                                       
{'loss': 0.1556, 'learning_rate': 0.0001732075471698113, 'epoch': 4.38}                                                                                                       
{'loss': 0.1697, 'learning_rate': 0.0001728032345013477, 'epoch': 4.4}                                                                                                        
{'loss': 0.1535, 'learning_rate': 0.0001723989218328841, 'epoch': 4.41}                                                                                                       
{'loss': 0.1584, 'learning_rate': 0.00017199460916442045, 'epoch': 4.42}                                                                                                      
{'loss': 0.168, 'learning_rate': 0.00017159029649595686, 'epoch': 4.44}                                                                                                       
{'loss': 0.1406, 'learning_rate': 0.00017118598382749326, 'epoch': 4.45}                                                                                                      
{'loss': 0.1639, 'learning_rate': 0.00017078167115902961, 'epoch': 4.46}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 3400/7620 [6:52:39<4:42:49,  4.02s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.28610625863075256, 'eval_wer': 0.27135944352033875, 'eval_cer': 0.085545602328919, 'eval_runtime': 369.4235, 'eval_samples_per_second': 5.414, 'eval_steps_per_second': 0.677, 'epoch': 4.46}                                                                                                                                               
{'loss': 0.1554, 'learning_rate': 0.00017037735849056602, 'epoch': 4.48}                                                                                                      
{'loss': 0.2134, 'learning_rate': 0.00016997304582210243, 'epoch': 4.49}                                                                                                      
{'loss': 0.1919, 'learning_rate': 0.0001695687331536388, 'epoch': 4.5}                                                                                                        
{'loss': 0.1451, 'learning_rate': 0.00016916442048517518, 'epoch': 4.51}                                                                                                      
{'loss': 0.1329, 'learning_rate': 0.00016876010781671156, 'epoch': 4.53}                                                                                                      
{'loss': 0.2079, 'learning_rate': 0.00016835579514824797, 'epoch': 4.54}                                                                                                      
{'loss': 0.1974, 'learning_rate': 0.00016795148247978435, 'epoch': 4.55}                                                                                                      
{'loss': 0.1803, 'learning_rate': 0.00016754716981132073, 'epoch': 4.57}                                                                                                      
{'loss': 0.1486, 'learning_rate': 0.00016714285714285713, 'epoch': 4.58}                                                                                                      
{'loss': 0.1723, 'learning_rate': 0.00016673854447439354, 'epoch': 4.59}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                     | 3500/7620 [7:04:33<4:27:20,  3.89s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.27195602655410767, 'eval_wer': 0.26856192348404656, 'eval_cer': 0.08493344488202366, 'eval_runtime': 363.4066, 'eval_samples_per_second': 5.503, 'eval_steps_per_second': 0.688, 'epoch': 4.59}                                                                                                                                             
{'loss': 0.1651, 'learning_rate': 0.0001663342318059299, 'epoch': 4.61}                                                                                                       
{'loss': 0.1698, 'learning_rate': 0.0001659299191374663, 'epoch': 4.62}                                                                                                       
{'loss': 0.1789, 'learning_rate': 0.0001655256064690027, 'epoch': 4.63}                                                                                                       
{'loss': 0.1388, 'learning_rate': 0.00016512129380053905, 'epoch': 4.65}                                                                                                      
{'loss': 0.1519, 'learning_rate': 0.00016471698113207546, 'epoch': 4.66}                                                                                                      
{'loss': 0.1563, 'learning_rate': 0.00016431266846361186, 'epoch': 4.67}                                                                                                      
{'loss': 0.1963, 'learning_rate': 0.00016390835579514824, 'epoch': 4.69}                                                                                                      
{'loss': 0.1565, 'learning_rate': 0.00016350404312668462, 'epoch': 4.7}                                                                                                       
{'loss': 0.1643, 'learning_rate': 0.000163099730458221, 'epoch': 4.71}                                                                                                        
{'loss': 0.1539, 'learning_rate': 0.0001626954177897574, 'epoch': 4.72}                                                                                                       
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                    | 3600/7620 [7:16:46<4:45:44,  4.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2555370032787323, 'eval_wer': 0.2652351429003478, 'eval_cer': 0.08371593173764293, 'eval_runtime': 390.978, 'eval_samples_per_second': 5.115, 'eval_steps_per_second': 0.639, 'epoch': 4.72}                                                                                                                                                
{'loss': 0.1376, 'learning_rate': 0.00016229110512129379, 'epoch': 4.74}                                                                                                      
{'loss': 0.2203, 'learning_rate': 0.00016188679245283016, 'epoch': 4.75}                                                                                                      
{'loss': 0.1374, 'learning_rate': 0.00016148247978436657, 'epoch': 4.76}                                                                                                      
{'loss': 0.1536, 'learning_rate': 0.00016107816711590298, 'epoch': 4.78}                                                                                                      
{'loss': 0.1406, 'learning_rate': 0.00016067385444743933, 'epoch': 4.79}                                                                                                      
{'loss': 0.1911, 'learning_rate': 0.00016026954177897573, 'epoch': 4.8}                                                                                                       
{'loss': 0.1929, 'learning_rate': 0.00015986522911051214, 'epoch': 4.82}                                                                                                      
{'loss': 0.1617, 'learning_rate': 0.0001594609164420485, 'epoch': 4.83}                                                                                                       
{'loss': 0.1155, 'learning_rate': 0.0001590566037735849, 'epoch': 4.84}                                                                                                       
{'loss': 0.1631, 'learning_rate': 0.00015865229110512128, 'epoch': 4.86}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 3700/7620 [7:29:12<4:32:06,  4.17s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2571773827075958, 'eval_wer': 0.2709435959473764, 'eval_cer': 0.08606933703348502, 'eval_runtime': 383.1409, 'eval_samples_per_second': 5.22, 'eval_steps_per_second': 0.653, 'epoch': 4.86}                                                                                                                                                
{'loss': 0.1846, 'learning_rate': 0.00015824797843665765, 'epoch': 4.87}                                                                                                      
{'loss': 0.1587, 'learning_rate': 0.00015784366576819406, 'epoch': 4.88}                                                                                                      
{'loss': 0.1386, 'learning_rate': 0.00015743935309973044, 'epoch': 4.9}                                                                                                       
{'loss': 0.1472, 'learning_rate': 0.00015703504043126684, 'epoch': 4.91}                                                                                                      
{'loss': 0.128, 'learning_rate': 0.0001566307277628032, 'epoch': 4.92}                                                                                                        
{'loss': 0.1386, 'learning_rate': 0.0001562264150943396, 'epoch': 4.93}                                                                                                       
{'loss': 0.1455, 'learning_rate': 0.000155822102425876, 'epoch': 4.95}                                                                                                        
{'loss': 0.129, 'learning_rate': 0.00015541778975741236, 'epoch': 4.96}                                                                                                       
{'loss': 0.1517, 'learning_rate': 0.00015501347708894877, 'epoch': 4.97}                                                                                                      
{'loss': 0.1637, 'learning_rate': 0.00015460916442048517, 'epoch': 4.99}                                                                                                      
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                | 3800/7620 [7:41:52<4:50:38,  4.57s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2686363458633423, 'eval_wer': 0.2634961439588689, 'eval_cer': 0.08429408043748852, 'eval_runtime': 388.8609, 'eval_samples_per_second': 5.143, 'eval_steps_per_second': 0.643, 'epoch': 4.99}                                                                                                                                               
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 3805/7620 [7:48:38<33:19:41, 31.45s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-3805                                                                                                  
Configuration saved in spanish_portuguese_high_augmented/checkpoint-3805/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-3805/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-3805/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1567, 'learning_rate': 0.00015420485175202155, 'epoch': 5.0}                                                                                                       
{'loss': 0.1332, 'learning_rate': 0.00015380053908355793, 'epoch': 5.01}                                                                                                      
{'loss': 0.2049, 'learning_rate': 0.00015339622641509433, 'epoch': 5.03}                                                                                                      
{'loss': 0.1191, 'learning_rate': 0.00015299191374663071, 'epoch': 5.04}                                                                                                      
{'loss': 0.1116, 'learning_rate': 0.0001525876010781671, 'epoch': 5.05}                                                                                                       
{'loss': 0.1023, 'learning_rate': 0.0001521832884097035, 'epoch': 5.07}                                                                                                       
{'loss': 0.1585, 'learning_rate': 0.00015177897574123988, 'epoch': 5.08}                                                                                                      
{'loss': 0.1486, 'learning_rate': 0.00015137466307277628, 'epoch': 5.09}                                                                                                      
{'loss': 0.1263, 'learning_rate': 0.00015097035040431263, 'epoch': 5.1}                                                                                                       
{'loss': 0.1127, 'learning_rate': 0.00015056603773584904, 'epoch': 5.12}                                                                                                      
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 3900/7620 [7:54:42<3:05:57,  3.00s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2746115028858185, 'eval_wer': 0.2605852109481325, 'eval_cer': 0.08491303963379382, 'eval_runtime': 372.2739, 'eval_samples_per_second': 5.372, 'eval_steps_per_second': 0.672, 'epoch': 5.12}                                                                                                                                               
{'loss': 0.1318, 'learning_rate': 0.00015016172506738545, 'epoch': 5.13}                                                                                                      
{'loss': 0.1695, 'learning_rate': 0.00014975741239892182, 'epoch': 5.14}                                                                                                      
{'loss': 0.1106, 'learning_rate': 0.0001493530997304582, 'epoch': 5.16}                                                                                                       
{'loss': 0.1651, 'learning_rate': 0.0001489487870619946, 'epoch': 5.17}                                                                                                       
{'loss': 0.1436, 'learning_rate': 0.000148544474393531, 'epoch': 5.18}                                                                                                        
{'loss': 0.1429, 'learning_rate': 0.00014814016172506737, 'epoch': 5.2}                                                                                                       
{'loss': 0.1335, 'learning_rate': 0.00014773584905660377, 'epoch': 5.21}                                                                                                      
{'loss': 0.1426, 'learning_rate': 0.00014733153638814015, 'epoch': 5.22}                                                                                                      
{'loss': 0.1384, 'learning_rate': 0.00014692722371967653, 'epoch': 5.24}                                                                                                      
{'loss': 0.1385, 'learning_rate': 0.0001465229110512129, 'epoch': 5.25}                                                                                                       
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                             | 4000/7620 [8:06:31<2:47:27,  2.78s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2840847074985504, 'eval_wer': 0.2679948586118252, 'eval_cer': 0.08693315920854844, 'eval_runtime': 367.7679, 'eval_samples_per_second': 5.438, 'eval_steps_per_second': 0.68, 'epoch': 5.25}                                                                                                                                                
{'loss': 0.1222, 'learning_rate': 0.00014611859838274932, 'epoch': 5.26}                                                                                                      
{'loss': 0.1451, 'learning_rate': 0.0001457142857142857, 'epoch': 5.28}                                                                                                       
{'loss': 0.1352, 'learning_rate': 0.0001453099730458221, 'epoch': 5.29}                                                                                                       
{'loss': 0.1514, 'learning_rate': 0.00014490566037735848, 'epoch': 5.3}                                                                                                       
{'loss': 0.1264, 'learning_rate': 0.00014450134770889486, 'epoch': 5.31}                                                                                                      
{'loss': 0.1225, 'learning_rate': 0.00014409703504043126, 'epoch': 5.33}                                                                                                      
{'loss': 0.1232, 'learning_rate': 0.00014369272237196764, 'epoch': 5.34}                                                                                                      
{'loss': 0.1514, 'learning_rate': 0.00014328840970350405, 'epoch': 5.35}                                                                                                      
{'loss': 0.1538, 'learning_rate': 0.00014288409703504043, 'epoch': 5.37}                                                                                                      
{'loss': 0.1296, 'learning_rate': 0.0001424797843665768, 'epoch': 5.38}                                                                                                       
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 4100/7620 [8:18:11<2:45:49,  2.83s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2628985047340393, 'eval_wer': 0.2607742325722063, 'eval_cer': 0.08451853816801681, 'eval_runtime': 359.3773, 'eval_samples_per_second': 5.565, 'eval_steps_per_second': 0.696, 'epoch': 5.38}                                                                                                                                               
{'loss': 0.1353, 'learning_rate': 0.00014207547169811318, 'epoch': 5.39}                                                                                                      
{'loss': 0.1513, 'learning_rate': 0.0001416711590296496, 'epoch': 5.41}                                                                                                       
{'loss': 0.1504, 'learning_rate': 0.00014126684636118597, 'epoch': 5.42}                                                                                                      
{'loss': 0.1338, 'learning_rate': 0.00014086253369272235, 'epoch': 5.43}                                                                                                      
{'loss': 0.1185, 'learning_rate': 0.00014045822102425875, 'epoch': 5.45}                                                                                                      
{'loss': 0.0998, 'learning_rate': 0.00014005390835579513, 'epoch': 5.46}                                                                                                      
{'loss': 0.1447, 'learning_rate': 0.0001396495956873315, 'epoch': 5.47}                                                                                                       
{'loss': 0.1365, 'learning_rate': 0.00013924528301886792, 'epoch': 5.49}                                                                                                      
{'loss': 0.1464, 'learning_rate': 0.0001388409703504043, 'epoch': 5.5}                                                                                                        
{'loss': 0.112, 'learning_rate': 0.0001384366576819407, 'epoch': 5.51}                                                                                                        
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 4200/7620 [8:29:50<2:46:55,  2.93s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2678402066230774, 'eval_wer': 0.2582413428096174, 'eval_cer': 0.0822467538650941, 'eval_runtime': 364.9035, 'eval_samples_per_second': 5.481, 'eval_steps_per_second': 0.685, 'epoch': 5.51}                                                                                                                                                
{'loss': 0.1337, 'learning_rate': 0.00013803234501347708, 'epoch': 5.52}                                                                                                      
{'loss': 0.1241, 'learning_rate': 0.00013762803234501349, 'epoch': 5.54}                                                                                                      
{'loss': 0.1661, 'learning_rate': 0.00013722371967654986, 'epoch': 5.55}                                                                                                      
{'loss': 0.1385, 'learning_rate': 0.00013681940700808624, 'epoch': 5.56}                                                                                                      
{'loss': 0.1019, 'learning_rate': 0.00013641509433962262, 'epoch': 5.58}                                                                                                      
{'loss': 0.1169, 'learning_rate': 0.000136010781671159, 'epoch': 5.59}                                                                                                        
{'loss': 0.1578, 'learning_rate': 0.0001356064690026954, 'epoch': 5.6}                                                                                                        
{'loss': 0.1502, 'learning_rate': 0.00013520215633423179, 'epoch': 5.62}                                                                                                      
{'loss': 0.146, 'learning_rate': 0.0001347978436657682, 'epoch': 5.63}                                                                                                        
{'loss': 0.1149, 'learning_rate': 0.00013439353099730457, 'epoch': 5.64}                                                                                                      
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 4300/7620 [8:41:36<2:40:11,  2.90s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2651519775390625, 'eval_wer': 0.25536821412369576, 'eval_cer': 0.081076852966583, 'eval_runtime': 378.9165, 'eval_samples_per_second': 5.278, 'eval_steps_per_second': 0.66, 'epoch': 5.64}                                                                                                                                                 
{'loss': 0.0983, 'learning_rate': 0.00013398921832884095, 'epoch': 5.66}                                                                                                      
{'loss': 0.1572, 'learning_rate': 0.00013358490566037735, 'epoch': 5.67}                                                                                                      
{'loss': 0.1496, 'learning_rate': 0.00013318059299191373, 'epoch': 5.68}                                                                                                      
{'loss': 0.0994, 'learning_rate': 0.00013277628032345014, 'epoch': 5.7}                                                                                                       
{'loss': 0.1078, 'learning_rate': 0.00013237196765498652, 'epoch': 5.71}                                                                                                      
{'loss': 0.105, 'learning_rate': 0.0001319676549865229, 'epoch': 5.72}                                                                                                        
{'loss': 0.1727, 'learning_rate': 0.0001315633423180593, 'epoch': 5.73}                                                                                                       
{'loss': 0.1534, 'learning_rate': 0.00013115902964959568, 'epoch': 5.75}                                                                                                      
{'loss': 0.1147, 'learning_rate': 0.00013075471698113206, 'epoch': 5.76}                                                                                                      
{'loss': 0.0929, 'learning_rate': 0.00013035040431266844, 'epoch': 5.77}                                                                                                      
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 4400/7620 [8:53:35<2:33:38,  2.86s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26437413692474365, 'eval_wer': 0.257523060638137, 'eval_cer': 0.08156657892409928, 'eval_runtime': 379.6012, 'eval_samples_per_second': 5.269, 'eval_steps_per_second': 0.659, 'epoch': 5.77}                                                                                                                                               
{'loss': 0.122, 'learning_rate': 0.00012994609164420484, 'epoch': 5.79}                                                                                                       
{'loss': 0.1162, 'learning_rate': 0.00012954177897574122, 'epoch': 5.8}                                                                                                       
{'loss': 0.1332, 'learning_rate': 0.0001291374663072776, 'epoch': 5.81}                                                                                                       
{'loss': 0.1103, 'learning_rate': 0.000128733153638814, 'epoch': 5.83}                                                                                                        
{'loss': 0.0942, 'learning_rate': 0.0001283288409703504, 'epoch': 5.84}                                                                                                       
{'loss': 0.112, 'learning_rate': 0.0001279245283018868, 'epoch': 5.85}                                                                                                        
{'loss': 0.1098, 'learning_rate': 0.00012752021563342317, 'epoch': 5.87}                                                                                                      
{'loss': 0.101, 'learning_rate': 0.00012711590296495958, 'epoch': 5.88}                                                                                                       
{'loss': 0.1188, 'learning_rate': 0.00012671159029649596, 'epoch': 5.89}                                                                                                      
{'loss': 0.1204, 'learning_rate': 0.00012630727762803233, 'epoch': 5.91}                                                                                                      
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 4500/7620 [9:05:12<2:21:53,  2.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.267184853553772, 'eval_wer': 0.2537426281566611, 'eval_cer': 0.08093401622897409, 'eval_runtime': 346.9668, 'eval_samples_per_second': 5.764, 'eval_steps_per_second': 0.721, 'epoch': 5.91}                                                                                                                                                
{'loss': 0.1349, 'learning_rate': 0.0001259029649595687, 'epoch': 5.92}                                                                                                       
{'loss': 0.155, 'learning_rate': 0.00012549865229110512, 'epoch': 5.93}                                                                                                       
{'loss': 0.1382, 'learning_rate': 0.0001250943396226415, 'epoch': 5.94}                                                                                                       
{'loss': 0.1308, 'learning_rate': 0.00012469002695417788, 'epoch': 5.96}                                                                                                      
{'loss': 0.136, 'learning_rate': 0.00012428571428571428, 'epoch': 5.97}                                                                                                       
{'loss': 0.1105, 'learning_rate': 0.00012388140161725066, 'epoch': 5.98}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                   | 4566/7620 [9:14:29<2:50:51,  3.36s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-4566
Configuration saved in spanish_portuguese_high_augmented/checkpoint-4566/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-4566/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-4566/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1426, 'learning_rate': 0.00012347708894878704, 'epoch': 6.0}                                                                                                       
{'loss': 0.0958, 'learning_rate': 0.00012307277628032345, 'epoch': 6.01}                                                                                                      
{'loss': 0.123, 'learning_rate': 0.00012266846361185982, 'epoch': 6.02}                                                                                                       
{'loss': 0.102, 'learning_rate': 0.00012226415094339623, 'epoch': 6.04}                                                                                                       
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 4600/7620 [9:16:48<2:38:28,  3.15s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.27131348848342896, 'eval_wer': 0.25517919249962195, 'eval_cer': 0.08314458478720727, 'eval_runtime': 348.8209, 'eval_samples_per_second': 5.734, 'eval_steps_per_second': 0.717, 'epoch': 6.04}                                                                                                                                             
{'loss': 0.0988, 'learning_rate': 0.00012185983827493261, 'epoch': 6.05}                                                                                                      
{'loss': 0.0844, 'learning_rate': 0.00012145552560646899, 'epoch': 6.06}                                                                                                      
{'loss': 0.1531, 'learning_rate': 0.00012105121293800538, 'epoch': 6.08}                                                                                                      
{'loss': 0.1281, 'learning_rate': 0.00012064690026954176, 'epoch': 6.09}                                                                                                      
{'loss': 0.126, 'learning_rate': 0.00012024258760107816, 'epoch': 6.1}                                                                                                        
{'loss': 0.1177, 'learning_rate': 0.00011983827493261454, 'epoch': 6.12}                                                                                                      
{'loss': 0.08, 'learning_rate': 0.00011943396226415094, 'epoch': 6.13}                                                                                                        
{'loss': 0.1495, 'learning_rate': 0.00011902964959568731, 'epoch': 6.14}                                                                                                      
{'loss': 0.1053, 'learning_rate': 0.00011862533692722371, 'epoch': 6.15}                                                                                                      
{'loss': 0.0931, 'learning_rate': 0.0001182210242587601, 'epoch': 6.17}                                                                                                       
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 4700/7620 [9:28:06<2:33:52,  3.16s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2589174807071686, 'eval_wer': 0.2503024345985181, 'eval_cer': 0.07978452057869284, 'eval_runtime': 435.1763, 'eval_samples_per_second': 4.596, 'eval_steps_per_second': 0.574, 'epoch': 6.17}                                                                                                                                               
{'loss': 0.1197, 'learning_rate': 0.00011781671159029648, 'epoch': 6.18}                                                                                                      
{'loss': 0.1042, 'learning_rate': 0.00011741239892183288, 'epoch': 6.19}                                                                                                      
{'loss': 0.0961, 'learning_rate': 0.00011700808625336926, 'epoch': 6.21}                                                                                                      
{'loss': 0.1226, 'learning_rate': 0.00011660377358490566, 'epoch': 6.22}                                                                                                      
{'loss': 0.1415, 'learning_rate': 0.00011619946091644203, 'epoch': 6.23}                                                                                                      
{'loss': 0.1354, 'learning_rate': 0.00011579514824797843, 'epoch': 6.25}                                                                                                      
{'loss': 0.0888, 'learning_rate': 0.00011539083557951482, 'epoch': 6.26}                                                                                                      
{'loss': 0.1129, 'learning_rate': 0.0001149865229110512, 'epoch': 6.27}                                                                                                       
{'loss': 0.1136, 'learning_rate': 0.0001145822102425876, 'epoch': 6.29}                                                                                                       
{'loss': 0.1022, 'learning_rate': 0.00011417789757412398, 'epoch': 6.3}                                                                                                       
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 4800/7620 [9:41:14<2:24:58,  3.08s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2547745406627655, 'eval_wer': 0.2530999546348102, 'eval_cer': 0.08023343603974942, 'eval_runtime': 333.5089, 'eval_samples_per_second': 5.997, 'eval_steps_per_second': 0.75, 'epoch': 6.3}                                                                                                                                                 
{'loss': 0.156, 'learning_rate': 0.00011377358490566037, 'epoch': 6.31}                                                                                                       
{'loss': 0.0974, 'learning_rate': 0.00011336927223719675, 'epoch': 6.33}                                                                                                      
{'loss': 0.1321, 'learning_rate': 0.00011296495956873313, 'epoch': 6.34}                                                                                                      
{'loss': 0.1265, 'learning_rate': 0.00011256064690026954, 'epoch': 6.35}                                                                                                      
{'loss': 0.1094, 'learning_rate': 0.00011215633423180592, 'epoch': 6.36}                                                                                                      
{'loss': 0.0855, 'learning_rate': 0.00011175202156334231, 'epoch': 6.38}                                                                                                      
{'loss': 0.0715, 'learning_rate': 0.0001113477088948787, 'epoch': 6.39}                                                                                                       
{'loss': 0.09, 'learning_rate': 0.00011094339622641508, 'epoch': 6.4}                                                                                                         
{'loss': 0.0997, 'learning_rate': 0.00011053908355795147, 'epoch': 6.42}                                                                                                      
{'loss': 0.1128, 'learning_rate': 0.00011013477088948785, 'epoch': 6.43}                                                                                                      
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 4900/7620 [9:52:02<2:13:19,  2.94s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2569761276245117, 'eval_wer': 0.252192650839256, 'eval_cer': 0.08214472762394488, 'eval_runtime': 334.5764, 'eval_samples_per_second': 5.978, 'eval_steps_per_second': 0.747, 'epoch': 6.43}                                                                                                                                                
{'loss': 0.0889, 'learning_rate': 0.00010973045822102426, 'epoch': 6.44}                                                                                                      
{'loss': 0.1467, 'learning_rate': 0.00010932614555256064, 'epoch': 6.46}                                                                                                      
{'loss': 0.115, 'learning_rate': 0.00010892183288409703, 'epoch': 6.47}                                                                                                       
{'loss': 0.085, 'learning_rate': 0.00010851752021563342, 'epoch': 6.48}                                                                                                       
{'loss': 0.1145, 'learning_rate': 0.0001081132075471698, 'epoch': 6.5}                                                                                                        
{'loss': 0.1122, 'learning_rate': 0.00010770889487870619, 'epoch': 6.51}                                                                                                      
{'loss': 0.0983, 'learning_rate': 0.00010730458221024257, 'epoch': 6.52}                                                                                                      
{'loss': 0.1104, 'learning_rate': 0.00010690026954177898, 'epoch': 6.54}                                                                                                      
{'loss': 0.0975, 'learning_rate': 0.00010649595687331535, 'epoch': 6.55}                                                                                                      
{'loss': 0.1116, 'learning_rate': 0.00010609164420485175, 'epoch': 6.56}                                                                                                      
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                            | 5000/7620 [10:02:56<2:17:35,  3.15s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2638322114944458, 'eval_wer': 0.25, 'eval_cer': 0.0826684623285109, 'eval_runtime': 349.3631, 'eval_samples_per_second': 5.725, 'eval_steps_per_second': 0.716, 'epoch': 6.56}                                                                                                                                                              
{'loss': 0.092, 'learning_rate': 0.00010568733153638813, 'epoch': 6.57}                                                                                                       
{'loss': 0.0922, 'learning_rate': 0.00010528301886792452, 'epoch': 6.59}                                                                                                      
{'loss': 0.107, 'learning_rate': 0.00010487870619946091, 'epoch': 6.6}                                                                                                        
{'loss': 0.1197, 'learning_rate': 0.00010447439353099729, 'epoch': 6.61}                                                                                                      
{'loss': 0.1001, 'learning_rate': 0.0001040700808625337, 'epoch': 6.63}                                                                                                       
{'loss': 0.1026, 'learning_rate': 0.00010366576819407007, 'epoch': 6.64}                                                                                                      
{'loss': 0.0769, 'learning_rate': 0.00010326145552560647, 'epoch': 6.65}                                                                                                      
{'loss': 0.1231, 'learning_rate': 0.00010285714285714284, 'epoch': 6.67}                                                                                                      
{'loss': 0.1153, 'learning_rate': 0.00010245283018867924, 'epoch': 6.68}                                                                                                      
{'loss': 0.1041, 'learning_rate': 0.00010204851752021563, 'epoch': 6.69}                                                                                                      
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                          | 5100/7620 [10:14:05<2:06:41,  3.02s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2535499930381775, 'eval_wer': 0.24810978375926207, 'eval_cer': 0.08073676549608559, 'eval_runtime': 344.4707, 'eval_samples_per_second': 5.806, 'eval_steps_per_second': 0.726, 'epoch': 6.69}                                                                                                                                              
{'loss': 0.1011, 'learning_rate': 0.00010164420485175201, 'epoch': 6.71}                                                                                                      
{'loss': 0.0916, 'learning_rate': 0.00010123989218328841, 'epoch': 6.72}                                                                                                      
{'loss': 0.1506, 'learning_rate': 0.00010083557951482479, 'epoch': 6.73}                                                                                                      
{'loss': 0.1223, 'learning_rate': 0.00010043126684636117, 'epoch': 6.75}                                                                                                      
{'loss': 0.1165, 'learning_rate': 0.00010002695417789756, 'epoch': 6.76}                                                                                                      
{'loss': 0.1104, 'learning_rate': 9.962264150943394e-05, 'epoch': 6.77}                                                                                                       
{'loss': 0.0774, 'learning_rate': 9.921832884097035e-05, 'epoch': 6.78}                                                                                                       
{'loss': 0.1595, 'learning_rate': 9.881401617250673e-05, 'epoch': 6.8}                                                                                                        
{'loss': 0.0954, 'learning_rate': 9.840970350404312e-05, 'epoch': 6.81}                                                                                                       
{'loss': 0.0858, 'learning_rate': 9.800539083557951e-05, 'epoch': 6.82}                                                                                                       
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                        | 5200/7620 [10:24:59<2:03:56,  3.07s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2562722861766815, 'eval_wer': 0.24674882806593074, 'eval_cer': 0.07835615320260371, 'eval_runtime': 352.0339, 'eval_samples_per_second': 5.681, 'eval_steps_per_second': 0.71, 'epoch': 6.82}                                                                                                                                               
{'loss': 0.1337, 'learning_rate': 9.760107816711589e-05, 'epoch': 6.84}                                                                                                       
{'loss': 0.1644, 'learning_rate': 9.719676549865228e-05, 'epoch': 6.85}                                                                                                       
{'loss': 0.0825, 'learning_rate': 9.679245283018866e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.1067, 'learning_rate': 9.638814016172507e-05, 'epoch': 6.88}                                                                                                       
{'loss': 0.089, 'learning_rate': 9.598382749326145e-05, 'epoch': 6.89}                                                                                                        
{'loss': 0.1135, 'learning_rate': 9.557951482479784e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.0868, 'learning_rate': 9.517520215633423e-05, 'epoch': 6.92}                                                                                                       
{'loss': 0.1075, 'learning_rate': 9.477088948787061e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1106, 'learning_rate': 9.4366576819407e-05, 'epoch': 6.94}                                                                                                         
{'loss': 0.1026, 'learning_rate': 9.396226415094338e-05, 'epoch': 6.96}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                       | 5300/7620 [10:36:14<2:00:05,  3.11s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.24374985694885254, 'eval_wer': 0.24637078481778316, 'eval_cer': 0.07843097244611313, 'eval_runtime': 340.4425, 'eval_samples_per_second': 5.875, 'eval_steps_per_second': 0.734, 'epoch': 6.96}                                                                                                                                             
{'loss': 0.0882, 'learning_rate': 9.355795148247979e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.0892, 'learning_rate': 9.315363881401616e-05, 'epoch': 6.98}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 5327/7620 [10:43:13<2:15:18,  3.54s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-5327
Configuration saved in spanish_portuguese_high_augmented/checkpoint-5327/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-5327/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-5327/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1288, 'learning_rate': 9.274932614555256e-05, 'epoch': 6.99}                                                                                                       
{'loss': 0.1138, 'learning_rate': 9.234501347708894e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.0937, 'learning_rate': 9.194070080862533e-05, 'epoch': 7.02}                                                                                                       
{'loss': 0.1035, 'learning_rate': 9.153638814016172e-05, 'epoch': 7.03}                                                                                                       
{'loss': 0.0728, 'learning_rate': 9.11320754716981e-05, 'epoch': 7.05}                                                                                                        
{'loss': 0.0866, 'learning_rate': 9.07277628032345e-05, 'epoch': 7.06}                                                                                                        
{'loss': 0.0881, 'learning_rate': 9.032345013477088e-05, 'epoch': 7.07}                                                                                                       
{'loss': 0.0853, 'learning_rate': 8.991913746630726e-05, 'epoch': 7.09}                                                                                                       
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                     | 5400/7620 [10:47:55<2:56:33,  4.77s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2596052885055542, 'eval_wer': 0.24780734916074398, 'eval_cer': 0.0785534039354922, 'eval_runtime': 411.3477, 'eval_samples_per_second': 4.862, 'eval_steps_per_second': 0.608, 'epoch': 7.09}                                                                                                                                               
{'loss': 0.1147, 'learning_rate': 8.951482479784365e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1014, 'learning_rate': 8.911051212938005e-05, 'epoch': 7.11}                                                                                                       
{'loss': 0.0778, 'learning_rate': 8.870619946091644e-05, 'epoch': 7.13}                                                                                                       
{'loss': 0.1095, 'learning_rate': 8.830188679245282e-05, 'epoch': 7.14}                                                                                                       
{'loss': 0.1046, 'learning_rate': 8.789757412398922e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.0856, 'learning_rate': 8.74932614555256e-05, 'epoch': 7.17}                                                                                                        
{'loss': 0.0943, 'learning_rate': 8.708894878706198e-05, 'epoch': 7.18}                                                                                                       
{'loss': 0.0665, 'learning_rate': 8.668463611859837e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.0973, 'learning_rate': 8.628032345013475e-05, 'epoch': 7.2}                                                                                                        
{'loss': 0.1144, 'learning_rate': 8.587601078167116e-05, 'epoch': 7.22}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 5500/7620 [11:00:35<2:08:37,  3.64s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2546943128108978, 'eval_wer': 0.24126720096779072, 'eval_cer': 0.07578509192564327, 'eval_runtime': 346.0983, 'eval_samples_per_second': 5.779, 'eval_steps_per_second': 0.722, 'epoch': 7.22}                                                                                                                                              
{'loss': 0.0877, 'learning_rate': 8.547169811320754e-05, 'epoch': 7.23}                                                                                                       
{'loss': 0.0683, 'learning_rate': 8.506738544474393e-05, 'epoch': 7.24}                                                                                                       
{'loss': 0.0799, 'learning_rate': 8.466307277628032e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.1005, 'learning_rate': 8.42587601078167e-05, 'epoch': 7.27}                                                                                                        
{'loss': 0.0838, 'learning_rate': 8.385444743935309e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.0847, 'learning_rate': 8.345013477088947e-05, 'epoch': 7.3}                                                                                                        
{'loss': 0.0852, 'learning_rate': 8.304582210242588e-05, 'epoch': 7.31}                                                                                                       
{'loss': 0.1094, 'learning_rate': 8.264150943396226e-05, 'epoch': 7.32}                                                                                                       
{'loss': 0.0842, 'learning_rate': 8.223719676549865e-05, 'epoch': 7.34}                                                                                                       
{'loss': 0.1168, 'learning_rate': 8.183288409703504e-05, 'epoch': 7.35}                                                                                                       
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 5600/7620 [11:11:46<2:02:09,  3.63s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25688230991363525, 'eval_wer': 0.2422879177377892, 'eval_cer': 0.07614558464437053, 'eval_runtime': 341.2938, 'eval_samples_per_second': 5.86, 'eval_steps_per_second': 0.733, 'epoch': 7.35}                                                                                                                                               
{'loss': 0.0895, 'learning_rate': 8.142857142857142e-05, 'epoch': 7.36}                                                                                                       
{'loss': 0.1008, 'learning_rate': 8.102425876010781e-05, 'epoch': 7.38}                                                                                                       
{'loss': 0.0642, 'learning_rate': 8.061994609164419e-05, 'epoch': 7.39}                                                                                                       
{'loss': 0.0947, 'learning_rate': 8.02156334231806e-05, 'epoch': 7.4}                                                                                                         
{'loss': 0.0914, 'learning_rate': 7.981132075471698e-05, 'epoch': 7.41}                                                                                                       
{'loss': 0.0818, 'learning_rate': 7.940700808625335e-05, 'epoch': 7.43}                                                                                                       
{'loss': 0.0869, 'learning_rate': 7.900269541778975e-05, 'epoch': 7.44}                                                                                                       
{'loss': 0.0628, 'learning_rate': 7.859838274932614e-05, 'epoch': 7.45}                                                                                                       
{'loss': 0.0727, 'learning_rate': 7.819407008086253e-05, 'epoch': 7.47}                                                                                                       
{'loss': 0.093, 'learning_rate': 7.778975741239891e-05, 'epoch': 7.48}                                                                                                        
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                | 5700/7620 [11:22:53<2:02:50,  3.84s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.257347971200943, 'eval_wer': 0.24047331014668077, 'eval_cer': 0.0758871181667925, 'eval_runtime': 371.7181, 'eval_samples_per_second': 5.38, 'eval_steps_per_second': 0.673, 'epoch': 7.48}                                                                                                                                                 
{'loss': 0.0998, 'learning_rate': 7.738544474393532e-05, 'epoch': 7.49}                                                                                                       
{'loss': 0.0918, 'learning_rate': 7.69811320754717e-05, 'epoch': 7.51}                                                                                                        
{'loss': 0.0841, 'learning_rate': 7.657681940700807e-05, 'epoch': 7.52}                                                                                                       
{'loss': 0.1044, 'learning_rate': 7.617250673854447e-05, 'epoch': 7.53}                                                                                                       
{'loss': 0.1148, 'learning_rate': 7.576819407008086e-05, 'epoch': 7.55}                                                                                                       
{'loss': 0.1055, 'learning_rate': 7.536388140161725e-05, 'epoch': 7.56}                                                                                                       
{'loss': 0.0867, 'learning_rate': 7.495956873315363e-05, 'epoch': 7.57}                                                                                                       
{'loss': 0.0622, 'learning_rate': 7.455525606469002e-05, 'epoch': 7.59}                                                                                                       
{'loss': 0.1101, 'learning_rate': 7.415094339622641e-05, 'epoch': 7.6}                                                                                                        
{'loss': 0.0898, 'learning_rate': 7.374663072776279e-05, 'epoch': 7.61}                                                                                                       
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 5800/7620 [11:34:38<1:48:07,  3.56s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25137796998023987, 'eval_wer': 0.2399062452744594, 'eval_cer': 0.07600954965617157, 'eval_runtime': 347.7345, 'eval_samples_per_second': 5.752, 'eval_steps_per_second': 0.719, 'epoch': 7.61}                                                                                                                                              
{'loss': 0.0905, 'learning_rate': 7.334231805929918e-05, 'epoch': 7.62}                                                                                                       
{'loss': 0.0832, 'learning_rate': 7.293800539083558e-05, 'epoch': 7.64}                                                                                                       
{'loss': 0.0694, 'learning_rate': 7.253369272237196e-05, 'epoch': 7.65}                                                                                                       
{'loss': 0.1095, 'learning_rate': 7.212938005390835e-05, 'epoch': 7.66}                                                                                                       
{'loss': 0.0941, 'learning_rate': 7.172506738544474e-05, 'epoch': 7.68}                                                                                                       
{'loss': 0.098, 'learning_rate': 7.132075471698113e-05, 'epoch': 7.69}                                                                                                        
{'loss': 0.0762, 'learning_rate': 7.091644204851751e-05, 'epoch': 7.7}                                                                                                        
{'loss': 0.079, 'learning_rate': 7.05121293800539e-05, 'epoch': 7.72}                                                                                                         
{'loss': 0.1239, 'learning_rate': 7.010781671159028e-05, 'epoch': 7.73}                                                                                                       
{'loss': 0.0955, 'learning_rate': 6.970350404312667e-05, 'epoch': 7.74}                                                                                                       
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 5900/7620 [11:45:51<1:44:26,  3.64s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2570047378540039, 'eval_wer': 0.24304400423408437, 'eval_cer': 0.07744471878167064, 'eval_runtime': 341.0165, 'eval_samples_per_second': 5.865, 'eval_steps_per_second': 0.733, 'epoch': 7.74}                                                                                                                                              
{'loss': 0.096, 'learning_rate': 6.929919137466307e-05, 'epoch': 7.76}                                                                                                        
{'loss': 0.1046, 'learning_rate': 6.889487870619946e-05, 'epoch': 7.77}                                                                                                       
{'loss': 0.0637, 'learning_rate': 6.849056603773585e-05, 'epoch': 7.78}                                                                                                       
{'loss': 0.1197, 'learning_rate': 6.808625336927223e-05, 'epoch': 7.8}                                                                                                        
{'loss': 0.1012, 'learning_rate': 6.768194070080862e-05, 'epoch': 7.81}                                                                                                       
{'loss': 0.0805, 'learning_rate': 6.7277628032345e-05, 'epoch': 7.82}                                                                                                         
{'loss': 0.0861, 'learning_rate': 6.68733153638814e-05, 'epoch': 7.83}                                                                                                        
{'loss': 0.0647, 'learning_rate': 6.646900269541779e-05, 'epoch': 7.85}                                                                                                       
{'loss': 0.0879, 'learning_rate': 6.606469002695418e-05, 'epoch': 7.86}                                                                                                       
{'loss': 0.117, 'learning_rate': 6.566037735849056e-05, 'epoch': 7.87}                                                                                                        
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 6000/7620 [11:56:49<1:38:03,  3.63s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2511013150215149, 'eval_wer': 0.23850748525631332, 'eval_cer': 0.07719985580291251, 'eval_runtime': 346.0653, 'eval_samples_per_second': 5.779, 'eval_steps_per_second': 0.722, 'epoch': 7.87}                                                                                                                                              
{'loss': 0.0946, 'learning_rate': 6.525606469002695e-05, 'epoch': 7.89}                                                                                                       
{'loss': 0.0854, 'learning_rate': 6.485175202156333e-05, 'epoch': 7.9}                                                                                                        
{'loss': 0.0991, 'learning_rate': 6.444743935309972e-05, 'epoch': 7.91}                                                                                                       
{'loss': 0.0922, 'learning_rate': 6.404312668463611e-05, 'epoch': 7.93}                                                                                                       
{'loss': 0.0992, 'learning_rate': 6.36388140161725e-05, 'epoch': 7.94}                                                                                                        
{'loss': 0.0811, 'learning_rate': 6.32345013477089e-05, 'epoch': 7.95}                                                                                                        
{'loss': 0.0987, 'learning_rate': 6.283018867924528e-05, 'epoch': 7.97}                                                                                                       
{'loss': 0.0486, 'learning_rate': 6.242587601078167e-05, 'epoch': 7.98}                                                                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 6088/7620 [12:07:19<1:28:31,  3.47s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-6088
Configuration saved in spanish_portuguese_high_augmented/checkpoint-6088/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-6088/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-6088/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1274, 'learning_rate': 6.202156334231805e-05, 'epoch': 7.99}                                                                                                       
{'loss': 0.1073, 'learning_rate': 6.161725067385444e-05, 'epoch': 8.01}                                                                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 6100/7620 [12:08:12<1:47:41,  4.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.24849925935268402, 'eval_wer': 0.2375245728111296, 'eval_cer': 0.07617279164201032, 'eval_runtime': 356.53, 'eval_samples_per_second': 5.61, 'eval_steps_per_second': 0.701, 'epoch': 8.01}                                                                                                                                                 
{'loss': 0.0826, 'learning_rate': 6.121293800539083e-05, 'epoch': 8.02}                                                                                                       
{'loss': 0.086, 'learning_rate': 6.080862533692722e-05, 'epoch': 8.03}                                                                                                        
{'loss': 0.0885, 'learning_rate': 6.040431266846361e-05, 'epoch': 8.04}                                                                                                       
{'loss': 0.0671, 'learning_rate': 5.9999999999999995e-05, 'epoch': 8.06}                                                                                                      
{'loss': 0.0824, 'learning_rate': 5.959568733153638e-05, 'epoch': 8.07}                                                                                                       
{'loss': 0.0851, 'learning_rate': 5.9191374663072766e-05, 'epoch': 8.08}                                                                                                      
{'loss': 0.1091, 'learning_rate': 5.878706199460916e-05, 'epoch': 8.1}                                                                                                        
{'loss': 0.0806, 'learning_rate': 5.838274932614555e-05, 'epoch': 8.11}                                                                                                       
{'loss': 0.0846, 'learning_rate': 5.7978436657681936e-05, 'epoch': 8.12}                                                                                                      
{'loss': 0.0908, 'learning_rate': 5.757412398921833e-05, 'epoch': 8.14}                                                                                                       
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 6200/7620 [12:19:50<1:40:55,  4.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26317399740219116, 'eval_wer': 0.23922576742779375, 'eval_cer': 0.07744471878167064, 'eval_runtime': 357.3914, 'eval_samples_per_second': 5.596, 'eval_steps_per_second': 0.7, 'epoch': 8.14}                                                                                                                                               
{'loss': 0.085, 'learning_rate': 5.7169811320754714e-05, 'epoch': 8.15}                                                                                                       
{'loss': 0.1135, 'learning_rate': 5.67654986522911e-05, 'epoch': 8.16}                                                                                                        
{'loss': 0.1119, 'learning_rate': 5.6361185983827485e-05, 'epoch': 8.18}                                                                                                      
{'loss': 0.0714, 'learning_rate': 5.595687331536388e-05, 'epoch': 8.19}                                                                                                       
{'loss': 0.0991, 'learning_rate': 5.555256064690026e-05, 'epoch': 8.2}                                                                                                        
{'loss': 0.082, 'learning_rate': 5.5148247978436655e-05, 'epoch': 8.22}                                                                                                       
{'loss': 0.0939, 'learning_rate': 5.474393530997305e-05, 'epoch': 8.23}                                                                                                       
{'loss': 0.0776, 'learning_rate': 5.4339622641509426e-05, 'epoch': 8.24}                                                                                                      
{'loss': 0.0709, 'learning_rate': 5.393530997304581e-05, 'epoch': 8.25}                                                                                                       
{'loss': 0.0653, 'learning_rate': 5.3530997304582204e-05, 'epoch': 8.27}                                                                                                      
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 6300/7620 [12:31:24<1:33:31,  4.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.267203688621521, 'eval_wer': 0.23835626795705428, 'eval_cer': 0.07715904530645282, 'eval_runtime': 337.315, 'eval_samples_per_second': 5.929, 'eval_steps_per_second': 0.741, 'epoch': 8.27}                                                                                                                                                
{'loss': 0.1099, 'learning_rate': 5.3126684636118596e-05, 'epoch': 8.28}                                                                                                      
{'loss': 0.0786, 'learning_rate': 5.272237196765498e-05, 'epoch': 8.29}                                                                                                       
{'loss': 0.0526, 'learning_rate': 5.2318059299191374e-05, 'epoch': 8.31}                                                                                                      
{'loss': 0.0724, 'learning_rate': 5.191374663072776e-05, 'epoch': 8.32}                                                                                                       
{'loss': 0.0837, 'learning_rate': 5.1509433962264145e-05, 'epoch': 8.33}                                                                                                      
{'loss': 0.0869, 'learning_rate': 5.110512129380053e-05, 'epoch': 8.35}                                                                                                       
{'loss': 0.0937, 'learning_rate': 5.070080862533692e-05, 'epoch': 8.36}                                                                                                       
{'loss': 0.075, 'learning_rate': 5.029649595687331e-05, 'epoch': 8.37}                                                                                                        
{'loss': 0.0485, 'learning_rate': 4.98921832884097e-05, 'epoch': 8.39}                                                                                                        
{'loss': 0.0687, 'learning_rate': 4.948787061994609e-05, 'epoch': 8.4}                                                                                                        
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 6400/7620 [12:42:23<1:20:15,  3.95s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25564488768577576, 'eval_wer': 0.23620142144261302, 'eval_cer': 0.07537698696104637, 'eval_runtime': 326.9903, 'eval_samples_per_second': 6.116, 'eval_steps_per_second': 0.765, 'epoch': 8.4}                                                                                                                                              
{'loss': 0.0809, 'learning_rate': 4.908355795148247e-05, 'epoch': 8.41}                                                                                                       
{'loss': 0.0926, 'learning_rate': 4.8679245283018864e-05, 'epoch': 8.43}                                                                                                      
{'loss': 0.056, 'learning_rate': 4.827493261455525e-05, 'epoch': 8.44}                                                                                                        
{'loss': 0.061, 'learning_rate': 4.787061994609164e-05, 'epoch': 8.45}                                                                                                        
{'loss': 0.0873, 'learning_rate': 4.746630727762803e-05, 'epoch': 8.46}                                                                                                       
{'loss': 0.1189, 'learning_rate': 4.706199460916442e-05, 'epoch': 8.48}                                                                                                       
{'loss': 0.0705, 'learning_rate': 4.6657681940700805e-05, 'epoch': 8.49}                                                                                                      
{'loss': 0.0906, 'learning_rate': 4.625336927223719e-05, 'epoch': 8.5}                                                                                                        
{'loss': 0.0489, 'learning_rate': 4.5849056603773576e-05, 'epoch': 8.52}                                                                                                      
{'loss': 0.0728, 'learning_rate': 4.544474393530997e-05, 'epoch': 8.53}                                                                                                       
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6500/7620 [12:53:02<1:16:11,  4.08s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26636815071105957, 'eval_wer': 0.23434900952668986, 'eval_cer': 0.07655368960896743, 'eval_runtime': 337.1356, 'eval_samples_per_second': 5.932, 'eval_steps_per_second': 0.742, 'epoch': 8.53}                                                                                                                                             
{'loss': 0.0828, 'learning_rate': 4.504043126684636e-05, 'epoch': 8.54}                                                                                                       
{'loss': 0.0795, 'learning_rate': 4.4636118598382746e-05, 'epoch': 8.56}                                                                                                      
{'loss': 0.0687, 'learning_rate': 4.423180592991914e-05, 'epoch': 8.57}                                                                                                       
{'loss': 0.0493, 'learning_rate': 4.382749326145552e-05, 'epoch': 8.58}                                                                                                       
{'loss': 0.0832, 'learning_rate': 4.342318059299191e-05, 'epoch': 8.6}                                                                                                        
{'loss': 0.0859, 'learning_rate': 4.3018867924528295e-05, 'epoch': 8.61}                                                                                                      
{'loss': 0.0753, 'learning_rate': 4.261455525606469e-05, 'epoch': 8.62}                                                                                                       
{'loss': 0.0938, 'learning_rate': 4.221024258760107e-05, 'epoch': 8.64}                                                                                                       
{'loss': 0.064, 'learning_rate': 4.1805929919137465e-05, 'epoch': 8.65}                                                                                                       
{'loss': 0.0679, 'learning_rate': 4.140161725067386e-05, 'epoch': 8.66}                                                                                                       
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 6600/7620 [13:03:45<1:06:53,  3.93s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26167795062065125, 'eval_wer': 0.23593679116890973, 'eval_cer': 0.07593473041266213, 'eval_runtime': 331.017, 'eval_samples_per_second': 6.042, 'eval_steps_per_second': 0.755, 'epoch': 8.66}                                                                                                                                              
{'loss': 0.097, 'learning_rate': 4.0997304582210236e-05, 'epoch': 8.67}                                                                                                       
{'loss': 0.0745, 'learning_rate': 4.059299191374662e-05, 'epoch': 8.69}                                                                                                       
{'loss': 0.0621, 'learning_rate': 4.0188679245283014e-05, 'epoch': 8.7}                                                                                                       
{'loss': 0.0539, 'learning_rate': 3.978436657681941e-05, 'epoch': 8.71}                                                                                                       
{'loss': 0.0921, 'learning_rate': 3.938005390835579e-05, 'epoch': 8.73}                                                                                                       
{'loss': 0.0833, 'learning_rate': 3.8975741239892184e-05, 'epoch': 8.74}                                                                                                      
{'loss': 0.0899, 'learning_rate': 3.857142857142856e-05, 'epoch': 8.75}                                                                                                       
{'loss': 0.0695, 'learning_rate': 3.8167115902964956e-05, 'epoch': 8.77}                                                                                                      
{'loss': 0.0851, 'learning_rate': 3.776280323450134e-05, 'epoch': 8.78}                                                                                                       
{'loss': 0.0863, 'learning_rate': 3.735849056603773e-05, 'epoch': 8.79}                                                                                                       
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 6700/7620 [13:14:24<1:00:42,  3.96s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26305484771728516, 'eval_wer': 0.23544533494631786, 'eval_cer': 0.07689377707946483, 'eval_runtime': 325.5829, 'eval_samples_per_second': 6.143, 'eval_steps_per_second': 0.768, 'epoch': 8.79}                                                                                                                                             
{'loss': 0.0899, 'learning_rate': 3.695417789757412e-05, 'epoch': 8.81}                                                                                                       
{'loss': 0.0582, 'learning_rate': 3.6549865229110504e-05, 'epoch': 8.82}                                                                                                      
{'loss': 0.0799, 'learning_rate': 3.61455525606469e-05, 'epoch': 8.83}                                                                                                        
{'loss': 0.0653, 'learning_rate': 3.574123989218329e-05, 'epoch': 8.85}                                                                                                       
{'loss': 0.0829, 'learning_rate': 3.5336927223719675e-05, 'epoch': 8.86}                                                                                                      
{'loss': 0.0895, 'learning_rate': 3.493261455525606e-05, 'epoch': 8.87}                                                                                                       
{'loss': 0.0935, 'learning_rate': 3.452830188679245e-05, 'epoch': 8.88}                                                                                                       
{'loss': 0.0654, 'learning_rate': 3.412398921832884e-05, 'epoch': 8.9}                                                                                                        
{'loss': 0.0625, 'learning_rate': 3.3719676549865223e-05, 'epoch': 8.91}                                                                                                      
{'loss': 0.0926, 'learning_rate': 3.3315363881401616e-05, 'epoch': 8.92}                                                                                                      
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 6800/7620 [13:24:56<54:20,  3.98s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.263174444437027, 'eval_wer': 0.23253440193558142, 'eval_cer': 0.07569666918331394, 'eval_runtime': 319.0908, 'eval_samples_per_second': 6.268, 'eval_steps_per_second': 0.783, 'epoch': 8.92}                                                                                                                                               
{'loss': 0.0853, 'learning_rate': 3.2911051212938e-05, 'epoch': 8.94}                                                                                                         
{'loss': 0.0613, 'learning_rate': 3.250673854447439e-05, 'epoch': 8.95}                                                                                                       
{'loss': 0.0731, 'learning_rate': 3.210242587601078e-05, 'epoch': 8.96}                                                                                                       
{'loss': 0.0542, 'learning_rate': 3.169811320754717e-05, 'epoch': 8.98}                                                                                                       
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 6849/7620 [13:32:40<41:58,  3.27s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-6849
Configuration saved in spanish_portuguese_high_augmented/checkpoint-6849/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-6849/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-6849/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1063, 'learning_rate': 3.129380053908356e-05, 'epoch': 8.99}                                                                                                       
{'loss': 0.1287, 'learning_rate': 3.088948787061994e-05, 'epoch': 9.0}                                                                                                        
{'loss': 0.0931, 'learning_rate': 3.048517520215633e-05, 'epoch': 9.02}                                                                                                       
{'loss': 0.0881, 'learning_rate': 3.0080862533692717e-05, 'epoch': 9.03}                                                                                                      
{'loss': 0.0742, 'learning_rate': 2.9676549865229106e-05, 'epoch': 9.04}                                                                                                      
{'loss': 0.1088, 'learning_rate': 2.9272237196765498e-05, 'epoch': 9.06}                                                                                                      
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 6900/7620 [13:35:32<30:18,  2.53s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25871536135673523, 'eval_wer': 0.23136246786632392, 'eval_cer': 0.07552662544806524, 'eval_runtime': 333.6748, 'eval_samples_per_second': 5.994, 'eval_steps_per_second': 0.749, 'epoch': 9.06}                                                                                                                                             
{'loss': 0.0747, 'learning_rate': 2.8867924528301887e-05, 'epoch': 9.07}                                                                                                      
{'loss': 0.0872, 'learning_rate': 2.8463611859838273e-05, 'epoch': 9.08}                                                                                                      
{'loss': 0.0709, 'learning_rate': 2.805929919137466e-05, 'epoch': 9.09}                                                                                                       
{'loss': 0.0565, 'learning_rate': 2.765498652291105e-05, 'epoch': 9.11}                                                                                                       
{'loss': 0.0975, 'learning_rate': 2.7250673854447436e-05, 'epoch': 9.12}                                                                                                      
{'loss': 0.0488, 'learning_rate': 2.6846361185983825e-05, 'epoch': 9.13}                                                                                                      
{'loss': 0.0785, 'learning_rate': 2.6442048517520214e-05, 'epoch': 9.15}                                                                                                      
{'loss': 0.0849, 'learning_rate': 2.60377358490566e-05, 'epoch': 9.16}                                                                                                        
{'loss': 0.0841, 'learning_rate': 2.5633423180592988e-05, 'epoch': 9.17}                                                                                                      
{'loss': 0.0646, 'learning_rate': 2.522911051212938e-05, 'epoch': 9.19}                                                                                                       
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 7000/7620 [13:46:10<25:14,  2.44s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25875934958457947, 'eval_wer': 0.23181611976410102, 'eval_cer': 0.07507770998700866, 'eval_runtime': 326.9993, 'eval_samples_per_second': 6.116, 'eval_steps_per_second': 0.765, 'epoch': 9.19}                                                                                                                                             
{'loss': 0.0597, 'learning_rate': 2.4824797843665763e-05, 'epoch': 9.2}                                                                                                       
{'loss': 0.1117, 'learning_rate': 2.4420485175202155e-05, 'epoch': 9.21}                                                                                                      
{'loss': 0.0761, 'learning_rate': 2.4016172506738544e-05, 'epoch': 9.23}                                                                                                      
{'loss': 0.0816, 'learning_rate': 2.3611859838274933e-05, 'epoch': 9.24}                                                                                                      
{'loss': 0.0593, 'learning_rate': 2.3207547169811318e-05, 'epoch': 9.25}                                                                                                      
{'loss': 0.0593, 'learning_rate': 2.2803234501347707e-05, 'epoch': 9.27}                                                                                                      
{'loss': 0.074, 'learning_rate': 2.2398921832884096e-05, 'epoch': 9.28}                                                                                                       
{'loss': 0.0853, 'learning_rate': 2.199460916442048e-05, 'epoch': 9.29}                                                                                                       
{'loss': 0.0646, 'learning_rate': 2.159029649595687e-05, 'epoch': 9.3}                                                                                                        
{'loss': 0.0721, 'learning_rate': 2.118598382749326e-05, 'epoch': 9.32}                                                                                                       
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7100/7620 [13:56:41<21:19,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26413866877555847, 'eval_wer': 0.2314380765159534, 'eval_cer': 0.07523415022343746, 'eval_runtime': 325.9643, 'eval_samples_per_second': 6.136, 'eval_steps_per_second': 0.767, 'epoch': 9.32}                                                                                                                                              
{'loss': 0.0559, 'learning_rate': 2.0781671159029645e-05, 'epoch': 9.33}                                                                                                      
{'loss': 0.1115, 'learning_rate': 2.0377358490566034e-05, 'epoch': 9.34}                                                                                                      
{'loss': 0.0633, 'learning_rate': 1.9973045822102426e-05, 'epoch': 9.36}                                                                                                      
{'loss': 0.0555, 'learning_rate': 1.9568733153638812e-05, 'epoch': 9.37}                                                                                                      
{'loss': 0.0644, 'learning_rate': 1.91644204851752e-05, 'epoch': 9.38}                                                                                                        
{'loss': 0.0716, 'learning_rate': 1.876010781671159e-05, 'epoch': 9.4}                                                                                                        
{'loss': 0.0671, 'learning_rate': 1.8355795148247975e-05, 'epoch': 9.41}                                                                                                      
{'loss': 0.0799, 'learning_rate': 1.7951482479784364e-05, 'epoch': 9.42}                                                                                                      
{'loss': 0.0605, 'learning_rate': 1.7547169811320753e-05, 'epoch': 9.44}                                                                                                      
{'loss': 0.0687, 'learning_rate': 1.7142857142857142e-05, 'epoch': 9.45}                                                                                                      
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 7200/7620 [14:07:15<17:36,  2.52s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2616162598133087, 'eval_wer': 0.22954786027521548, 'eval_cer': 0.07447235428952327, 'eval_runtime': 330.78, 'eval_samples_per_second': 6.046, 'eval_steps_per_second': 0.756, 'epoch': 9.45}                                                                                                                                                
{'loss': 0.0851, 'learning_rate': 1.673854447439353e-05, 'epoch': 9.46}                                                                                                       
{'loss': 0.0716, 'learning_rate': 1.6334231805929916e-05, 'epoch': 9.48}                                                                                                      
{'loss': 0.0667, 'learning_rate': 1.5929919137466305e-05, 'epoch': 9.49}                                                                                                      
{'loss': 0.0571, 'learning_rate': 1.5525606469002694e-05, 'epoch': 9.5}                                                                                                       
{'loss': 0.0557, 'learning_rate': 1.5121293800539081e-05, 'epoch': 9.51}                                                                                                      
{'loss': 0.0674, 'learning_rate': 1.4716981132075472e-05, 'epoch': 9.53}                                                                                                      
{'loss': 0.0659, 'learning_rate': 1.431266846361186e-05, 'epoch': 9.54}                                                                                                       
{'loss': 0.0632, 'learning_rate': 1.3908355795148246e-05, 'epoch': 9.55}                                                                                                      
{'loss': 0.0541, 'learning_rate': 1.3504043126684635e-05, 'epoch': 9.57}                                                                                                      
{'loss': 0.0692, 'learning_rate': 1.3099730458221023e-05, 'epoch': 9.58}                                                                                                      
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 7300/7620 [14:17:59<13:47,  2.59s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26250338554382324, 'eval_wer': 0.22954786027521548, 'eval_cer': 0.07458798402949239, 'eval_runtime': 326.892, 'eval_samples_per_second': 6.118, 'eval_steps_per_second': 0.765, 'epoch': 9.58}                                                                                                                                              
{'loss': 0.0704, 'learning_rate': 1.269541778975741e-05, 'epoch': 9.59}                                                                                                       
{'loss': 0.0825, 'learning_rate': 1.22911051212938e-05, 'epoch': 9.61}                                                                                                        
{'loss': 0.076, 'learning_rate': 1.1886792452830188e-05, 'epoch': 9.62}                                                                                                       
{'loss': 0.0775, 'learning_rate': 1.1482479784366576e-05, 'epoch': 9.63}                                                                                                      
{'loss': 0.0499, 'learning_rate': 1.1078167115902964e-05, 'epoch': 9.65}                                                                                                      
{'loss': 0.0655, 'learning_rate': 1.0673854447439351e-05, 'epoch': 9.66}                                                                                                      
{'loss': 0.0773, 'learning_rate': 1.0269541778975742e-05, 'epoch': 9.67}                                                                                                      
{'loss': 0.0874, 'learning_rate': 9.865229110512129e-06, 'epoch': 9.69}                                                                                                       
{'loss': 0.0906, 'learning_rate': 9.460916442048518e-06, 'epoch': 9.7}                                                                                                        
{'loss': 0.0502, 'learning_rate': 9.056603773584905e-06, 'epoch': 9.71}                                                                                                       
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 7400/7620 [14:28:35<09:00,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.25964269042015076, 'eval_wer': 0.2282625132315137, 'eval_cer': 0.07424109480958503, 'eval_runtime': 337.8676, 'eval_samples_per_second': 5.919, 'eval_steps_per_second': 0.74, 'epoch': 9.71}                                                                                                                                               
{'loss': 0.0751, 'learning_rate': 8.652291105121294e-06, 'epoch': 9.72}                                                                                                       
{'loss': 0.0761, 'learning_rate': 8.247978436657681e-06, 'epoch': 9.74}                                                                                                       
{'loss': 0.0833, 'learning_rate': 7.84366576819407e-06, 'epoch': 9.75}                                                                                                        
{'loss': 0.0651, 'learning_rate': 7.439353099730457e-06, 'epoch': 9.76}                                                                                                       
{'loss': 0.0546, 'learning_rate': 7.035040431266846e-06, 'epoch': 9.78}                                                                                                       
{'loss': 0.0708, 'learning_rate': 6.630727762803234e-06, 'epoch': 9.79}                                                                                                       
{'loss': 0.0782, 'learning_rate': 6.226415094339621e-06, 'epoch': 9.8}                                                                                                        
{'loss': 0.0608, 'learning_rate': 5.82210242587601e-06, 'epoch': 9.82}                                                                                                        
{'loss': 0.0578, 'learning_rate': 5.417789757412398e-06, 'epoch': 9.83}                                                                                                       
{'loss': 0.0663, 'learning_rate': 5.013477088948787e-06, 'epoch': 9.84}                                                                                                       
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7500/7620 [14:39:31<05:27,  2.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.2603391706943512, 'eval_wer': 0.22901859972780886, 'eval_cer': 0.07434312105073425, 'eval_runtime': 347.8965, 'eval_samples_per_second': 5.749, 'eval_steps_per_second': 0.719, 'epoch': 9.84}                                                                                                                                              
{'loss': 0.0503, 'learning_rate': 4.6091644204851745e-06, 'epoch': 9.86}                                                                                                      
{'loss': 0.088, 'learning_rate': 4.2048517520215626e-06, 'epoch': 9.87}                                                                                                       
{'loss': 0.0568, 'learning_rate': 3.800539083557951e-06, 'epoch': 9.88}                                                                                                       
{'loss': 0.078, 'learning_rate': 3.396226415094339e-06, 'epoch': 9.9}                                                                                                         
{'loss': 0.0523, 'learning_rate': 2.9919137466307276e-06, 'epoch': 9.91}                                                                                                      
{'loss': 0.0558, 'learning_rate': 2.587601078167116e-06, 'epoch': 9.92}                                                                                                       
{'loss': 0.0793, 'learning_rate': 2.1832884097035038e-06, 'epoch': 9.93}                                                                                                      
{'loss': 0.0653, 'learning_rate': 1.778975741239892e-06, 'epoch': 9.95}                                                                                                       
{'loss': 0.0745, 'learning_rate': 1.37466307277628e-06, 'epoch': 9.96}                                                                                                        
{'loss': 0.0509, 'learning_rate': 9.703504043126684e-07, 'epoch': 9.97}                                                                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7600/7620 [14:50:44<00:53,  2.65s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.26016685366630554, 'eval_wer': 0.22894299107817934, 'eval_cer': 0.07428190530604471, 'eval_runtime': 341.5345, 'eval_samples_per_second': 5.856, 'eval_steps_per_second': 0.732, 'epoch': 9.97}                                                                                                                                             
{'loss': 0.0935, 'learning_rate': 5.660377358490566e-07, 'epoch': 9.99}                                                                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 7610/7620 [14:56:53<01:16,  7.61s/it]Saving model checkpoint to spanish_portuguese_high_augmented/checkpoint-7610
Configuration saved in spanish_portuguese_high_augmented/checkpoint-7610/config.json
Model weights saved in spanish_portuguese_high_augmented/checkpoint-7610/pytorch_model.bin
Feature extractor saved in spanish_portuguese_high_augmented/checkpoint-7610/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.0535, 'learning_rate': 1.6172506738544476e-07, 'epoch': 10.0}                                                                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [14:57:34<00:00,  2.83s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 53854.4905, 'train_samples_per_second': 2.263, 'train_steps_per_second': 0.141, 'train_loss': 0.5019006706089798, 'epoch': 10.0}                            
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [14:57:34<00:00,  7.07s/it]
----------------- Training complete. -----------------


(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ 


