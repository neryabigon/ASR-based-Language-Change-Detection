(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ python3 training_script.py 
2023-04-01 23:08:08.355020: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-01 23:08:08.448992: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-01 23:08:08.451645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-04-01 23:08:08.451657: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-04-01 23:08:08.788234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-04-01 23:08:08.788274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-04-01 23:08:08.788278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets complete. -----------------
----------------- Loading Datasets complete. -----------------


----------------- Extracting all characters... -----------------
Parameter 'function'=<function extract_all_chars at 0x7fd92865b310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 95/96 [04:37<00:02,  2.92s/ba]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 15/16 [00:49<00:03,  3.31s/ba]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'p': 0, 'f': 1, 'l': 2, 'u': 3, 'o': 4, '-': 5, 'h': 6, 'n': 7, 'z': 8, 'k': 9, 'a': 10, 'd': 11, 'v': 12, 'b': 13, 'g': 14, 'y': 15, 'x': 16, ' ': 17, 'e': 18, 'j': 19, 'c': 20, 's': 21, 'i': 22, 'q': 23, 't': 24, '.': 25, 'r': 26, "'": 27, 'w': 28, 'm': 29}
Vocab_len: 32
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/3047 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/3046 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3046/3046 [01:21<00:00, 37.60ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [01:29<00:00, 34.10ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [01:30<00:00, 33.73ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [01:31<00:00, 33.43ex/s]
#0:   0%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:15<00:00, 32.58ex/s]
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:15<00:00, 32.59ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:15<00:00, 32.34ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:15<00:00, 31.59ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 499/500 [00:15<00:00, 32.98ex/s]

----------------- Preparing datasets complete. -----------------


----------------- Loading Metrics... -----------------
/home/or/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-/training_script.py:173: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.bias', 'quantizer.codevectors', 'quantizer.weight_proj.weight', 'project_q.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'project_hid.weight']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 12187
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 7620
  Number of trainable parameters = 311261344
  0%|                                                                                                                                                | 0/7620 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 15.3546, 'learning_rate': 1.1999999999999999e-05, 'epoch': 0.01}                                                                                                     
{'loss': 18.495, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.03}                                                                                                      
{'loss': 20.2387, 'learning_rate': 4.2e-05, 'epoch': 0.04}                                                                                                                    
{'loss': 20.153, 'learning_rate': 5.2499999999999995e-05, 'epoch': 0.05}                                                                                                      
{'loss': 14.5429, 'learning_rate': 6.75e-05, 'epoch': 0.07}                                                                                                                   
{'loss': 5.6997, 'learning_rate': 8.25e-05, 'epoch': 0.08}                                                                                                                    
{'loss': 4.3856, 'learning_rate': 9.75e-05, 'epoch': 0.09}                                                                                                                    
{'loss': 3.4909, 'learning_rate': 0.0001125, 'epoch': 0.1}                                                                                                                    
{'loss': 3.2611, 'learning_rate': 0.00012749999999999998, 'epoch': 0.12}                                                                                                      
{'loss': 3.0894, 'learning_rate': 0.0001425, 'epoch': 0.13}                                                                                                                   
  1%|â–ˆâ–‹                                                                                                                                  | 100/7620 [02:42<2:13:14,  1.06s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 3.0170600414276123, 'eval_wer': 1.0, 'eval_cer': 0.9902754111353279, 'eval_runtime': 135.0585, 'eval_samples_per_second': 14.808, 'eval_steps_per_second': 1.851, 'epoch': 0.13}                                                                                                                                                              
{'loss': 3.0558, 'learning_rate': 0.00015749999999999998, 'epoch': 0.14}                                                                                                      
{'loss': 2.9573, 'learning_rate': 0.00017249999999999996, 'epoch': 0.16}                                                                                                      
{'loss': 2.9467, 'learning_rate': 0.00018749999999999998, 'epoch': 0.17}                                                                                                      
{'loss': 2.922, 'learning_rate': 0.0002025, 'epoch': 0.18}                                                                                                                    
{'loss': 2.9804, 'learning_rate': 0.00021749999999999997, 'epoch': 0.2}                                                                                                       
{'loss': 3.0474, 'learning_rate': 0.00023249999999999999, 'epoch': 0.21}                                                                                                      
{'loss': 2.946, 'learning_rate': 0.00024749999999999994, 'epoch': 0.22}                                                                                                       
{'loss': 2.9106, 'learning_rate': 0.0002625, 'epoch': 0.24}                                                                                                                   
{'loss': 2.9154, 'learning_rate': 0.00027749999999999997, 'epoch': 0.25}                                                                                                      
{'loss': 2.9284, 'learning_rate': 0.00029249999999999995, 'epoch': 0.26}                                                                                                      
  3%|â–ˆâ–ˆâ–ˆâ–                                                                                                                                | 200/7620 [07:36<2:16:10,  1.10s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.944765329360962, 'eval_wer': 1.0, 'eval_cer': 0.9902754111353279, 'eval_runtime': 135.9017, 'eval_samples_per_second': 14.717, 'eval_steps_per_second': 1.84, 'epoch': 0.26}                                                                                                                                                                
{'loss': 2.9867, 'learning_rate': 0.00029979784366576814, 'epoch': 0.28}                                                                                                      
{'loss': 2.9403, 'learning_rate': 0.00029939353099730457, 'epoch': 0.29}                                                                                                      
{'loss': 2.9255, 'learning_rate': 0.00029898921832884095, 'epoch': 0.3}                                                                                                       
{'loss': 2.9183, 'learning_rate': 0.0002985849056603773, 'epoch': 0.31}                                                                                                       
{'loss': 2.9521, 'learning_rate': 0.0002981805929919137, 'epoch': 0.33}                                                                                                       
{'loss': 2.9806, 'learning_rate': 0.00029777628032345014, 'epoch': 0.34}                                                                                                      
{'loss': 3.4591, 'learning_rate': 0.0002973719676549865, 'epoch': 0.35}                                                                                                       
{'loss': 2.9114, 'learning_rate': 0.0002969676549865229, 'epoch': 0.37}                                                                                                       
{'loss': 2.9049, 'learning_rate': 0.0002965633423180593, 'epoch': 0.38}                                                                                                       
{'loss': 2.9415, 'learning_rate': 0.00029615902964959565, 'epoch': 0.39}                                                                                                      
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                              | 300/7620 [13:00<3:05:20,  1.52s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.9709229469299316, 'eval_wer': 1.0, 'eval_cer': 0.9902754111353279, 'eval_runtime': 136.5818, 'eval_samples_per_second': 14.643, 'eval_steps_per_second': 1.83, 'epoch': 0.39}                                                                                                                                                               
{'loss': 2.9948, 'learning_rate': 0.00029575471698113203, 'epoch': 0.41}                                                                                                      
{'loss': 2.9373, 'learning_rate': 0.0002953504043126684, 'epoch': 0.42}                                                                                                       
{'loss': 2.9116, 'learning_rate': 0.00029494609164420484, 'epoch': 0.43}                                                                                                      
{'loss': 2.899, 'learning_rate': 0.0002945417789757412, 'epoch': 0.45}                                                                                                        
{'loss': 2.9296, 'learning_rate': 0.0002941374663072776, 'epoch': 0.46}                                                                                                       
{'loss': 2.9824, 'learning_rate': 0.000293733153638814, 'epoch': 0.47}                                                                                                        
{'loss': 2.8972, 'learning_rate': 0.0002933288409703504, 'epoch': 0.49}                                                                                                       
{'loss': 2.8933, 'learning_rate': 0.00029292452830188674, 'epoch': 0.5}                                                                                                       
{'loss': 2.8786, 'learning_rate': 0.00029252021563342317, 'epoch': 0.51}                                                                                                      
{'loss': 2.8856, 'learning_rate': 0.00029211590296495955, 'epoch': 0.52}                                                                                                      
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                             | 400/7620 [18:24<2:09:55,  1.08s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.8787841796875, 'eval_wer': 1.0, 'eval_cer': 0.9902754111353279, 'eval_runtime': 135.7869, 'eval_samples_per_second': 14.729, 'eval_steps_per_second': 1.841, 'epoch': 0.52}                                                                                                                                                                 
{'loss': 2.928, 'learning_rate': 0.00029171159029649593, 'epoch': 0.54}                                                                                                       
{'loss': 2.906, 'learning_rate': 0.0002913072776280323, 'epoch': 0.55}                                                                                                        
{'loss': 2.8816, 'learning_rate': 0.0002909029649595687, 'epoch': 0.56}                                                                                                       
{'loss': 2.8529, 'learning_rate': 0.0002904986522911051, 'epoch': 0.58}                                                                                                       
{'loss': 2.8712, 'learning_rate': 0.00029009433962264144, 'epoch': 0.59}                                                                                                      
{'loss': 2.9294, 'learning_rate': 0.0002896900269541779, 'epoch': 0.6}                                                                                                        
{'loss': 2.8781, 'learning_rate': 0.00028928571428571425, 'epoch': 0.62}                                                                                                      
{'loss': 2.8569, 'learning_rate': 0.0002888814016172507, 'epoch': 0.63}                                                                                                       
{'loss': 2.8394, 'learning_rate': 0.000288477088948787, 'epoch': 0.64}                                                                                                        
{'loss': 2.8493, 'learning_rate': 0.00028807277628032345, 'epoch': 0.66}                                                                                                      
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                                          | 500/7620 [26:30<11:04:25,  5.60s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.8350391387939453, 'eval_wer': 1.0, 'eval_cer': 0.9902754111353279, 'eval_runtime': 419.6051, 'eval_samples_per_second': 4.766, 'eval_steps_per_second': 0.596, 'epoch': 0.66}                                                                                                                                                               
{'loss': 2.9233, 'learning_rate': 0.0002876684636118598, 'epoch': 0.67}                                                                                                       
{'loss': 2.8765, 'learning_rate': 0.0002872641509433962, 'epoch': 0.68}                                                                                                       
{'loss': 2.8295, 'learning_rate': 0.0002868598382749326, 'epoch': 0.7}                                                                                                        
{'loss': 2.7783, 'learning_rate': 0.00028645552560646896, 'epoch': 0.71}                                                                                                      
{'loss': 2.7172, 'learning_rate': 0.0002860512129380054, 'epoch': 0.72}                                                                                                       
{'loss': 2.6651, 'learning_rate': 0.00028564690026954177, 'epoch': 0.73}                                                                                                      
{'loss': 2.4867, 'learning_rate': 0.00028524258760107815, 'epoch': 0.75}                                                                                                      
{'loss': 2.29, 'learning_rate': 0.00028483827493261453, 'epoch': 0.76}                                                                                                        
{'loss': 2.0382, 'learning_rate': 0.0002844339622641509, 'epoch': 0.77}                                                                                                       
{'loss': 1.9946, 'learning_rate': 0.0002840296495956873, 'epoch': 0.79}                                                                                                       
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                         | 600/7620 [38:14<4:10:43,  2.14s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 1.850983738899231, 'eval_wer': 0.9824081138087332, 'eval_cer': 0.5563384188626908, 'eval_runtime': 317.4549, 'eval_samples_per_second': 6.3, 'eval_steps_per_second': 0.788, 'epoch': 0.79}                                                                                                                                                   
{'loss': 1.9659, 'learning_rate': 0.0002836253369272237, 'epoch': 0.8}                                                                                                        
{'loss': 1.7545, 'learning_rate': 0.0002832210242587601, 'epoch': 0.81}                                                                                                       
{'loss': 1.537, 'learning_rate': 0.0002828167115902965, 'epoch': 0.83}                                                                                                        
{'loss': 1.4623, 'learning_rate': 0.00028241239892183286, 'epoch': 0.84}                                                                                                      
{'loss': 1.543, 'learning_rate': 0.00028200808625336923, 'epoch': 0.85}                                                                                                       
{'loss': 1.5669, 'learning_rate': 0.0002816037735849056, 'epoch': 0.87}                                                                                                       
{'loss': 1.4756, 'learning_rate': 0.00028119946091644205, 'epoch': 0.88}                                                                                                      
{'loss': 1.3225, 'learning_rate': 0.0002807951482479784, 'epoch': 0.89}                                                                                                       
{'loss': 1.1771, 'learning_rate': 0.0002803908355795148, 'epoch': 0.91}                                                                                                       
{'loss': 1.244, 'learning_rate': 0.0002799865229110512, 'epoch': 0.92}                                                                                                        
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                       | 700/7620 [48:24<4:01:36,  2.09s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 1.1189757585525513, 'eval_wer': 0.8811650136875645, 'eval_cer': 0.36476322567862096, 'eval_runtime': 328.9098, 'eval_samples_per_second': 6.081, 'eval_steps_per_second': 0.76, 'epoch': 0.92}                                                                                                                                                
{'loss': 1.3797, 'learning_rate': 0.00027958221024258756, 'epoch': 0.93}                                                                                                      
{'loss': 1.179, 'learning_rate': 0.000279177897574124, 'epoch': 0.94}                                                                                                         
{'loss': 1.0632, 'learning_rate': 0.0002787735849056603, 'epoch': 0.96}                                                                                                       
{'loss': 0.966, 'learning_rate': 0.00027836927223719675, 'epoch': 0.97}                                                                                                       
{'loss': 1.047, 'learning_rate': 0.00027796495956873313, 'epoch': 0.98}                                                                                                       
{'loss': 1.13, 'learning_rate': 0.0002775606469002695, 'epoch': 1.0}                                                                                                          
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                      | 761/7620 [56:47<4:35:56,  2.41s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-761
Configuration saved in russian_portuguese_high_augmented/checkpoint-761/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-761/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-761/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 1.2016, 'learning_rate': 0.0002771563342318059, 'epoch': 1.01}                                                                                                       
{'loss': 1.0756, 'learning_rate': 0.0002767520215633423, 'epoch': 1.02}                                                                                                       
{'loss': 0.8611, 'learning_rate': 0.0002763477088948787, 'epoch': 1.04}                                                                                                       
{'loss': 0.8859, 'learning_rate': 0.0002759433962264151, 'epoch': 1.05}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                      | 800/7620 [59:00<4:36:56,  2.44s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.766607403755188, 'eval_wer': 0.7274603958174393, 'eval_cer': 0.2613750743015653, 'eval_runtime': 317.4451, 'eval_samples_per_second': 6.3, 'eval_steps_per_second': 0.788, 'epoch': 1.05}                                                                                                                                                   
{'loss': 0.8108, 'learning_rate': 0.00027553908355795146, 'epoch': 1.06}                                                                                                      
{'loss': 1.3599, 'learning_rate': 0.00027513477088948784, 'epoch': 1.08}                                                                                                      
{'loss': 0.9761, 'learning_rate': 0.0002747304582210242, 'epoch': 1.09}                                                                                                       
{'loss': 0.8859, 'learning_rate': 0.0002743261455525606, 'epoch': 1.1}                                                                                                        
{'loss': 0.7173, 'learning_rate': 0.000273921832884097, 'epoch': 1.12}                                                                                                        
{'loss': 0.789, 'learning_rate': 0.0002735175202156334, 'epoch': 1.13}                                                                                                        
{'loss': 1.063, 'learning_rate': 0.0002731132075471698, 'epoch': 1.14}                                                                                                        
{'loss': 0.809, 'learning_rate': 0.00027270889487870616, 'epoch': 1.15}                                                                                                       
{'loss': 0.6687, 'learning_rate': 0.0002723045822102426, 'epoch': 1.17}                                                                                                       
{'loss': 0.6336, 'learning_rate': 0.0002719002695417789, 'epoch': 1.18}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                  | 900/7620 [1:08:56<4:32:08,  2.43s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6463837623596191, 'eval_wer': 0.652560247722479, 'eval_cer': 0.23258173172181493, 'eval_runtime': 301.2016, 'eval_samples_per_second': 6.64, 'eval_steps_per_second': 0.83, 'epoch': 1.18}                                                                                                                                                  
{'loss': 0.7063, 'learning_rate': 0.00027149595687331535, 'epoch': 1.19}                                                                                                      
{'loss': 0.9458, 'learning_rate': 0.00027109164420485173, 'epoch': 1.21}                                                                                                      
{'loss': 0.8445, 'learning_rate': 0.0002706873315363881, 'epoch': 1.22}                                                                                                       
{'loss': 0.7163, 'learning_rate': 0.0002702830188679245, 'epoch': 1.23}                                                                                                       
{'loss': 0.6048, 'learning_rate': 0.00026987870619946087, 'epoch': 1.25}                                                                                                      
{'loss': 0.6403, 'learning_rate': 0.0002694743935309973, 'epoch': 1.26}                                                                                                       
{'loss': 0.9969, 'learning_rate': 0.0002690700808625337, 'epoch': 1.27}                                                                                                       
{'loss': 0.7367, 'learning_rate': 0.00026866576819407006, 'epoch': 1.29}                                                                                                      
{'loss': 0.649, 'learning_rate': 0.00026826145552560644, 'epoch': 1.3}                                                                                                        
{'loss': 0.6018, 'learning_rate': 0.00026785714285714287, 'epoch': 1.31}                                                                                                      
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                | 1000/7620 [1:18:47<4:31:03,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5768088102340698, 'eval_wer': 0.6213256742808418, 'eval_cer': 0.21323558549633445, 'eval_runtime': 310.2189, 'eval_samples_per_second': 6.447, 'eval_steps_per_second': 0.806, 'epoch': 1.31}                                                                                                                                               
{'loss': 0.5792, 'learning_rate': 0.0002674528301886792, 'epoch': 1.33}                                                                                                       
{'loss': 0.8827, 'learning_rate': 0.00026704851752021563, 'epoch': 1.34}                                                                                                      
{'loss': 0.681, 'learning_rate': 0.000266644204851752, 'epoch': 1.35}                                                                                                         
{'loss': 0.5507, 'learning_rate': 0.0002662398921832884, 'epoch': 1.36}                                                                                                       
{'loss': 0.4983, 'learning_rate': 0.00026583557951482476, 'epoch': 1.38}                                                                                                      
{'loss': 0.5311, 'learning_rate': 0.00026543126684636114, 'epoch': 1.39}                                                                                                      
{'loss': 0.8939, 'learning_rate': 0.0002650269541778976, 'epoch': 1.4}                                                                                                        
{'loss': 0.6632, 'learning_rate': 0.00026462264150943395, 'epoch': 1.42}                                                                                                      
{'loss': 0.5701, 'learning_rate': 0.00026421832884097033, 'epoch': 1.43}                                                                                                      
{'loss': 0.474, 'learning_rate': 0.0002638140161725067, 'epoch': 1.44}                                                                                                        
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                              | 1100/7620 [1:28:38<4:22:08,  2.41s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5257905721664429, 'eval_wer': 0.5836736525602477, 'eval_cer': 0.20817911630671687, 'eval_runtime': 303.9357, 'eval_samples_per_second': 6.58, 'eval_steps_per_second': 0.823, 'epoch': 1.44}                                                                                                                                                
{'loss': 0.4919, 'learning_rate': 0.0002634097035040431, 'epoch': 1.46}                                                                                                       
{'loss': 0.8824, 'learning_rate': 0.00026300539083557947, 'epoch': 1.47}                                                                                                      
{'loss': 0.7394, 'learning_rate': 0.0002626010781671159, 'epoch': 1.48}                                                                                                       
{'loss': 0.5508, 'learning_rate': 0.0002621967654986523, 'epoch': 1.5}                                                                                                        
{'loss': 0.4954, 'learning_rate': 0.00026179245283018866, 'epoch': 1.51}                                                                                                      
{'loss': 0.5171, 'learning_rate': 0.00026138814016172504, 'epoch': 1.52}                                                                                                      
{'loss': 0.8687, 'learning_rate': 0.0002609838274932614, 'epoch': 1.54}                                                                                                       
{'loss': 0.6712, 'learning_rate': 0.0002605795148247978, 'epoch': 1.55}                                                                                                       
{'loss': 0.5309, 'learning_rate': 0.00026017520215633423, 'epoch': 1.56}                                                                                                      
{'loss': 0.4636, 'learning_rate': 0.0002597708894878706, 'epoch': 1.57}                                                                                                       
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                            | 1200/7620 [1:38:14<4:04:29,  2.28s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5106876492500305, 'eval_wer': 0.5540546605035228, 'eval_cer': 0.19060035664751337, 'eval_runtime': 288.6888, 'eval_samples_per_second': 6.928, 'eval_steps_per_second': 0.866, 'epoch': 1.57}                                                                                                                                               
{'loss': 0.4791, 'learning_rate': 0.000259366576819407, 'epoch': 1.59}                                                                                                        
{'loss': 0.8361, 'learning_rate': 0.00025896226415094337, 'epoch': 1.6}                                                                                                       
{'loss': 0.608, 'learning_rate': 0.00025855795148247974, 'epoch': 1.61}                                                                                                       
{'loss': 0.4478, 'learning_rate': 0.0002581536388140162, 'epoch': 1.63}                                                                                                       
{'loss': 0.4739, 'learning_rate': 0.0002577493261455525, 'epoch': 1.64}                                                                                                       
{'loss': 0.4931, 'learning_rate': 0.00025734501347708893, 'epoch': 1.65}                                                                                                      
{'loss': 0.7493, 'learning_rate': 0.0002569407008086253, 'epoch': 1.67}                                                                                                       
{'loss': 0.5781, 'learning_rate': 0.0002565363881401617, 'epoch': 1.68}                                                                                                       
{'loss': 0.4211, 'learning_rate': 0.00025613207547169807, 'epoch': 1.69}                                                                                                      
{'loss': 0.4224, 'learning_rate': 0.0002557277628032345, 'epoch': 1.71}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                           | 1300/7620 [1:47:30<3:55:47,  2.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.44835737347602844, 'eval_wer': 0.5279809720414665, 'eval_cer': 0.17330691499900933, 'eval_runtime': 279.4657, 'eval_samples_per_second': 7.157, 'eval_steps_per_second': 0.895, 'epoch': 1.71}                                                                                                                                              
{'loss': 0.5321, 'learning_rate': 0.0002553234501347709, 'epoch': 1.72}                                                                                                       
{'loss': 0.7875, 'learning_rate': 0.00025491913746630726, 'epoch': 1.73}                                                                                                      
{'loss': 0.5638, 'learning_rate': 0.00025451482479784364, 'epoch': 1.75}                                                                                                      
{'loss': 0.4394, 'learning_rate': 0.00025411051212938, 'epoch': 1.76}                                                                                                         
{'loss': 0.4031, 'learning_rate': 0.0002537061994609164, 'epoch': 1.77}                                                                                                       
{'loss': 0.4403, 'learning_rate': 0.0002533018867924528, 'epoch': 1.78}                                                                                                       
{'loss': 0.7051, 'learning_rate': 0.0002528975741239892, 'epoch': 1.8}                                                                                                        
{'loss': 0.5383, 'learning_rate': 0.0002524932614555256, 'epoch': 1.81}                                                                                                       
{'loss': 0.4514, 'learning_rate': 0.00025208894878706197, 'epoch': 1.82}                                                                                                      
{'loss': 0.3648, 'learning_rate': 0.00025168463611859835, 'epoch': 1.84}                                                                                                      
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                         | 1400/7620 [1:56:45<4:02:29,  2.34s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.44558119773864746, 'eval_wer': 0.506574518691379, 'eval_cer': 0.16891618783435705, 'eval_runtime': 285.9167, 'eval_samples_per_second': 6.995, 'eval_steps_per_second': 0.874, 'epoch': 1.84}                                                                                                                                               
{'loss': 0.5021, 'learning_rate': 0.0002512803234501348, 'epoch': 1.85}                                                                                                       
{'loss': 0.7937, 'learning_rate': 0.0002508760107816711, 'epoch': 1.86}                                                                                                       
{'loss': 0.5226, 'learning_rate': 0.00025047169811320754, 'epoch': 1.88}                                                                                                      
{'loss': 0.387, 'learning_rate': 0.0002500673854447439, 'epoch': 1.89}                                                                                                        
{'loss': 0.3285, 'learning_rate': 0.0002496630727762803, 'epoch': 1.9}                                                                                                        
{'loss': 0.3871, 'learning_rate': 0.00024925876010781667, 'epoch': 1.92}                                                                                                      
{'loss': 0.6777, 'learning_rate': 0.00024885444743935305, 'epoch': 1.93}                                                                                                      
{'loss': 0.5431, 'learning_rate': 0.0002484501347708895, 'epoch': 1.94}                                                                                                       
{'loss': 0.4287, 'learning_rate': 0.00024804582210242586, 'epoch': 1.96}                                                                                                      
{'loss': 0.3671, 'learning_rate': 0.00024764150943396224, 'epoch': 1.97}                                                                                                      
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                       | 1500/7620 [2:06:10<4:00:58,  2.36s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.42776814103126526, 'eval_wer': 0.5028945833146344, 'eval_cer': 0.16836932831384982, 'eval_runtime': 283.7306, 'eval_samples_per_second': 7.049, 'eval_steps_per_second': 0.881, 'epoch': 1.97}                                                                                                                                              
{'loss': 0.4141, 'learning_rate': 0.0002472371967654986, 'epoch': 1.98}                                                                                                       
{'loss': 0.5961, 'learning_rate': 0.00024683288409703505, 'epoch': 1.99}                                                                                                      
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                       | 1522/7620 [2:11:45<4:05:26,  2.41s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-1522
Configuration saved in russian_portuguese_high_augmented/checkpoint-1522/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-1522/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-1522/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.5811, 'learning_rate': 0.0002464285714285714, 'epoch': 2.01}                                                                                                       
{'loss': 0.445, 'learning_rate': 0.0002460242587601078, 'epoch': 2.02}                                                                                                        
{'loss': 0.3527, 'learning_rate': 0.0002456199460916442, 'epoch': 2.03}                                                                                                       
{'loss': 0.2916, 'learning_rate': 0.00024521563342318057, 'epoch': 2.05}                                                                                                      
{'loss': 0.3367, 'learning_rate': 0.00024481132075471695, 'epoch': 2.06}                                                                                                      
{'loss': 0.5786, 'learning_rate': 0.0002444070080862534, 'epoch': 2.07}                                                                                                       
{'loss': 0.4758, 'learning_rate': 0.00024400269541778976, 'epoch': 2.09}                                                                                                      
{'loss': 0.3259, 'learning_rate': 0.0002435983827493261, 'epoch': 2.1}                                                                                                        
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                      | 1600/7620 [2:15:32<4:24:55,  2.64s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.4091964662075043, 'eval_wer': 0.4798725485796347, 'eval_cer': 0.16343966712898753, 'eval_runtime': 289.1373, 'eval_samples_per_second': 6.917, 'eval_steps_per_second': 0.865, 'epoch': 2.1}                                                                                                                                                
{'loss': 0.2612, 'learning_rate': 0.00024319407008086252, 'epoch': 2.11}                                                                                                      
{'loss': 0.3304, 'learning_rate': 0.00024278975741239892, 'epoch': 2.13}                                                                                                      
{'loss': 0.6294, 'learning_rate': 0.00024238544474393527, 'epoch': 2.14}                                                                                                      
{'loss': 0.5071, 'learning_rate': 0.00024198113207547168, 'epoch': 2.15}                                                                                                      
{'loss': 0.3412, 'learning_rate': 0.00024157681940700806, 'epoch': 2.17}                                                                                                      
{'loss': 0.3242, 'learning_rate': 0.00024117250673854446, 'epoch': 2.18}                                                                                                      
{'loss': 0.2573, 'learning_rate': 0.00024076819407008084, 'epoch': 2.19}                                                                                                      
{'loss': 0.5965, 'learning_rate': 0.00024036388140161722, 'epoch': 2.2}                                                                                                       
{'loss': 0.4451, 'learning_rate': 0.00023995956873315363, 'epoch': 2.22}                                                                                                      
{'loss': 0.3287, 'learning_rate': 0.00023955525606469, 'epoch': 2.23}                                                                                                         
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                    | 1700/7620 [2:25:03<4:17:17,  2.61s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.40511736273765564, 'eval_wer': 0.45999192209307543, 'eval_cer': 0.15169407568852783, 'eval_runtime': 286.8929, 'eval_samples_per_second': 6.971, 'eval_steps_per_second': 0.871, 'epoch': 2.23}                                                                                                                                             
{'loss': 0.3206, 'learning_rate': 0.00023915094339622639, 'epoch': 2.24}                                                                                                      
{'loss': 0.2573, 'learning_rate': 0.0002387466307277628, 'epoch': 2.26}                                                                                                       
{'loss': 0.5418, 'learning_rate': 0.0002383423180592992, 'epoch': 2.27}                                                                                                       
{'loss': 0.408, 'learning_rate': 0.00023793800539083555, 'epoch': 2.28}                                                                                                       
{'loss': 0.3918, 'learning_rate': 0.00023753369272237195, 'epoch': 2.3}                                                                                                       
{'loss': 0.2877, 'learning_rate': 0.00023712938005390833, 'epoch': 2.31}                                                                                                      
{'loss': 0.3141, 'learning_rate': 0.0002367250673854447, 'epoch': 2.32}                                                                                                       
{'loss': 0.5101, 'learning_rate': 0.00023632075471698112, 'epoch': 2.34}                                                                                                      
{'loss': 0.3874, 'learning_rate': 0.0002359164420485175, 'epoch': 2.35}                                                                                                       
{'loss': 0.3266, 'learning_rate': 0.00023551212938005388, 'epoch': 2.36}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 1800/7620 [2:34:32<4:23:27,  2.72s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.38071826100349426, 'eval_wer': 0.45447201902795853, 'eval_cer': 0.1436734693877551, 'eval_runtime': 297.5305, 'eval_samples_per_second': 6.722, 'eval_steps_per_second': 0.84, 'epoch': 2.36}                                                                                                                                               
{'loss': 0.2797, 'learning_rate': 0.00023510781671159028, 'epoch': 2.38}                                                                                                      
{'loss': 0.2989, 'learning_rate': 0.00023470350404312666, 'epoch': 2.39}                                                                                                      
{'loss': 0.5272, 'learning_rate': 0.00023429919137466307, 'epoch': 2.4}                                                                                                       
{'loss': 0.3806, 'learning_rate': 0.00023389487870619942, 'epoch': 2.41}                                                                                                      
{'loss': 0.3431, 'learning_rate': 0.00023349056603773582, 'epoch': 2.43}                                                                                                      
{'loss': 0.2262, 'learning_rate': 0.00023308625336927223, 'epoch': 2.44}                                                                                                      
{'loss': 0.2939, 'learning_rate': 0.00023268194070080858, 'epoch': 2.45}                                                                                                      
{'loss': 0.5257, 'learning_rate': 0.000232277628032345, 'epoch': 2.47}                                                                                                        
{'loss': 0.4019, 'learning_rate': 0.0002318733153638814, 'epoch': 2.48}                                                                                                       
{'loss': 0.3001, 'learning_rate': 0.00023146900269541777, 'epoch': 2.49}                                                                                                      
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                | 1900/7620 [2:44:10<4:23:24,  2.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3853038251399994, 'eval_wer': 0.4495803976125297, 'eval_cer': 0.14280958985535963, 'eval_runtime': 291.3741, 'eval_samples_per_second': 6.864, 'eval_steps_per_second': 0.858, 'epoch': 2.49}                                                                                                                                               
{'loss': 0.2394, 'learning_rate': 0.00023106469002695415, 'epoch': 2.51}                                                                                                      
{'loss': 0.262, 'learning_rate': 0.00023066037735849056, 'epoch': 2.52}                                                                                                       
{'loss': 0.5023, 'learning_rate': 0.00023025606469002693, 'epoch': 2.53}                                                                                                      
{'loss': 0.367, 'learning_rate': 0.0002298517520215633, 'epoch': 2.55}                                                                                                        
{'loss': 0.3067, 'learning_rate': 0.0002294474393530997, 'epoch': 2.56}                                                                                                       
{'loss': 0.2839, 'learning_rate': 0.0002290431266846361, 'epoch': 2.57}                                                                                                       
{'loss': 0.2869, 'learning_rate': 0.0002286388140161725, 'epoch': 2.59}                                                                                                       
{'loss': 0.4887, 'learning_rate': 0.00022823450134770886, 'epoch': 2.6}                                                                                                       
{'loss': 0.4295, 'learning_rate': 0.00022783018867924526, 'epoch': 2.61}                                                                                                      
{'loss': 0.2982, 'learning_rate': 0.00022742587601078167, 'epoch': 2.62}                                                                                                      
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                               | 2000/7620 [2:53:35<4:07:33,  2.64s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.4024476408958435, 'eval_wer': 0.44118834986312433, 'eval_cer': 0.14263522884882107, 'eval_runtime': 290.4082, 'eval_samples_per_second': 6.887, 'eval_steps_per_second': 0.861, 'epoch': 2.62}                                                                                                                                              
{'loss': 0.2317, 'learning_rate': 0.00022702156334231802, 'epoch': 2.64}                                                                                                      
{'loss': 0.2963, 'learning_rate': 0.00022661725067385442, 'epoch': 2.65}                                                                                                      
{'loss': 0.5408, 'learning_rate': 0.00022621293800539083, 'epoch': 2.66}                                                                                                      
{'loss': 0.3841, 'learning_rate': 0.0002258086253369272, 'epoch': 2.68}                                                                                                       
{'loss': 0.3215, 'learning_rate': 0.0002254043126684636, 'epoch': 2.69}                                                                                                       
{'loss': 0.2553, 'learning_rate': 0.000225, 'epoch': 2.7}                                                                                                                     
{'loss': 0.314, 'learning_rate': 0.00022459568733153637, 'epoch': 2.72}                                                                                                       
{'loss': 0.5387, 'learning_rate': 0.00022419137466307275, 'epoch': 2.73}                                                                                                      
{'loss': 0.4272, 'learning_rate': 0.00022378706199460913, 'epoch': 2.74}                                                                                                      
{'loss': 0.2627, 'learning_rate': 0.00022338274932614554, 'epoch': 2.76}                                                                                                      
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                             | 2100/7620 [3:03:05<4:16:30,  2.79s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.39500007033348083, 'eval_wer': 0.4494457658304537, 'eval_cer': 0.145821279968298, 'eval_runtime': 296.3862, 'eval_samples_per_second': 6.748, 'eval_steps_per_second': 0.843, 'epoch': 2.76}                                                                                                                                                
{'loss': 0.2637, 'learning_rate': 0.00022297843665768194, 'epoch': 2.77}                                                                                                      
{'loss': 0.3124, 'learning_rate': 0.0002225741239892183, 'epoch': 2.78}                                                                                                       
{'loss': 0.4889, 'learning_rate': 0.0002221698113207547, 'epoch': 2.8}                                                                                                        
{'loss': 0.3639, 'learning_rate': 0.0002217654986522911, 'epoch': 2.81}                                                                                                       
{'loss': 0.2771, 'learning_rate': 0.00022136118598382746, 'epoch': 2.82}                                                                                                      
{'loss': 0.2221, 'learning_rate': 0.00022095687331536386, 'epoch': 2.83}                                                                                                      
{'loss': 0.2771, 'learning_rate': 0.00022055256064690027, 'epoch': 2.85}                                                                                                      
{'loss': 0.4658, 'learning_rate': 0.00022014824797843665, 'epoch': 2.86}                                                                                                      
{'loss': 0.3566, 'learning_rate': 0.00021974393530997303, 'epoch': 2.87}                                                                                                      
{'loss': 0.2724, 'learning_rate': 0.0002193396226415094, 'epoch': 2.89}                                                                                                       
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 2200/7620 [3:12:37<4:06:44,  2.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3745802640914917, 'eval_wer': 0.4248979042319257, 'eval_cer': 0.13864870219932635, 'eval_runtime': 287.9126, 'eval_samples_per_second': 6.947, 'eval_steps_per_second': 0.868, 'epoch': 2.89}                                                                                                                                               
{'loss': 0.1895, 'learning_rate': 0.0002189353099730458, 'epoch': 2.9}                                                                                                        
{'loss': 0.2178, 'learning_rate': 0.0002185309973045822, 'epoch': 2.91}                                                                                                       
{'loss': 0.5158, 'learning_rate': 0.00021812668463611857, 'epoch': 2.93}                                                                                                      
{'loss': 0.4293, 'learning_rate': 0.00021772237196765497, 'epoch': 2.94}                                                                                                      
{'loss': 0.2398, 'learning_rate': 0.00021731805929919138, 'epoch': 2.95}                                                                                                      
{'loss': 0.2621, 'learning_rate': 0.00021691374663072773, 'epoch': 2.97}                                                                                                      
{'loss': 0.2504, 'learning_rate': 0.00021650943396226414, 'epoch': 2.98}                                                                                                      
{'loss': 0.4756, 'learning_rate': 0.00021610512129380054, 'epoch': 2.99}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                          | 2283/7620 [3:21:07<3:48:53,  2.57s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-2283
Configuration saved in russian_portuguese_high_augmented/checkpoint-2283/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-2283/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-2283/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.337, 'learning_rate': 0.0002157008086253369, 'epoch': 3.01}                                                                                                        
{'loss': 0.3413, 'learning_rate': 0.0002152964959568733, 'epoch': 3.02}                                                                                                       
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                          | 2300/7620 [3:22:15<4:39:56,  3.16s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3864341378211975, 'eval_wer': 0.4287124713907463, 'eval_cer': 0.1412641172974044, 'eval_runtime': 294.615, 'eval_samples_per_second': 6.789, 'eval_steps_per_second': 0.849, 'epoch': 3.02}                                                                                                                                                 
{'loss': 0.2714, 'learning_rate': 0.00021489218328840968, 'epoch': 3.03}                                                                                                      
{'loss': 0.2134, 'learning_rate': 0.00021448787061994609, 'epoch': 3.04}                                                                                                      
{'loss': 0.1987, 'learning_rate': 0.00021408355795148246, 'epoch': 3.06}                                                                                                      
{'loss': 0.3699, 'learning_rate': 0.00021367924528301884, 'epoch': 3.07}                                                                                                      
{'loss': 0.313, 'learning_rate': 0.00021327493261455525, 'epoch': 3.08}                                                                                                       
{'loss': 0.2586, 'learning_rate': 0.00021287061994609163, 'epoch': 3.1}                                                                                                       
{'loss': 0.232, 'learning_rate': 0.000212466307277628, 'epoch': 3.11}                                                                                                         
{'loss': 0.1748, 'learning_rate': 0.0002120619946091644, 'epoch': 3.12}                                                                                                       
{'loss': 0.4101, 'learning_rate': 0.00021165768194070076, 'epoch': 3.14}                                                                                                      
{'loss': 0.3325, 'learning_rate': 0.00021125336927223717, 'epoch': 3.15}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                        | 2400/7620 [3:31:47<4:30:08,  3.11s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3504549264907837, 'eval_wer': 0.42112821433379705, 'eval_cer': 0.13596988309887062, 'eval_runtime': 289.6731, 'eval_samples_per_second': 6.904, 'eval_steps_per_second': 0.863, 'epoch': 3.15}                                                                                                                                              
{'loss': 0.2088, 'learning_rate': 0.00021084905660377358, 'epoch': 3.16}                                                                                                      
{'loss': 0.2349, 'learning_rate': 0.00021044474393530995, 'epoch': 3.18}                                                                                                      
{'loss': 0.1638, 'learning_rate': 0.00021004043126684633, 'epoch': 3.19}                                                                                                      
{'loss': 0.3671, 'learning_rate': 0.00020963611859838274, 'epoch': 3.2}                                                                                                       
{'loss': 0.3405, 'learning_rate': 0.00020923180592991912, 'epoch': 3.22}                                                                                                      
{'loss': 0.2565, 'learning_rate': 0.0002088274932614555, 'epoch': 3.23}                                                                                                       
{'loss': 0.1703, 'learning_rate': 0.0002084231805929919, 'epoch': 3.24}                                                                                                       
{'loss': 0.2356, 'learning_rate': 0.00020801886792452828, 'epoch': 3.25}                                                                                                      
{'loss': 0.3948, 'learning_rate': 0.0002076145552560647, 'epoch': 3.27}                                                                                                       
{'loss': 0.3412, 'learning_rate': 0.00020721024258760104, 'epoch': 3.28}                                                                                                      
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                      | 2500/7620 [3:41:08<4:24:17,  3.10s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3649960458278656, 'eval_wer': 0.42112821433379705, 'eval_cer': 0.13690509213394095, 'eval_runtime': 291.3701, 'eval_samples_per_second': 6.864, 'eval_steps_per_second': 0.858, 'epoch': 3.28}                                                                                                                                              
{'loss': 0.212, 'learning_rate': 0.00020680592991913744, 'epoch': 3.29}                                                                                                       
{'loss': 0.1815, 'learning_rate': 0.00020640161725067385, 'epoch': 3.31}                                                                                                      
{'loss': 0.2233, 'learning_rate': 0.0002059973045822102, 'epoch': 3.32}                                                                                                       
{'loss': 0.3512, 'learning_rate': 0.0002055929919137466, 'epoch': 3.33}                                                                                                       
{'loss': 0.3, 'learning_rate': 0.000205188679245283, 'epoch': 3.35}                                                                                                           
{'loss': 0.2504, 'learning_rate': 0.0002047843665768194, 'epoch': 3.36}                                                                                                       
{'loss': 0.2069, 'learning_rate': 0.00020438005390835577, 'epoch': 3.37}                                                                                                      
{'loss': 0.195, 'learning_rate': 0.00020397574123989218, 'epoch': 3.39}                                                                                                       
{'loss': 0.4304, 'learning_rate': 0.00020357142857142856, 'epoch': 3.4}                                                                                                       
{'loss': 0.2888, 'learning_rate': 0.00020316711590296493, 'epoch': 3.41}                                                                                                      
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                     | 2600/7620 [3:50:41<4:20:30,  3.11s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.36226025223731995, 'eval_wer': 0.4134542027554638, 'eval_cer': 0.135216960570636, 'eval_runtime': 284.0849, 'eval_samples_per_second': 7.04, 'eval_steps_per_second': 0.88, 'epoch': 3.41}                                                                                                                                                  
{'loss': 0.2204, 'learning_rate': 0.0002027628032345013, 'epoch': 3.43}                                                                                                       
{'loss': 0.2048, 'learning_rate': 0.00020235849056603772, 'epoch': 3.44}                                                                                                      
{'loss': 0.1733, 'learning_rate': 0.00020195417789757412, 'epoch': 3.45}                                                                                                      
{'loss': 0.454, 'learning_rate': 0.00020154986522911048, 'epoch': 3.46}                                                                                                       
{'loss': 0.3473, 'learning_rate': 0.00020114555256064688, 'epoch': 3.48}                                                                                                      
{'loss': 0.2395, 'learning_rate': 0.0002007412398921833, 'epoch': 3.49}                                                                                                       
{'loss': 0.1625, 'learning_rate': 0.00020033692722371964, 'epoch': 3.5}                                                                                                       
{'loss': 0.1949, 'learning_rate': 0.00019993261455525605, 'epoch': 3.52}                                                                                                      
{'loss': 0.4395, 'learning_rate': 0.00019952830188679245, 'epoch': 3.53}                                                                                                      
{'loss': 0.3321, 'learning_rate': 0.00019912398921832883, 'epoch': 3.54}                                                                                                      
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                   | 2700/7620 [3:59:56<4:05:33,  2.99s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3710547685623169, 'eval_wer': 0.4127810438450837, 'eval_cer': 0.1381018426788191, 'eval_runtime': 290.2054, 'eval_samples_per_second': 6.892, 'eval_steps_per_second': 0.861, 'epoch': 3.54}                                                                                                                                                
{'loss': 0.2178, 'learning_rate': 0.0001987196765498652, 'epoch': 3.56}                                                                                                       
{'loss': 0.1658, 'learning_rate': 0.0001983153638814016, 'epoch': 3.57}                                                                                                       
{'loss': 0.1982, 'learning_rate': 0.000197911051212938, 'epoch': 3.58}                                                                                                        
{'loss': 0.3751, 'learning_rate': 0.00019750673854447437, 'epoch': 3.6}                                                                                                       
{'loss': 0.317, 'learning_rate': 0.00019710242587601075, 'epoch': 3.61}                                                                                                       
{'loss': 0.2297, 'learning_rate': 0.00019669811320754716, 'epoch': 3.62}                                                                                                      
{'loss': 0.2206, 'learning_rate': 0.00019629380053908356, 'epoch': 3.64}                                                                                                      
{'loss': 0.2012, 'learning_rate': 0.00019588948787061991, 'epoch': 3.65}                                                                                                      
{'loss': 0.3964, 'learning_rate': 0.00019548517520215632, 'epoch': 3.66}                                                                                                      
{'loss': 0.2837, 'learning_rate': 0.00019508086253369273, 'epoch': 3.67}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                 | 2800/7620 [4:09:15<4:03:05,  3.03s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3488181233406067, 'eval_wer': 0.4002154108513216, 'eval_cer': 0.12867842282544087, 'eval_runtime': 280.6118, 'eval_samples_per_second': 7.127, 'eval_steps_per_second': 0.891, 'epoch': 3.67}                                                                                                                                               
{'loss': 0.2235, 'learning_rate': 0.00019467654986522908, 'epoch': 3.69}                                                                                                      
{'loss': 0.2198, 'learning_rate': 0.00019427223719676548, 'epoch': 3.7}                                                                                                       
{'loss': 0.2042, 'learning_rate': 0.0001938679245283019, 'epoch': 3.71}                                                                                                       
{'loss': 0.364, 'learning_rate': 0.00019346361185983827, 'epoch': 3.73}                                                                                                       
{'loss': 0.3121, 'learning_rate': 0.00019305929919137465, 'epoch': 3.74}                                                                                                      
{'loss': 0.2911, 'learning_rate': 0.00019265498652291103, 'epoch': 3.75}                                                                                                      
{'loss': 0.1723, 'learning_rate': 0.00019225067385444743, 'epoch': 3.77}                                                                                                      
{'loss': 0.1775, 'learning_rate': 0.0001918463611859838, 'epoch': 3.78}                                                                                                       
{'loss': 0.3547, 'learning_rate': 0.0001914420485175202, 'epoch': 3.79}                                                                                                       
{'loss': 0.3266, 'learning_rate': 0.0001910377358490566, 'epoch': 3.81}                                                                                                       
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                | 2900/7620 [4:18:29<4:00:45,  3.06s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34639474749565125, 'eval_wer': 0.40398510074945027, 'eval_cer': 0.1300019813750743, 'eval_runtime': 290.0456, 'eval_samples_per_second': 6.895, 'eval_steps_per_second': 0.862, 'epoch': 3.81}                                                                                                                                              
{'loss': 0.245, 'learning_rate': 0.00019063342318059295, 'epoch': 3.82}                                                                                                       
{'loss': 0.1786, 'learning_rate': 0.00019022911051212935, 'epoch': 3.83}                                                                                                      
{'loss': 0.2196, 'learning_rate': 0.00018982479784366576, 'epoch': 3.85}                                                                                                      
{'loss': 0.3633, 'learning_rate': 0.00018942048517520216, 'epoch': 3.86}                                                                                                      
{'loss': 0.3334, 'learning_rate': 0.00018901617250673852, 'epoch': 3.87}                                                                                                      
{'loss': 0.2293, 'learning_rate': 0.00018861185983827492, 'epoch': 3.88}                                                                                                      
{'loss': 0.1958, 'learning_rate': 0.0001882075471698113, 'epoch': 3.9}                                                                                                        
{'loss': 0.1826, 'learning_rate': 0.00018780323450134768, 'epoch': 3.91}                                                                                                      
{'loss': 0.3969, 'learning_rate': 0.00018739892183288409, 'epoch': 3.92}                                                                                                      
{'loss': 0.3269, 'learning_rate': 0.00018699460916442046, 'epoch': 3.94}                                                                                                      
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                              | 3000/7620 [4:28:02<3:58:53,  3.10s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3487820327281952, 'eval_wer': 0.402549028407306, 'eval_cer': 0.1266970477511393, 'eval_runtime': 293.8165, 'eval_samples_per_second': 6.807, 'eval_steps_per_second': 0.851, 'epoch': 3.94}                                                                                                                                                 
{'loss': 0.2386, 'learning_rate': 0.00018659029649595687, 'epoch': 3.95}                                                                                                      
{'loss': 0.2052, 'learning_rate': 0.00018618598382749322, 'epoch': 3.96}                                                                                                      
{'loss': 0.2386, 'learning_rate': 0.00018578167115902963, 'epoch': 3.98}                                                                                                      
{'loss': 0.3299, 'learning_rate': 0.00018537735849056603, 'epoch': 3.99}                                                                                                      
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                             | 3044/7620 [4:34:46<3:15:41,  2.57s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-3044
Configuration saved in russian_portuguese_high_augmented/checkpoint-3044/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-3044/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-3044/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2254, 'learning_rate': 0.00018497304582210238, 'epoch': 4.0}                                                                                                       
{'loss': 0.2711, 'learning_rate': 0.0001845687331536388, 'epoch': 4.02}                                                                                                       
{'loss': 0.2031, 'learning_rate': 0.0001841644204851752, 'epoch': 4.03}                                                                                                       
{'loss': 0.1483, 'learning_rate': 0.00018376010781671158, 'epoch': 4.04}                                                                                                      
{'loss': 0.2232, 'learning_rate': 0.00018335579514824795, 'epoch': 4.06}                                                                                                      
{'loss': 0.2954, 'learning_rate': 0.00018295148247978436, 'epoch': 4.07}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 3100/7620 [4:37:29<4:19:09,  3.44s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3822433650493622, 'eval_wer': 0.4012924651079298, 'eval_cer': 0.13054091539528434, 'eval_runtime': 284.2361, 'eval_samples_per_second': 7.036, 'eval_steps_per_second': 0.88, 'epoch': 4.07}                                                                                                                                                
{'loss': 0.2866, 'learning_rate': 0.00018254716981132074, 'epoch': 4.08}                                                                                                      
{'loss': 0.1954, 'learning_rate': 0.00018214285714285712, 'epoch': 4.09}                                                                                                      
{'loss': 0.1688, 'learning_rate': 0.00018173854447439352, 'epoch': 4.11}                                                                                                      
{'loss': 0.1382, 'learning_rate': 0.0001813342318059299, 'epoch': 4.12}                                                                                                       
{'loss': 0.2879, 'learning_rate': 0.0001809299191374663, 'epoch': 4.13}                                                                                                       
{'loss': 0.2824, 'learning_rate': 0.00018052560646900266, 'epoch': 4.15}                                                                                                      
{'loss': 0.1904, 'learning_rate': 0.00018012129380053907, 'epoch': 4.16}                                                                                                      
{'loss': 0.1612, 'learning_rate': 0.00017971698113207547, 'epoch': 4.17}                                                                                                      
{'loss': 0.1462, 'learning_rate': 0.00017931266846361182, 'epoch': 4.19}                                                                                                      
{'loss': 0.3098, 'learning_rate': 0.00017890835579514823, 'epoch': 4.2}                                                                                                       
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 3200/7620 [4:46:53<4:05:23,  3.33s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3758239448070526, 'eval_wer': 0.40591482295920656, 'eval_cer': 0.127109173766594, 'eval_runtime': 296.8129, 'eval_samples_per_second': 6.738, 'eval_steps_per_second': 0.842, 'epoch': 4.2}                                                                                                                                                 
{'loss': 0.3086, 'learning_rate': 0.00017850404312668463, 'epoch': 4.21}                                                                                                      
{'loss': 0.2318, 'learning_rate': 0.000178099730458221, 'epoch': 4.23}                                                                                                        
{'loss': 0.1793, 'learning_rate': 0.0001776954177897574, 'epoch': 4.24}                                                                                                       
{'loss': 0.1523, 'learning_rate': 0.0001772911051212938, 'epoch': 4.25}                                                                                                       
{'loss': 0.3091, 'learning_rate': 0.00017688679245283018, 'epoch': 4.27}                                                                                                      
{'loss': 0.2738, 'learning_rate': 0.00017648247978436656, 'epoch': 4.28}                                                                                                      
{'loss': 0.2387, 'learning_rate': 0.00017607816711590293, 'epoch': 4.29}                                                                                                      
{'loss': 0.131, 'learning_rate': 0.00017567385444743934, 'epoch': 4.3}                                                                                                        
{'loss': 0.1673, 'learning_rate': 0.00017526954177897575, 'epoch': 4.32}                                                                                                      
{'loss': 0.3225, 'learning_rate': 0.0001748652291105121, 'epoch': 4.33}                                                                                                       
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                         | 3300/7620 [4:56:30<4:02:13,  3.36s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35577699542045593, 'eval_wer': 0.3970740026028811, 'eval_cer': 0.12680007925500297, 'eval_runtime': 297.2181, 'eval_samples_per_second': 6.729, 'eval_steps_per_second': 0.841, 'epoch': 4.33}                                                                                                                                              
{'loss': 0.3133, 'learning_rate': 0.0001744609164420485, 'epoch': 4.34}                                                                                                       
{'loss': 0.2242, 'learning_rate': 0.0001740566037735849, 'epoch': 4.36}                                                                                                       
{'loss': 0.2356, 'learning_rate': 0.00017365229110512126, 'epoch': 4.37}                                                                                                      
{'loss': 0.1228, 'learning_rate': 0.00017324797843665767, 'epoch': 4.38}                                                                                                      
{'loss': 0.3404, 'learning_rate': 0.00017284366576819407, 'epoch': 4.4}                                                                                                       
{'loss': 0.3129, 'learning_rate': 0.00017243935309973045, 'epoch': 4.41}                                                                                                      
{'loss': 0.1878, 'learning_rate': 0.00017203504043126683, 'epoch': 4.42}                                                                                                      
{'loss': 0.1756, 'learning_rate': 0.0001716307277628032, 'epoch': 4.44}                                                                                                       
{'loss': 0.1593, 'learning_rate': 0.00017122641509433961, 'epoch': 4.45}                                                                                                      
{'loss': 0.2475, 'learning_rate': 0.000170822102425876, 'epoch': 4.46}                                                                                                        
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 3400/7620 [5:06:19<4:02:44,  3.45s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3875501751899719, 'eval_wer': 0.390252658977696, 'eval_cer': 0.12578561521696058, 'eval_runtime': 291.6436, 'eval_samples_per_second': 6.858, 'eval_steps_per_second': 0.857, 'epoch': 4.46}                                                                                                                                                
{'loss': 0.3204, 'learning_rate': 0.00017041778975741237, 'epoch': 4.48}                                                                                                      
{'loss': 0.2177, 'learning_rate': 0.00017001347708894878, 'epoch': 4.49}                                                                                                      
{'loss': 0.1379, 'learning_rate': 0.00016960916442048516, 'epoch': 4.5}                                                                                                       
{'loss': 0.1781, 'learning_rate': 0.00016920485175202154, 'epoch': 4.51}                                                                                                      
{'loss': 0.2601, 'learning_rate': 0.00016880053908355794, 'epoch': 4.53}                                                                                                      
{'loss': 0.2612, 'learning_rate': 0.00016839622641509435, 'epoch': 4.54}                                                                                                      
{'loss': 0.2254, 'learning_rate': 0.0001679919137466307, 'epoch': 4.55}                                                                                                       
{'loss': 0.1426, 'learning_rate': 0.0001675876010781671, 'epoch': 4.57}                                                                                                       
{'loss': 0.1534, 'learning_rate': 0.0001671832884097035, 'epoch': 4.58}                                                                                                       
{'loss': 0.2686, 'learning_rate': 0.00016677897574123986, 'epoch': 4.59}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                     | 3500/7620 [5:15:47<4:12:08,  3.67s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35483983159065247, 'eval_wer': 0.39200287214468427, 'eval_cer': 0.1257935407172578, 'eval_runtime': 284.4733, 'eval_samples_per_second': 7.031, 'eval_steps_per_second': 0.879, 'epoch': 4.59}                                                                                                                                              
{'loss': 0.2635, 'learning_rate': 0.00016637466307277627, 'epoch': 4.61}                                                                                                      
{'loss': 0.2026, 'learning_rate': 0.00016597035040431265, 'epoch': 4.62}                                                                                                      
{'loss': 0.1479, 'learning_rate': 0.00016556603773584905, 'epoch': 4.63}                                                                                                      
{'loss': 0.1535, 'learning_rate': 0.00016516172506738543, 'epoch': 4.65}                                                                                                      
{'loss': 0.2445, 'learning_rate': 0.0001647574123989218, 'epoch': 4.66}                                                                                                       
{'loss': 0.293, 'learning_rate': 0.00016435309973045822, 'epoch': 4.67}                                                                                                       
{'loss': 0.1648, 'learning_rate': 0.00016394878706199457, 'epoch': 4.69}                                                                                                      
{'loss': 0.1897, 'learning_rate': 0.00016354447439353097, 'epoch': 4.7}                                                                                                       
{'loss': 0.179, 'learning_rate': 0.00016314016172506738, 'epoch': 4.71}                                                                                                       
{'loss': 0.2533, 'learning_rate': 0.00016273584905660379, 'epoch': 4.72}                                                                                                      
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                    | 3600/7620 [5:25:00<3:27:07,  3.09s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3643287420272827, 'eval_wer': 0.3828927882242068, 'eval_cer': 0.12103031503863682, 'eval_runtime': 279.0341, 'eval_samples_per_second': 7.168, 'eval_steps_per_second': 0.896, 'epoch': 4.72}                                                                                                                                               
{'loss': 0.2972, 'learning_rate': 0.00016233153638814014, 'epoch': 4.74}                                                                                                      
{'loss': 0.2433, 'learning_rate': 0.00016192722371967654, 'epoch': 4.75}                                                                                                      
{'loss': 0.1756, 'learning_rate': 0.00016152291105121292, 'epoch': 4.76}                                                                                                      
{'loss': 0.148, 'learning_rate': 0.0001611185983827493, 'epoch': 4.78}                                                                                                        
{'loss': 0.2214, 'learning_rate': 0.0001607142857142857, 'epoch': 4.79}                                                                                                       
{'loss': 0.2778, 'learning_rate': 0.00016030997304582208, 'epoch': 4.8}                                                                                                       
{'loss': 0.2271, 'learning_rate': 0.0001599056603773585, 'epoch': 4.82}                                                                                                       
{'loss': 0.2105, 'learning_rate': 0.00015950134770889484, 'epoch': 4.83}                                                                                                      
{'loss': 0.1361, 'learning_rate': 0.00015909703504043125, 'epoch': 4.84}                                                                                                      
{'loss': 0.2513, 'learning_rate': 0.00015869272237196765, 'epoch': 4.86}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 3700/7620 [5:34:18<3:54:58,  3.60s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3730512261390686, 'eval_wer': 0.38612395099403135, 'eval_cer': 0.1239310481474143, 'eval_runtime': 287.6973, 'eval_samples_per_second': 6.952, 'eval_steps_per_second': 0.869, 'epoch': 4.86}                                                                                                                                               
{'loss': 0.2651, 'learning_rate': 0.000158288409703504, 'epoch': 4.87}                                                                                                        
{'loss': 0.1931, 'learning_rate': 0.0001578840970350404, 'epoch': 4.88}                                                                                                       
{'loss': 0.1419, 'learning_rate': 0.00015747978436657682, 'epoch': 4.9}                                                                                                       
{'loss': 0.1519, 'learning_rate': 0.0001570754716981132, 'epoch': 4.91}                                                                                                       
{'loss': 0.2718, 'learning_rate': 0.00015667115902964957, 'epoch': 4.92}                                                                                                      
{'loss': 0.3138, 'learning_rate': 0.00015626684636118598, 'epoch': 4.93}                                                                                                      
{'loss': 0.1942, 'learning_rate': 0.00015586253369272236, 'epoch': 4.95}                                                                                                      
{'loss': 0.1561, 'learning_rate': 0.00015545822102425874, 'epoch': 4.96}                                                                                                      
{'loss': 0.1167, 'learning_rate': 0.00015505390835579514, 'epoch': 4.97}                                                                                                      
{'loss': 0.2192, 'learning_rate': 0.00015464959568733152, 'epoch': 4.99}                                                                                                      
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                | 3800/7620 [5:43:42<3:07:59,  2.95s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3824385106563568, 'eval_wer': 0.3846878786518871, 'eval_cer': 0.12340003962750148, 'eval_runtime': 276.6418, 'eval_samples_per_second': 7.23, 'eval_steps_per_second': 0.904, 'epoch': 4.99}                                                                                                                                                
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 3805/7620 [5:48:31<23:47:42, 22.45s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-3805                                                                                                  
Configuration saved in russian_portuguese_high_augmented/checkpoint-3805/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-3805/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-3805/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2404, 'learning_rate': 0.00015424528301886793, 'epoch': 5.0}                                                                                                       
{'loss': 0.2545, 'learning_rate': 0.00015384097035040428, 'epoch': 5.01}                                                                                                      
{'loss': 0.2158, 'learning_rate': 0.00015343665768194069, 'epoch': 5.03}                                                                                                      
{'loss': 0.1722, 'learning_rate': 0.0001530323450134771, 'epoch': 5.04}                                                                                                       
{'loss': 0.1567, 'learning_rate': 0.00015262803234501344, 'epoch': 5.05}                                                                                                      
{'loss': 0.2024, 'learning_rate': 0.00015222371967654985, 'epoch': 5.07}                                                                                                      
{'loss': 0.2708, 'learning_rate': 0.00015181940700808626, 'epoch': 5.08}                                                                                                      
{'loss': 0.1819, 'learning_rate': 0.00015141509433962263, 'epoch': 5.09}                                                                                                      
{'loss': 0.1222, 'learning_rate': 0.000151010781671159, 'epoch': 5.1}                                                                                                         
{'loss': 0.1142, 'learning_rate': 0.00015060646900269542, 'epoch': 5.12}                                                                                                      
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 3900/7620 [5:52:57<2:18:41,  2.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3737929165363312, 'eval_wer': 0.37692411255216984, 'eval_cer': 0.12068159302555974, 'eval_runtime': 273.4204, 'eval_samples_per_second': 7.315, 'eval_steps_per_second': 0.914, 'epoch': 5.12}                                                                                                                                              
{'loss': 0.1917, 'learning_rate': 0.0001502021563342318, 'epoch': 5.13}                                                                                                       
{'loss': 0.3003, 'learning_rate': 0.00014979784366576818, 'epoch': 5.14}                                                                                                      
{'loss': 0.1954, 'learning_rate': 0.00014939353099730455, 'epoch': 5.16}                                                                                                      
{'loss': 0.1756, 'learning_rate': 0.00014898921832884096, 'epoch': 5.17}                                                                                                      
{'loss': 0.1011, 'learning_rate': 0.00014858490566037734, 'epoch': 5.18}                                                                                                      
{'loss': 0.2017, 'learning_rate': 0.00014818059299191372, 'epoch': 5.2}                                                                                                       
{'loss': 0.2463, 'learning_rate': 0.00014777628032345012, 'epoch': 5.21}                                                                                                      
{'loss': 0.1788, 'learning_rate': 0.0001473719676549865, 'epoch': 5.22}                                                                                                       
{'loss': 0.0872, 'learning_rate': 0.0001469676549865229, 'epoch': 5.24}                                                                                                       
{'loss': 0.1286, 'learning_rate': 0.0001465633423180593, 'epoch': 5.25}                                                                                                       
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                             | 4000/7620 [6:02:01<2:19:06,  2.31s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3763212263584137, 'eval_wer': 0.3768792352914778, 'eval_cer': 0.11888250445809392, 'eval_runtime': 281.9389, 'eval_samples_per_second': 7.094, 'eval_steps_per_second': 0.887, 'epoch': 5.25}                                                                                                                                               
{'loss': 0.1987, 'learning_rate': 0.0001461590296495957, 'epoch': 5.26}                                                                                                       
{'loss': 0.267, 'learning_rate': 0.00014575471698113207, 'epoch': 5.28}                                                                                                       
{'loss': 0.1786, 'learning_rate': 0.00014535040431266845, 'epoch': 5.29}                                                                                                      
{'loss': 0.1193, 'learning_rate': 0.00014494609164420483, 'epoch': 5.3}                                                                                                       
{'loss': 0.1212, 'learning_rate': 0.00014454177897574124, 'epoch': 5.31}                                                                                                      
{'loss': 0.189, 'learning_rate': 0.00014413746630727761, 'epoch': 5.33}                                                                                                       
{'loss': 0.3073, 'learning_rate': 0.000143733153638814, 'epoch': 5.34}                                                                                                        
{'loss': 0.1496, 'learning_rate': 0.00014332884097035037, 'epoch': 5.35}                                                                                                      
{'loss': 0.1327, 'learning_rate': 0.00014292452830188678, 'epoch': 5.37}                                                                                                      
{'loss': 0.0982, 'learning_rate': 0.00014252021563342316, 'epoch': 5.38}                                                                                                      
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 4100/7620 [6:11:14<2:13:16,  2.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.356291800737381, 'eval_wer': 0.37414172238926535, 'eval_cer': 0.11776500891618784, 'eval_runtime': 280.3821, 'eval_samples_per_second': 7.133, 'eval_steps_per_second': 0.892, 'epoch': 5.38}                                                                                                                                               
{'loss': 0.2088, 'learning_rate': 0.00014211590296495956, 'epoch': 5.39}                                                                                                      
{'loss': 0.2522, 'learning_rate': 0.00014171159029649594, 'epoch': 5.41}                                                                                                      
{'loss': 0.1942, 'learning_rate': 0.00014130727762803235, 'epoch': 5.42}                                                                                                      
{'loss': 0.1756, 'learning_rate': 0.00014090296495956873, 'epoch': 5.43}                                                                                                      
{'loss': 0.149, 'learning_rate': 0.0001404986522911051, 'epoch': 5.45}                                                                                                        
{'loss': 0.2034, 'learning_rate': 0.0001400943396226415, 'epoch': 5.46}                                                                                                       
{'loss': 0.291, 'learning_rate': 0.0001396900269541779, 'epoch': 5.47}                                                                                                        
{'loss': 0.1878, 'learning_rate': 0.00013928571428571427, 'epoch': 5.49}                                                                                                      
{'loss': 0.1474, 'learning_rate': 0.00013888140161725065, 'epoch': 5.5}                                                                                                       
{'loss': 0.1194, 'learning_rate': 0.00013847708894878705, 'epoch': 5.51}                                                                                                      
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 4200/7620 [6:20:22<2:09:16,  2.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.371848464012146, 'eval_wer': 0.3736929497823453, 'eval_cer': 0.12261541509807806, 'eval_runtime': 277.7577, 'eval_samples_per_second': 7.201, 'eval_steps_per_second': 0.9, 'epoch': 5.51}                                                                                                                                                  
{'loss': 0.176, 'learning_rate': 0.00013807277628032343, 'epoch': 5.52}                                                                                                       
{'loss': 0.2777, 'learning_rate': 0.0001376684636118598, 'epoch': 5.54}                                                                                                       
{'loss': 0.1884, 'learning_rate': 0.00013726415094339622, 'epoch': 5.55}                                                                                                      
{'loss': 0.1342, 'learning_rate': 0.0001368598382749326, 'epoch': 5.56}                                                                                                       
{'loss': 0.0921, 'learning_rate': 0.000136455525606469, 'epoch': 5.58}                                                                                                        
{'loss': 0.1651, 'learning_rate': 0.00013605121293800538, 'epoch': 5.59}                                                                                                      
{'loss': 0.2361, 'learning_rate': 0.00013564690026954178, 'epoch': 5.6}                                                                                                       
{'loss': 0.1376, 'learning_rate': 0.00013524258760107816, 'epoch': 5.62}                                                                                                      
{'loss': 0.1441, 'learning_rate': 0.00013483827493261454, 'epoch': 5.63}                                                                                                      
{'loss': 0.1006, 'learning_rate': 0.00013443396226415095, 'epoch': 5.64}                                                                                                      
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 4300/7620 [6:29:38<2:16:17,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3672069013118744, 'eval_wer': 0.3701476461876767, 'eval_cer': 0.11778085991678225, 'eval_runtime': 298.583, 'eval_samples_per_second': 6.698, 'eval_steps_per_second': 0.837, 'epoch': 5.64}                                                                                                                                                
{'loss': 0.2046, 'learning_rate': 0.00013402964959568733, 'epoch': 5.66}                                                                                                      
{'loss': 0.2576, 'learning_rate': 0.0001336253369272237, 'epoch': 5.67}                                                                                                       
{'loss': 0.1684, 'learning_rate': 0.00013322102425876008, 'epoch': 5.68}                                                                                                      
{'loss': 0.1292, 'learning_rate': 0.00013281671159029646, 'epoch': 5.7}                                                                                                       
{'loss': 0.1227, 'learning_rate': 0.00013241239892183287, 'epoch': 5.71}                                                                                                      
{'loss': 0.1629, 'learning_rate': 0.00013200808625336925, 'epoch': 5.72}                                                                                                      
{'loss': 0.2415, 'learning_rate': 0.00013160377358490565, 'epoch': 5.73}                                                                                                      
{'loss': 0.2206, 'learning_rate': 0.00013119946091644203, 'epoch': 5.75}                                                                                                      
{'loss': 0.1273, 'learning_rate': 0.00013079514824797844, 'epoch': 5.76}                                                                                                      
{'loss': 0.1179, 'learning_rate': 0.00013039083557951482, 'epoch': 5.77}                                                                                                      
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 4400/7620 [6:39:14<2:10:13,  2.43s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3650134205818176, 'eval_wer': 0.371808104833281, 'eval_cer': 0.12072122052704577, 'eval_runtime': 295.3632, 'eval_samples_per_second': 6.771, 'eval_steps_per_second': 0.846, 'epoch': 5.77}                                                                                                                                                
{'loss': 0.1861, 'learning_rate': 0.0001299865229110512, 'epoch': 5.79}                                                                                                       
{'loss': 0.2816, 'learning_rate': 0.0001295822102425876, 'epoch': 5.8}                                                                                                        
{'loss': 0.2059, 'learning_rate': 0.00012917789757412398, 'epoch': 5.81}                                                                                                      
{'loss': 0.1216, 'learning_rate': 0.00012877358490566036, 'epoch': 5.83}                                                                                                      
{'loss': 0.1509, 'learning_rate': 0.00012836927223719677, 'epoch': 5.84}                                                                                                      
{'loss': 0.1601, 'learning_rate': 0.00012796495956873314, 'epoch': 5.85}                                                                                                      
{'loss': 0.2282, 'learning_rate': 0.00012756064690026952, 'epoch': 5.87}                                                                                                      
{'loss': 0.1872, 'learning_rate': 0.0001271563342318059, 'epoch': 5.88}                                                                                                       
{'loss': 0.1363, 'learning_rate': 0.0001267520215633423, 'epoch': 5.89}                                                                                                       
{'loss': 0.1407, 'learning_rate': 0.00012634770889487869, 'epoch': 5.91}                                                                                                      
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 4500/7620 [6:48:51<2:03:47,  2.38s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34586673974990845, 'eval_wer': 0.3677242741103083, 'eval_cer': 0.11955617198335645, 'eval_runtime': 290.2687, 'eval_samples_per_second': 6.89, 'eval_steps_per_second': 0.861, 'epoch': 5.91}                                                                                                                                               
{'loss': 0.1905, 'learning_rate': 0.0001259433962264151, 'epoch': 5.92}                                                                                                       
{'loss': 0.2573, 'learning_rate': 0.00012553908355795147, 'epoch': 5.93}                                                                                                      
{'loss': 0.1667, 'learning_rate': 0.00012513477088948788, 'epoch': 5.94}                                                                                                      
{'loss': 0.1428, 'learning_rate': 0.00012473045822102426, 'epoch': 5.96}                                                                                                      
{'loss': 0.1084, 'learning_rate': 0.00012432614555256063, 'epoch': 5.97}                                                                                                      
{'loss': 0.2218, 'learning_rate': 0.00012392183288409704, 'epoch': 5.98}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                   | 4566/7620 [6:56:35<2:27:25,  2.90s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-4566
Configuration saved in russian_portuguese_high_augmented/checkpoint-4566/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-4566/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-4566/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1573, 'learning_rate': 0.00012351752021563342, 'epoch': 6.0}                                                                                                       
{'loss': 0.2048, 'learning_rate': 0.0001231132075471698, 'epoch': 6.01}                                                                                                       
{'loss': 0.1941, 'learning_rate': 0.00012270889487870618, 'epoch': 6.02}                                                                                                      
{'loss': 0.1202, 'learning_rate': 0.00012230458221024258, 'epoch': 6.04}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 4600/7620 [6:58:28<2:08:57,  2.56s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3389391005039215, 'eval_wer': 0.36498676120809587, 'eval_cer': 0.12007925500297206, 'eval_runtime': 306.4219, 'eval_samples_per_second': 6.527, 'eval_steps_per_second': 0.816, 'epoch': 6.04}                                                                                                                                              
{'loss': 0.1015, 'learning_rate': 0.00012190026954177896, 'epoch': 6.05}                                                                                                      
{'loss': 0.142, 'learning_rate': 0.00012149595687331535, 'epoch': 6.06}                                                                                                       
{'loss': 0.2436, 'learning_rate': 0.00012109164420485175, 'epoch': 6.08}                                                                                                      
{'loss': 0.1454, 'learning_rate': 0.00012068733153638812, 'epoch': 6.09}                                                                                                      
{'loss': 0.1117, 'learning_rate': 0.00012028301886792453, 'epoch': 6.1}                                                                                                       
{'loss': 0.1045, 'learning_rate': 0.00011987870619946091, 'epoch': 6.12}                                                                                                      
{'loss': 0.0953, 'learning_rate': 0.00011947439353099729, 'epoch': 6.13}                                                                                                      
{'loss': 0.2363, 'learning_rate': 0.00011907008086253368, 'epoch': 6.14}                                                                                                      
{'loss': 0.1752, 'learning_rate': 0.00011866576819407007, 'epoch': 6.15}                                                                                                      
{'loss': 0.1075, 'learning_rate': 0.00011826145552560646, 'epoch': 6.17}                                                                                                      
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 4700/7620 [7:08:12<2:12:20,  2.72s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34998029470443726, 'eval_wer': 0.36076829870304716, 'eval_cer': 0.11694075688527839, 'eval_runtime': 293.3723, 'eval_samples_per_second': 6.817, 'eval_steps_per_second': 0.852, 'epoch': 6.17}                                                                                                                                             
{'loss': 0.1024, 'learning_rate': 0.00011785714285714284, 'epoch': 6.18}                                                                                                      
{'loss': 0.1249, 'learning_rate': 0.00011745283018867925, 'epoch': 6.19}                                                                                                      
{'loss': 0.2467, 'learning_rate': 0.00011704851752021563, 'epoch': 6.21}                                                                                                      
{'loss': 0.1176, 'learning_rate': 0.000116644204851752, 'epoch': 6.22}                                                                                                        
{'loss': 0.1448, 'learning_rate': 0.0001162398921832884, 'epoch': 6.23}                                                                                                       
{'loss': 0.09, 'learning_rate': 0.00011583557951482478, 'epoch': 6.25}                                                                                                        
{'loss': 0.1116, 'learning_rate': 0.00011543126684636118, 'epoch': 6.26}                                                                                                      
{'loss': 0.2341, 'learning_rate': 0.00011502695417789756, 'epoch': 6.27}                                                                                                      
{'loss': 0.1753, 'learning_rate': 0.00011462264150943395, 'epoch': 6.29}                                                                                                      
{'loss': 0.1301, 'learning_rate': 0.00011421832884097035, 'epoch': 6.3}                                                                                                       
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 4800/7620 [7:17:37<1:55:45,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34797847270965576, 'eval_wer': 0.3635955661266436, 'eval_cer': 0.12014265900534972, 'eval_runtime': 274.8435, 'eval_samples_per_second': 7.277, 'eval_steps_per_second': 0.91, 'epoch': 6.3}                                                                                                                                                
{'loss': 0.1095, 'learning_rate': 0.00011381401617250673, 'epoch': 6.31}                                                                                                      
{'loss': 0.1433, 'learning_rate': 0.00011340970350404312, 'epoch': 6.33}                                                                                                      
{'loss': 0.2268, 'learning_rate': 0.0001130053908355795, 'epoch': 6.34}                                                                                                       
{'loss': 0.1867, 'learning_rate': 0.0001126010781671159, 'epoch': 6.35}                                                                                                       
{'loss': 0.1152, 'learning_rate': 0.00011219676549865228, 'epoch': 6.36}                                                                                                      
{'loss': 0.1101, 'learning_rate': 0.00011179245283018866, 'epoch': 6.38}                                                                                                      
{'loss': 0.1412, 'learning_rate': 0.00011138814016172507, 'epoch': 6.39}                                                                                                      
{'loss': 0.2638, 'learning_rate': 0.00011098382749326144, 'epoch': 6.4}                                                                                                       
{'loss': 0.125, 'learning_rate': 0.00011057951482479784, 'epoch': 6.42}                                                                                                       
{'loss': 0.104, 'learning_rate': 0.00011017520215633422, 'epoch': 6.43}                                                                                                       
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 4900/7620 [7:26:43<1:58:06,  2.61s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3521043658256531, 'eval_wer': 0.36130682583135126, 'eval_cer': 0.11965127798692292, 'eval_runtime': 287.5779, 'eval_samples_per_second': 6.955, 'eval_steps_per_second': 0.869, 'epoch': 6.43}                                                                                                                                              
{'loss': 0.1386, 'learning_rate': 0.00010977088948787062, 'epoch': 6.44}                                                                                                      
{'loss': 0.1377, 'learning_rate': 0.000109366576819407, 'epoch': 6.46}                                                                                                        
{'loss': 0.2466, 'learning_rate': 0.00010896226415094338, 'epoch': 6.47}                                                                                                      
{'loss': 0.1549, 'learning_rate': 0.00010855795148247977, 'epoch': 6.48}                                                                                                      
{'loss': 0.127, 'learning_rate': 0.00010815363881401616, 'epoch': 6.5}                                                                                                        
{'loss': 0.1113, 'learning_rate': 0.00010774932614555256, 'epoch': 6.51}                                                                                                      
{'loss': 0.152, 'learning_rate': 0.00010734501347708893, 'epoch': 6.52}                                                                                                       
{'loss': 0.1944, 'learning_rate': 0.00010694070080862534, 'epoch': 6.54}                                                                                                      
{'loss': 0.1602, 'learning_rate': 0.00010653638814016172, 'epoch': 6.55}                                                                                                      
{'loss': 0.1033, 'learning_rate': 0.0001061320754716981, 'epoch': 6.56}                                                                                                       
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 5000/7620 [7:36:06<1:52:53,  2.59s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35070204734802246, 'eval_wer': 0.3653906565543239, 'eval_cer': 0.123534773132554, 'eval_runtime': 284.701, 'eval_samples_per_second': 7.025, 'eval_steps_per_second': 0.878, 'epoch': 6.56}                                                                                                                                                 
{'loss': 0.0917, 'learning_rate': 0.00010572776280323449, 'epoch': 6.57}                                                                                                      
{'loss': 0.1112, 'learning_rate': 0.00010532345013477088, 'epoch': 6.59}                                                                                                      
{'loss': 0.3001, 'learning_rate': 0.00010491913746630727, 'epoch': 6.6}                                                                                                       
{'loss': 0.1585, 'learning_rate': 0.00010451482479784365, 'epoch': 6.61}                                                                                                      
{'loss': 0.1141, 'learning_rate': 0.00010411051212938006, 'epoch': 6.63}                                                                                                      
{'loss': 0.1433, 'learning_rate': 0.00010370619946091644, 'epoch': 6.64}                                                                                                      
{'loss': 0.1424, 'learning_rate': 0.00010330188679245282, 'epoch': 6.65}                                                                                                      
{'loss': 0.2096, 'learning_rate': 0.00010289757412398921, 'epoch': 6.67}                                                                                                      
{'loss': 0.1311, 'learning_rate': 0.00010249326145552559, 'epoch': 6.68}                                                                                                      
{'loss': 0.121, 'learning_rate': 0.000102088948787062, 'epoch': 6.69}                                                                                                         
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                          | 5100/7620 [7:45:16<1:43:37,  2.47s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35362452268600464, 'eval_wer': 0.3608131759637392, 'eval_cer': 0.12602338022587675, 'eval_runtime': 276.5883, 'eval_samples_per_second': 7.231, 'eval_steps_per_second': 0.904, 'epoch': 6.69}                                                                                                                                              
{'loss': 0.0917, 'learning_rate': 0.00010168463611859837, 'epoch': 6.71}                                                                                                      
{'loss': 0.1471, 'learning_rate': 0.00010128032345013475, 'epoch': 6.72}                                                                                                      
{'loss': 0.2453, 'learning_rate': 0.00010087601078167116, 'epoch': 6.73}                                                                                                      
{'loss': 0.1694, 'learning_rate': 0.00010047169811320754, 'epoch': 6.75}                                                                                                      
{'loss': 0.1308, 'learning_rate': 0.00010006738544474393, 'epoch': 6.76}                                                                                                      
{'loss': 0.1083, 'learning_rate': 9.966307277628031e-05, 'epoch': 6.77}                                                                                                       
{'loss': 0.1306, 'learning_rate': 9.925876010781671e-05, 'epoch': 6.78}                                                                                                       
{'loss': 0.223, 'learning_rate': 9.885444743935309e-05, 'epoch': 6.8}                                                                                                         
{'loss': 0.151, 'learning_rate': 9.845013477088947e-05, 'epoch': 6.81}                                                                                                        
{'loss': 0.1002, 'learning_rate': 9.804582210242588e-05, 'epoch': 6.82}                                                                                                       
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                         | 5200/7620 [7:54:28<1:44:11,  2.58s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.33431705832481384, 'eval_wer': 0.3580756630615267, 'eval_cer': 0.12192589657222112, 'eval_runtime': 289.8763, 'eval_samples_per_second': 6.899, 'eval_steps_per_second': 0.862, 'epoch': 6.82}                                                                                                                                              
{'loss': 0.1074, 'learning_rate': 9.764150943396225e-05, 'epoch': 6.84}                                                                                                       
{'loss': 0.1288, 'learning_rate': 9.723719676549865e-05, 'epoch': 6.85}                                                                                                       
{'loss': 0.2768, 'learning_rate': 9.683288409703503e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.1646, 'learning_rate': 9.642857142857143e-05, 'epoch': 6.88}                                                                                                       
{'loss': 0.1238, 'learning_rate': 9.602425876010781e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.0669, 'learning_rate': 9.561994609164419e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.1348, 'learning_rate': 9.521563342318058e-05, 'epoch': 6.92}                                                                                                       
{'loss': 0.2405, 'learning_rate': 9.481132075471697e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1756, 'learning_rate': 9.440700808625337e-05, 'epoch': 6.94}                                                                                                       
{'loss': 0.1082, 'learning_rate': 9.400269541778974e-05, 'epoch': 6.96}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 5300/7620 [8:03:47<1:35:29,  2.47s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3305785655975342, 'eval_wer': 0.35668446798007447, 'eval_cer': 0.12286903110758866, 'eval_runtime': 271.484, 'eval_samples_per_second': 7.367, 'eval_steps_per_second': 0.921, 'epoch': 6.96}                                                                                                                                               
{'loss': 0.0947, 'learning_rate': 9.359838274932615e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.1304, 'learning_rate': 9.319407008086253e-05, 'epoch': 6.98}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 5327/7620 [8:09:22<1:48:11,  2.83s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-5327
Configuration saved in russian_portuguese_high_augmented/checkpoint-5327/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-5327/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-5327/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.148, 'learning_rate': 9.278975741239891e-05, 'epoch': 6.99}                                                                                                        
{'loss': 0.1613, 'learning_rate': 9.23854447439353e-05, 'epoch': 7.01}                                                                                                        
{'loss': 0.1401, 'learning_rate': 9.198113207547169e-05, 'epoch': 7.02}                                                                                                       
{'loss': 0.0901, 'learning_rate': 9.157681940700809e-05, 'epoch': 7.03}                                                                                                       
{'loss': 0.0969, 'learning_rate': 9.117250673854446e-05, 'epoch': 7.05}                                                                                                       
{'loss': 0.0995, 'learning_rate': 9.076819407008084e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.22, 'learning_rate': 9.036388140161725e-05, 'epoch': 7.07}                                                                                                         
{'loss': 0.158, 'learning_rate': 8.995956873315363e-05, 'epoch': 7.09}                                                                                                        
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 5400/7620 [8:13:00<1:51:59,  3.03s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3549298644065857, 'eval_wer': 0.3592424718395189, 'eval_cer': 0.12141073905290271, 'eval_runtime': 292.5946, 'eval_samples_per_second': 6.835, 'eval_steps_per_second': 0.854, 'epoch': 7.09}                                                                                                                                               
{'loss': 0.1074, 'learning_rate': 8.955525606469002e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.0921, 'learning_rate': 8.91509433962264e-05, 'epoch': 7.11}                                                                                                        
{'loss': 0.0886, 'learning_rate': 8.87466307277628e-05, 'epoch': 7.13}                                                                                                        
{'loss': 0.2016, 'learning_rate': 8.834231805929918e-05, 'epoch': 7.14}                                                                                                       
{'loss': 0.1455, 'learning_rate': 8.793800539083556e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.1075, 'learning_rate': 8.753369272237197e-05, 'epoch': 7.17}                                                                                                       
{'loss': 0.0799, 'learning_rate': 8.712938005390835e-05, 'epoch': 7.18}                                                                                                       
{'loss': 0.0962, 'learning_rate': 8.672506738544474e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.2323, 'learning_rate': 8.632075471698112e-05, 'epoch': 7.2}                                                                                                        
{'loss': 0.1641, 'learning_rate': 8.591644204851752e-05, 'epoch': 7.22}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    | 5500/7620 [8:22:18<1:45:15,  2.98s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3326530456542969, 'eval_wer': 0.3521518646501818, 'eval_cer': 0.11476124430354666, 'eval_runtime': 280.0245, 'eval_samples_per_second': 7.142, 'eval_steps_per_second': 0.893, 'epoch': 7.22}                                                                                                                                               
{'loss': 0.123, 'learning_rate': 8.55121293800539e-05, 'epoch': 7.23}                                                                                                         
{'loss': 0.1071, 'learning_rate': 8.510781671159028e-05, 'epoch': 7.24}                                                                                                       
{'loss': 0.1372, 'learning_rate': 8.470350404312669e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.2252, 'learning_rate': 8.429919137466307e-05, 'epoch': 7.27}                                                                                                       
{'loss': 0.1405, 'learning_rate': 8.389487870619946e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.0937, 'learning_rate': 8.349056603773584e-05, 'epoch': 7.3}                                                                                                        
{'loss': 0.0898, 'learning_rate': 8.308625336927224e-05, 'epoch': 7.31}                                                                                                       
{'loss': 0.1192, 'learning_rate': 8.268194070080862e-05, 'epoch': 7.32}                                                                                                       
{'loss': 0.1862, 'learning_rate': 8.2277628032345e-05, 'epoch': 7.34}                                                                                                         
{'loss': 0.1462, 'learning_rate': 8.187331536388139e-05, 'epoch': 7.35}                                                                                                       
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                  | 5600/7620 [8:31:25<1:41:19,  3.01s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.32843390107154846, 'eval_wer': 0.34856168379482116, 'eval_cer': 0.11522092332078462, 'eval_runtime': 276.0006, 'eval_samples_per_second': 7.246, 'eval_steps_per_second': 0.906, 'epoch': 7.35}                                                                                                                                             
{'loss': 0.1062, 'learning_rate': 8.146900269541778e-05, 'epoch': 7.36}                                                                                                       
{'loss': 0.0931, 'learning_rate': 8.106469002695418e-05, 'epoch': 7.38}                                                                                                       
{'loss': 0.0682, 'learning_rate': 8.066037735849056e-05, 'epoch': 7.39}                                                                                                       
{'loss': 0.2336, 'learning_rate': 8.025606469002693e-05, 'epoch': 7.4}                                                                                                        
{'loss': 0.1625, 'learning_rate': 7.985175202156334e-05, 'epoch': 7.41}                                                                                                       
{'loss': 0.1099, 'learning_rate': 7.944743935309972e-05, 'epoch': 7.43}                                                                                                       
{'loss': 0.098, 'learning_rate': 7.904312668463611e-05, 'epoch': 7.44}                                                                                                        
{'loss': 0.0793, 'learning_rate': 7.86388140161725e-05, 'epoch': 7.45}                                                                                                        
{'loss': 0.1982, 'learning_rate': 7.82345013477089e-05, 'epoch': 7.47}                                                                                                        
{'loss': 0.1702, 'learning_rate': 7.783018867924527e-05, 'epoch': 7.48}                                                                                                       
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                | 5700/7620 [8:40:32<1:34:59,  2.97s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3472740352153778, 'eval_wer': 0.34595880267468476, 'eval_cer': 0.1155696453338617, 'eval_runtime': 286.9538, 'eval_samples_per_second': 6.97, 'eval_steps_per_second': 0.871, 'epoch': 7.48}                                                                                                                                                
{'loss': 0.1082, 'learning_rate': 7.742587601078165e-05, 'epoch': 7.49}                                                                                                       
{'loss': 0.0889, 'learning_rate': 7.702156334231806e-05, 'epoch': 7.51}                                                                                                       
{'loss': 0.0976, 'learning_rate': 7.661725067385444e-05, 'epoch': 7.52}                                                                                                       
{'loss': 0.2266, 'learning_rate': 7.621293800539083e-05, 'epoch': 7.53}                                                                                                       
{'loss': 0.1553, 'learning_rate': 7.580862533692721e-05, 'epoch': 7.55}                                                                                                       
{'loss': 0.1158, 'learning_rate': 7.540431266846361e-05, 'epoch': 7.56}                                                                                                       
{'loss': 0.0907, 'learning_rate': 7.5e-05, 'epoch': 7.57}                                                                                                                     
{'loss': 0.1038, 'learning_rate': 7.459568733153639e-05, 'epoch': 7.59}                                                                                                       
{'loss': 0.2262, 'learning_rate': 7.419137466307278e-05, 'epoch': 7.6}                                                                                                        
{'loss': 0.1377, 'learning_rate': 7.378706199460916e-05, 'epoch': 7.61}                                                                                                       
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 5800/7620 [8:49:51<1:34:44,  3.12s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3292393088340759, 'eval_wer': 0.34551003006776465, 'eval_cer': 0.11314444224291659, 'eval_runtime': 293.1303, 'eval_samples_per_second': 6.823, 'eval_steps_per_second': 0.853, 'epoch': 7.61}                                                                                                                                              
{'loss': 0.1216, 'learning_rate': 7.338274932614555e-05, 'epoch': 7.62}                                                                                                       
{'loss': 0.0846, 'learning_rate': 7.297843665768193e-05, 'epoch': 7.64}                                                                                                       
{'loss': 0.0966, 'learning_rate': 7.257412398921832e-05, 'epoch': 7.65}                                                                                                       
{'loss': 0.1975, 'learning_rate': 7.216981132075471e-05, 'epoch': 7.66}                                                                                                       
{'loss': 0.1451, 'learning_rate': 7.17654986522911e-05, 'epoch': 7.68}                                                                                                        
{'loss': 0.1198, 'learning_rate': 7.136118598382748e-05, 'epoch': 7.69}                                                                                                       
{'loss': 0.0872, 'learning_rate': 7.095687331536388e-05, 'epoch': 7.7}                                                                                                        
{'loss': 0.1002, 'learning_rate': 7.055256064690025e-05, 'epoch': 7.72}                                                                                                       
{'loss': 0.2042, 'learning_rate': 7.014824797843665e-05, 'epoch': 7.73}                                                                                                       
{'loss': 0.1722, 'learning_rate': 6.974393530997304e-05, 'epoch': 7.74}                                                                                                       
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                             | 5900/7620 [8:59:15<1:25:52,  3.00s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3327883183956146, 'eval_wer': 0.34672171610644886, 'eval_cer': 0.11624331285912423, 'eval_runtime': 282.6628, 'eval_samples_per_second': 7.076, 'eval_steps_per_second': 0.884, 'epoch': 7.74}                                                                                                                                              
{'loss': 0.0882, 'learning_rate': 6.933962264150943e-05, 'epoch': 7.76}                                                                                                       
{'loss': 0.0724, 'learning_rate': 6.893530997304582e-05, 'epoch': 7.77}                                                                                                       
{'loss': 0.1151, 'learning_rate': 6.85309973045822e-05, 'epoch': 7.78}                                                                                                        
{'loss': 0.184, 'learning_rate': 6.81266846361186e-05, 'epoch': 7.8}                                                                                                          
{'loss': 0.1248, 'learning_rate': 6.772237196765497e-05, 'epoch': 7.81}                                                                                                       
{'loss': 0.1032, 'learning_rate': 6.731805929919137e-05, 'epoch': 7.82}                                                                                                       
{'loss': 0.0964, 'learning_rate': 6.691374663072776e-05, 'epoch': 7.83}                                                                                                       
{'loss': 0.1219, 'learning_rate': 6.650943396226415e-05, 'epoch': 7.85}                                                                                                       
{'loss': 0.1963, 'learning_rate': 6.610512129380054e-05, 'epoch': 7.86}                                                                                                       
{'loss': 0.1671, 'learning_rate': 6.570080862533692e-05, 'epoch': 7.87}                                                                                                       
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6000/7620 [9:08:25<1:20:24,  2.98s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.32988303899765015, 'eval_wer': 0.3463178207602208, 'eval_cer': 0.11331087774915792, 'eval_runtime': 277.7464, 'eval_samples_per_second': 7.201, 'eval_steps_per_second': 0.9, 'epoch': 7.87}                                                                                                                                                
{'loss': 0.1158, 'learning_rate': 6.52964959568733e-05, 'epoch': 7.89}                                                                                                        
{'loss': 0.1333, 'learning_rate': 6.489218328840969e-05, 'epoch': 7.9}                                                                                                        
{'loss': 0.0843, 'learning_rate': 6.448787061994608e-05, 'epoch': 7.91}                                                                                                       
{'loss': 0.174, 'learning_rate': 6.408355795148248e-05, 'epoch': 7.93}                                                                                                        
{'loss': 0.1229, 'learning_rate': 6.367924528301887e-05, 'epoch': 7.94}                                                                                                       
{'loss': 0.1155, 'learning_rate': 6.327493261455525e-05, 'epoch': 7.95}                                                                                                       
{'loss': 0.0776, 'learning_rate': 6.287061994609164e-05, 'epoch': 7.97}                                                                                                       
{'loss': 0.1391, 'learning_rate': 6.246630727762802e-05, 'epoch': 7.98}                                                                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 6088/7620 [9:16:55<1:14:16,  2.91s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-6088
Configuration saved in russian_portuguese_high_augmented/checkpoint-6088/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-6088/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-6088/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1355, 'learning_rate': 6.206199460916441e-05, 'epoch': 7.99}                                                                                                       
{'loss': 0.2061, 'learning_rate': 6.16576819407008e-05, 'epoch': 8.01}                                                                                                        
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 6100/7620 [9:17:42<1:32:19,  3.64s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.33898359537124634, 'eval_wer': 0.34497150293946055, 'eval_cer': 0.11094115316029324, 'eval_runtime': 290.3724, 'eval_samples_per_second': 6.888, 'eval_steps_per_second': 0.861, 'epoch': 8.01}                                                                                                                                             
{'loss': 0.1374, 'learning_rate': 6.12533692722372e-05, 'epoch': 8.02}                                                                                                        
{'loss': 0.1016, 'learning_rate': 6.084905660377358e-05, 'epoch': 8.03}                                                                                                       
{'loss': 0.0941, 'learning_rate': 6.044474393530996e-05, 'epoch': 8.04}                                                                                                       
{'loss': 0.0793, 'learning_rate': 6.004043126684635e-05, 'epoch': 8.06}                                                                                                       
{'loss': 0.2123, 'learning_rate': 5.9636118598382745e-05, 'epoch': 8.07}                                                                                                      
{'loss': 0.1325, 'learning_rate': 5.923180592991913e-05, 'epoch': 8.08}                                                                                                       
{'loss': 0.0958, 'learning_rate': 5.882749326145552e-05, 'epoch': 8.1}                                                                                                        
{'loss': 0.091, 'learning_rate': 5.842318059299191e-05, 'epoch': 8.11}                                                                                                        
{'loss': 0.0619, 'learning_rate': 5.80188679245283e-05, 'epoch': 8.12}                                                                                                        
{'loss': 0.1593, 'learning_rate': 5.761455525606468e-05, 'epoch': 8.14}                                                                                                       
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                        | 6200/7620 [9:27:07<1:28:28,  3.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3639538586139679, 'eval_wer': 0.3446573621146165, 'eval_cer': 0.11046562314246086, 'eval_runtime': 293.7578, 'eval_samples_per_second': 6.808, 'eval_steps_per_second': 0.851, 'epoch': 8.14}                                                                                                                                               
{'loss': 0.1622, 'learning_rate': 5.721024258760107e-05, 'epoch': 8.15}                                                                                                       
{'loss': 0.109, 'learning_rate': 5.680592991913746e-05, 'epoch': 8.16}                                                                                                        
{'loss': 0.0805, 'learning_rate': 5.640161725067385e-05, 'epoch': 8.18}                                                                                                       
{'loss': 0.0742, 'learning_rate': 5.599730458221024e-05, 'epoch': 8.19}                                                                                                       
{'loss': 0.1356, 'learning_rate': 5.559299191374663e-05, 'epoch': 8.2}                                                                                                        
{'loss': 0.2017, 'learning_rate': 5.518867924528301e-05, 'epoch': 8.22}                                                                                                       
{'loss': 0.0875, 'learning_rate': 5.47843665768194e-05, 'epoch': 8.23}                                                                                                        
{'loss': 0.0571, 'learning_rate': 5.438005390835579e-05, 'epoch': 8.24}                                                                                                       
{'loss': 0.1193, 'learning_rate': 5.3975741239892176e-05, 'epoch': 8.25}                                                                                                      
{'loss': 0.1844, 'learning_rate': 5.357142857142857e-05, 'epoch': 8.27}                                                                                                       
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                      | 6300/7620 [9:36:38<1:21:29,  3.70s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3397320508956909, 'eval_wer': 0.33990037248126376, 'eval_cer': 0.10827025956013474, 'eval_runtime': 296.3231, 'eval_samples_per_second': 6.749, 'eval_steps_per_second': 0.844, 'epoch': 8.27}                                                                                                                                              
{'loss': 0.1396, 'learning_rate': 5.3167115902964954e-05, 'epoch': 8.28}                                                                                                      
{'loss': 0.098, 'learning_rate': 5.2762803234501347e-05, 'epoch': 8.29}                                                                                                       
{'loss': 0.0838, 'learning_rate': 5.2358490566037725e-05, 'epoch': 8.31}                                                                                                      
{'loss': 0.0944, 'learning_rate': 5.195417789757412e-05, 'epoch': 8.32}                                                                                                       
{'loss': 0.1349, 'learning_rate': 5.154986522911051e-05, 'epoch': 8.33}                                                                                                       
{'loss': 0.1344, 'learning_rate': 5.1145552560646895e-05, 'epoch': 8.35}                                                                                                      
{'loss': 0.0843, 'learning_rate': 5.074123989218329e-05, 'epoch': 8.36}                                                                                                       
{'loss': 0.0806, 'learning_rate': 5.033692722371967e-05, 'epoch': 8.37}                                                                                                       
{'loss': 0.0791, 'learning_rate': 4.993261455525606e-05, 'epoch': 8.39}                                                                                                       
{'loss': 0.213, 'learning_rate': 4.9528301886792444e-05, 'epoch': 8.4}                                                                                                        
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 6400/7620 [9:46:10<1:18:12,  3.85s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35001519322395325, 'eval_wer': 0.34129156756271595, 'eval_cer': 0.10938775510204081, 'eval_runtime': 292.245, 'eval_samples_per_second': 6.844, 'eval_steps_per_second': 0.855, 'epoch': 8.4}                                                                                                                                               
{'loss': 0.1427, 'learning_rate': 4.9123989218328837e-05, 'epoch': 8.41}                                                                                                      
{'loss': 0.1147, 'learning_rate': 4.871967654986522e-05, 'epoch': 8.43}                                                                                                       
{'loss': 0.0568, 'learning_rate': 4.8315363881401614e-05, 'epoch': 8.44}                                                                                                      
{'loss': 0.0824, 'learning_rate': 4.791105121293801e-05, 'epoch': 8.45}                                                                                                       
{'loss': 0.1819, 'learning_rate': 4.750673854447439e-05, 'epoch': 8.46}                                                                                                       
{'loss': 0.1371, 'learning_rate': 4.710242587601077e-05, 'epoch': 8.48}                                                                                                       
{'loss': 0.1356, 'learning_rate': 4.669811320754716e-05, 'epoch': 8.49}                                                                                                       
{'loss': 0.0859, 'learning_rate': 4.6293800539083556e-05, 'epoch': 8.5}                                                                                                       
{'loss': 0.0601, 'learning_rate': 4.588948787061994e-05, 'epoch': 8.52}                                                                                                       
{'loss': 0.2017, 'learning_rate': 4.5485175202156333e-05, 'epoch': 8.53}                                                                                                      
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 6500/7620 [9:55:41<1:19:40,  4.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3500532805919647, 'eval_wer': 0.33765650944666337, 'eval_cer': 0.10849217356845652, 'eval_runtime': 284.2324, 'eval_samples_per_second': 7.036, 'eval_steps_per_second': 0.88, 'epoch': 8.53}                                                                                                                                               
{'loss': 0.137, 'learning_rate': 4.508086253369272e-05, 'epoch': 8.54}                                                                                                        
{'loss': 0.0847, 'learning_rate': 4.4676549865229104e-05, 'epoch': 8.56}                                                                                                      
{'loss': 0.1077, 'learning_rate': 4.427223719676549e-05, 'epoch': 8.57}                                                                                                       
{'loss': 0.0845, 'learning_rate': 4.386792452830188e-05, 'epoch': 8.58}                                                                                                       
{'loss': 0.1468, 'learning_rate': 4.346361185983827e-05, 'epoch': 8.6}                                                                                                        
{'loss': 0.1875, 'learning_rate': 4.305929919137466e-05, 'epoch': 8.61}                                                                                                       
{'loss': 0.094, 'learning_rate': 4.265498652291105e-05, 'epoch': 8.62}                                                                                                        
{'loss': 0.0726, 'learning_rate': 4.225067385444744e-05, 'epoch': 8.64}                                                                                                       
{'loss': 0.0697, 'learning_rate': 4.1846361185983823e-05, 'epoch': 8.65}                                                                                                      
{'loss': 0.1928, 'learning_rate': 4.144204851752021e-05, 'epoch': 8.66}                                                                                                       
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                 | 6600/7620 [10:05:00<57:21,  3.37s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34685641527175903, 'eval_wer': 0.3370282277969753, 'eval_cer': 0.1065821279968298, 'eval_runtime': 297.2164, 'eval_samples_per_second': 6.729, 'eval_steps_per_second': 0.841, 'epoch': 8.66}                                                                                                                                               
{'loss': 0.147, 'learning_rate': 4.10377358490566e-05, 'epoch': 8.67}                                                                                                         
{'loss': 0.0979, 'learning_rate': 4.063342318059299e-05, 'epoch': 8.69}                                                                                                       
{'loss': 0.0617, 'learning_rate': 4.022911051212938e-05, 'epoch': 8.7}                                                                                                        
{'loss': 0.0806, 'learning_rate': 3.9824797843665765e-05, 'epoch': 8.71}                                                                                                      
{'loss': 0.186, 'learning_rate': 3.942048517520215e-05, 'epoch': 8.73}                                                                                                        
{'loss': 0.1348, 'learning_rate': 3.9016172506738536e-05, 'epoch': 8.74}                                                                                                      
{'loss': 0.089, 'learning_rate': 3.861185983827493e-05, 'epoch': 8.75}                                                                                                        
{'loss': 0.0619, 'learning_rate': 3.820754716981132e-05, 'epoch': 8.77}                                                                                                       
{'loss': 0.0751, 'learning_rate': 3.7803234501347706e-05, 'epoch': 8.78}                                                                                                      
{'loss': 0.1618, 'learning_rate': 3.739892183288409e-05, 'epoch': 8.79}                                                                                                       
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 6700/7620 [10:14:30<57:43,  3.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.355542927980423, 'eval_wer': 0.33806040479289146, 'eval_cer': 0.10714483851793144, 'eval_runtime': 302.748, 'eval_samples_per_second': 6.606, 'eval_steps_per_second': 0.826, 'epoch': 8.79}                                                                                                                                                
{'loss': 0.1065, 'learning_rate': 3.6994609164420484e-05, 'epoch': 8.81}                                                                                                      
{'loss': 0.0912, 'learning_rate': 3.659029649595687e-05, 'epoch': 8.82}                                                                                                       
{'loss': 0.0733, 'learning_rate': 3.618598382749326e-05, 'epoch': 8.83}                                                                                                       
{'loss': 0.0661, 'learning_rate': 3.578167115902965e-05, 'epoch': 8.85}                                                                                                       
{'loss': 0.1685, 'learning_rate': 3.537735849056603e-05, 'epoch': 8.86}                                                                                                       
{'loss': 0.1129, 'learning_rate': 3.4973045822102425e-05, 'epoch': 8.87}                                                                                                      
{'loss': 0.0996, 'learning_rate': 3.456873315363881e-05, 'epoch': 8.88}                                                                                                       
{'loss': 0.0899, 'learning_rate': 3.4164420485175196e-05, 'epoch': 8.9}                                                                                                       
{'loss': 0.0523, 'learning_rate': 3.376010781671159e-05, 'epoch': 8.91}                                                                                                       
{'loss': 0.1462, 'learning_rate': 3.3355795148247974e-05, 'epoch': 8.92}                                                                                                      
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 6800/7620 [10:24:06<50:52,  3.72s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.337636798620224, 'eval_wer': 0.33577166449759904, 'eval_cer': 0.10637606498910243, 'eval_runtime': 281.7125, 'eval_samples_per_second': 7.099, 'eval_steps_per_second': 0.887, 'epoch': 8.92}                                                                                                                                               
{'loss': 0.1459, 'learning_rate': 3.2951482479784366e-05, 'epoch': 8.94}                                                                                                      
{'loss': 0.0951, 'learning_rate': 3.254716981132075e-05, 'epoch': 8.95}                                                                                                       
{'loss': 0.0659, 'learning_rate': 3.214285714285714e-05, 'epoch': 8.96}                                                                                                       
{'loss': 0.0768, 'learning_rate': 3.173854447439353e-05, 'epoch': 8.98}                                                                                                       
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 6849/7620 [10:30:53<37:22,  2.91s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-6849
Configuration saved in russian_portuguese_high_augmented/checkpoint-6849/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-6849/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-6849/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1085, 'learning_rate': 3.1334231805929915e-05, 'epoch': 8.99}                                                                                                      
{'loss': 0.1146, 'learning_rate': 3.092991913746631e-05, 'epoch': 9.0}                                                                                                        
{'loss': 0.1824, 'learning_rate': 3.052560646900269e-05, 'epoch': 9.02}                                                                                                       
{'loss': 0.1061, 'learning_rate': 3.0121293800539082e-05, 'epoch': 9.03}                                                                                                      
{'loss': 0.0684, 'learning_rate': 2.971698113207547e-05, 'epoch': 9.04}                                                                                                       
{'loss': 0.0796, 'learning_rate': 2.9312668463611856e-05, 'epoch': 9.06}                                                                                                      
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 6900/7620 [10:33:32<28:46,  2.40s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34705010056495667, 'eval_wer': 0.3347843647623749, 'eval_cer': 0.10617000198137508, 'eval_runtime': 301.7819, 'eval_samples_per_second': 6.627, 'eval_steps_per_second': 0.828, 'epoch': 9.06}                                                                                                                                              
{'loss': 0.1314, 'learning_rate': 2.8908355795148245e-05, 'epoch': 9.07}                                                                                                      
{'loss': 0.1585, 'learning_rate': 2.8504043126684634e-05, 'epoch': 9.08}                                                                                                      
{'loss': 0.0838, 'learning_rate': 2.809973045822102e-05, 'epoch': 9.09}                                                                                                       
{'loss': 0.1197, 'learning_rate': 2.769541778975741e-05, 'epoch': 9.11}                                                                                                       
{'loss': 0.0616, 'learning_rate': 2.72911051212938e-05, 'epoch': 9.12}                                                                                                        
{'loss': 0.1481, 'learning_rate': 2.6886792452830183e-05, 'epoch': 9.13}                                                                                                      
{'loss': 0.1649, 'learning_rate': 2.6482479784366575e-05, 'epoch': 9.15}                                                                                                      
{'loss': 0.1062, 'learning_rate': 2.6078167115902964e-05, 'epoch': 9.16}                                                                                                      
{'loss': 0.0629, 'learning_rate': 2.5673854447439353e-05, 'epoch': 9.17}                                                                                                      
{'loss': 0.07, 'learning_rate': 2.526954177897574e-05, 'epoch': 9.19}                                                                                                         
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 7000/7620 [10:43:14<25:22,  2.46s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.35074353218078613, 'eval_wer': 0.33487411928375893, 'eval_cer': 0.10636813948880523, 'eval_runtime': 302.5591, 'eval_samples_per_second': 6.61, 'eval_steps_per_second': 0.826, 'epoch': 9.19}                                                                                                                                              
{'loss': 0.1743, 'learning_rate': 2.4865229110512127e-05, 'epoch': 9.2}                                                                                                       
{'loss': 0.1731, 'learning_rate': 2.4460916442048516e-05, 'epoch': 9.21}                                                                                                      
{'loss': 0.0811, 'learning_rate': 2.4056603773584902e-05, 'epoch': 9.23}                                                                                                      
{'loss': 0.0656, 'learning_rate': 2.365229110512129e-05, 'epoch': 9.24}                                                                                                       
{'loss': 0.0778, 'learning_rate': 2.324797843665768e-05, 'epoch': 9.25}                                                                                                       
{'loss': 0.1517, 'learning_rate': 2.2843665768194065e-05, 'epoch': 9.27}                                                                                                      
{'loss': 0.1338, 'learning_rate': 2.2439353099730458e-05, 'epoch': 9.28}                                                                                                      
{'loss': 0.092, 'learning_rate': 2.2035040431266846e-05, 'epoch': 9.29}                                                                                                       
{'loss': 0.0934, 'learning_rate': 2.1630727762803232e-05, 'epoch': 9.3}                                                                                                       
{'loss': 0.0829, 'learning_rate': 2.122641509433962e-05, 'epoch': 9.32}                                                                                                       
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7100/7620 [10:52:53<20:52,  2.41s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3479313254356384, 'eval_wer': 0.335322891890679, 'eval_cer': 0.10606697047751139, 'eval_runtime': 287.7124, 'eval_samples_per_second': 6.951, 'eval_steps_per_second': 0.869, 'epoch': 9.32}                                                                                                                                                
{'loss': 0.1271, 'learning_rate': 2.082210242587601e-05, 'epoch': 9.33}                                                                                                       
{'loss': 0.1325, 'learning_rate': 2.04177897574124e-05, 'epoch': 9.34}                                                                                                        
{'loss': 0.0839, 'learning_rate': 2.0013477088948784e-05, 'epoch': 9.36}                                                                                                      
{'loss': 0.0683, 'learning_rate': 1.9609164420485173e-05, 'epoch': 9.37}                                                                                                      
{'loss': 0.0548, 'learning_rate': 1.9204851752021562e-05, 'epoch': 9.38}                                                                                                      
{'loss': 0.1085, 'learning_rate': 1.8800539083557948e-05, 'epoch': 9.4}                                                                                                       
{'loss': 0.1393, 'learning_rate': 1.8396226415094337e-05, 'epoch': 9.41}                                                                                                      
{'loss': 0.0663, 'learning_rate': 1.7991913746630725e-05, 'epoch': 9.42}                                                                                                      
{'loss': 0.0709, 'learning_rate': 1.7587601078167114e-05, 'epoch': 9.44}                                                                                                      
{'loss': 0.0695, 'learning_rate': 1.7183288409703503e-05, 'epoch': 9.45}                                                                                                      
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 7200/7620 [11:02:18<16:19,  2.33s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3541358709335327, 'eval_wer': 0.3325853789884665, 'eval_cer': 0.10577372696651476, 'eval_runtime': 296.456, 'eval_samples_per_second': 6.746, 'eval_steps_per_second': 0.843, 'epoch': 9.45}                                                                                                                                                
{'loss': 0.1594, 'learning_rate': 1.6778975741239892e-05, 'epoch': 9.46}                                                                                                      
{'loss': 0.1465, 'learning_rate': 1.6374663072776278e-05, 'epoch': 9.48}                                                                                                      
{'loss': 0.1151, 'learning_rate': 1.5970350404312667e-05, 'epoch': 9.49}                                                                                                      
{'loss': 0.0625, 'learning_rate': 1.5566037735849056e-05, 'epoch': 9.5}                                                                                                       
{'loss': 0.0776, 'learning_rate': 1.5161725067385443e-05, 'epoch': 9.51}                                                                                                      
{'loss': 0.1348, 'learning_rate': 1.475741239892183e-05, 'epoch': 9.53}                                                                                                       
{'loss': 0.0983, 'learning_rate': 1.435309973045822e-05, 'epoch': 9.54}                                                                                                       
{'loss': 0.0955, 'learning_rate': 1.3948787061994608e-05, 'epoch': 9.55}                                                                                                      
{'loss': 0.0725, 'learning_rate': 1.3544474393530997e-05, 'epoch': 9.57}                                                                                                      
{'loss': 0.063, 'learning_rate': 1.3140161725067384e-05, 'epoch': 9.58}                                                                                                       
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 7300/7620 [11:11:53<12:06,  2.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.3466849625110626, 'eval_wer': 0.3325853789884665, 'eval_cer': 0.10641569249058846, 'eval_runtime': 290.2415, 'eval_samples_per_second': 6.891, 'eval_steps_per_second': 0.861, 'epoch': 9.58}                                                                                                                                               
{'loss': 0.1328, 'learning_rate': 1.2735849056603771e-05, 'epoch': 9.59}                                                                                                      
{'loss': 0.1241, 'learning_rate': 1.2331536388140162e-05, 'epoch': 9.61}                                                                                                      
{'loss': 0.1099, 'learning_rate': 1.1927223719676549e-05, 'epoch': 9.62}                                                                                                      
{'loss': 0.0782, 'learning_rate': 1.1522911051212938e-05, 'epoch': 9.63}                                                                                                      
{'loss': 0.0987, 'learning_rate': 1.1118598382749325e-05, 'epoch': 9.65}                                                                                                      
{'loss': 0.1367, 'learning_rate': 1.0714285714285712e-05, 'epoch': 9.66}                                                                                                      
{'loss': 0.1242, 'learning_rate': 1.0309973045822103e-05, 'epoch': 9.67}                                                                                                      
{'loss': 0.1095, 'learning_rate': 9.90566037735849e-06, 'epoch': 9.69}                                                                                                        
{'loss': 0.0523, 'learning_rate': 9.501347708894877e-06, 'epoch': 9.7}                                                                                                        
{'loss': 0.0579, 'learning_rate': 9.097035040431266e-06, 'epoch': 9.71}                                                                                                       
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 7400/7620 [11:21:19<08:26,  2.30s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.33942827582359314, 'eval_wer': 0.33173271103531843, 'eval_cer': 0.10612244897959183, 'eval_runtime': 294.539, 'eval_samples_per_second': 6.79, 'eval_steps_per_second': 0.849, 'epoch': 9.71}                                                                                                                                               
{'loss': 0.125, 'learning_rate': 8.692722371967654e-06, 'epoch': 9.72}                                                                                                        
{'loss': 0.1412, 'learning_rate': 8.288409703504042e-06, 'epoch': 9.74}                                                                                                       
{'loss': 0.1038, 'learning_rate': 7.884097035040431e-06, 'epoch': 9.75}                                                                                                       
{'loss': 0.0979, 'learning_rate': 7.479784366576819e-06, 'epoch': 9.76}                                                                                                       
{'loss': 0.0594, 'learning_rate': 7.0754716981132075e-06, 'epoch': 9.78}                                                                                                      
{'loss': 0.1524, 'learning_rate': 6.671159029649595e-06, 'epoch': 9.79}                                                                                                       
{'loss': 0.1203, 'learning_rate': 6.266846361185983e-06, 'epoch': 9.8}                                                                                                        
{'loss': 0.0995, 'learning_rate': 5.862533692722372e-06, 'epoch': 9.82}                                                                                                       
{'loss': 0.079, 'learning_rate': 5.45822102425876e-06, 'epoch': 9.83}                                                                                                         
{'loss': 0.0732, 'learning_rate': 5.053908355795147e-06, 'epoch': 9.84}                                                                                                       
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7500/7620 [11:30:59<05:18,  2.65s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34358057379722595, 'eval_wer': 0.33200197459947045, 'eval_cer': 0.10573409946502874, 'eval_runtime': 294.5037, 'eval_samples_per_second': 6.791, 'eval_steps_per_second': 0.849, 'epoch': 9.84}                                                                                                                                             
{'loss': 0.1449, 'learning_rate': 4.649595687331536e-06, 'epoch': 9.86}                                                                                                       
{'loss': 0.1298, 'learning_rate': 4.245283018867924e-06, 'epoch': 9.87}                                                                                                       
{'loss': 0.0756, 'learning_rate': 3.840970350404312e-06, 'epoch': 9.88}                                                                                                       
{'loss': 0.0751, 'learning_rate': 3.4366576819407006e-06, 'epoch': 9.9}                                                                                                       
{'loss': 0.076, 'learning_rate': 3.0323450134770886e-06, 'epoch': 9.91}                                                                                                       
{'loss': 0.0984, 'learning_rate': 2.6280323450134767e-06, 'epoch': 9.92}                                                                                                      
{'loss': 0.1296, 'learning_rate': 2.223719676549865e-06, 'epoch': 9.93}                                                                                                       
{'loss': 0.0681, 'learning_rate': 1.8194070080862533e-06, 'epoch': 9.95}                                                                                                      
{'loss': 0.0633, 'learning_rate': 1.4150943396226413e-06, 'epoch': 9.96}                                                                                                      
{'loss': 0.0699, 'learning_rate': 1.0107816711590296e-06, 'epoch': 9.97}                                                                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7600/7620 [11:40:21<00:45,  2.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.34212759137153625, 'eval_wer': 0.3316878337746264, 'eval_cer': 0.10567069546265108, 'eval_runtime': 276.696, 'eval_samples_per_second': 7.228, 'eval_steps_per_second': 0.904, 'epoch': 9.97}                                                                                                                                               
{'loss': 0.1433, 'learning_rate': 6.064690026954178e-07, 'epoch': 9.99}                                                                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 7610/7620 [11:45:21<01:02,  6.28s/it]Saving model checkpoint to russian_portuguese_high_augmented/checkpoint-7610
Configuration saved in russian_portuguese_high_augmented/checkpoint-7610/config.json
Model weights saved in russian_portuguese_high_augmented/checkpoint-7610/pytorch_model.bin
Feature extractor saved in russian_portuguese_high_augmented/checkpoint-7610/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.0913, 'learning_rate': 2.021563342318059e-07, 'epoch': 10.0}                                                                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [11:45:55<00:00,  2.14s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 42355.2145, 'train_samples_per_second': 2.877, 'train_steps_per_second': 0.18, 'train_loss': 0.5772176511566157, 'epoch': 10.0}                             
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [11:45:55<00:00,  5.56s/it]
----------------- Training complete. -----------------


(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ 


