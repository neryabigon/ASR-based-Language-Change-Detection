(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ python3 training_script.py 
2023-03-28 12:24:42.137032: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-28 12:24:42.275902: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-28 12:24:42.282115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-03-28 12:24:42.282126: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-03-28 12:24:42.740043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-03-28 12:24:42.740082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-03-28 12:24:42.740086: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets complete. -----------------
----------------- Loading Datasets complete. -----------------


----------------- Extracting all characters... -----------------
Parameter 'function'=<function extract_all_chars at 0x7f564309d040> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 78/79 [04:13<00:03,  3.25s/ba]
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍        | 15/16 [00:53<00:03,  3.56s/ba]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'f': 0, 'q': 1, 'i': 2, 'o': 3, 'h': 4, 'g': 5, 'w': 6, 'n': 7, '-': 8, 't': 9, 'p': 10, 'd': 11, 'b': 12, ' ': 13, 'm': 14, "'": 15, 'x': 16, 'z': 17, 'y': 18, 'l': 19, 'v': 20, 's': 21, 'e': 22, 'k': 23, 'c': 24, 'a': 25, 'j': 26, 'r': 27, '>': 28, '<': 29, 'u': 30}
Vocab_len: 33
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/2500 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/2500 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:16<00:00, 32.52ex/s]
#1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:18<00:00, 31.89ex/s]
#3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:18<00:00, 31.89ex/s]
#0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2500/2500 [01:18<00:00, 31.80ex/s]
#0:   0%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                             | 0/500 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.88ex/s]
#3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.87ex/s]
#0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.66ex/s]
#2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:16<00:00, 30.10ex/s]
#2:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 491/500 [00:16<00:00, 29.56ex/s]
#2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 498/500 [00:16<00:00, 28.41ex/s]
----------------- Preparing datasets complete. -----------------


----------------- saving datasets... -----------------
----------------- saving datasets complete. -----------


----------------- Loading Metrics... -----------------
/home/or/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-/training_script.py:172: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.codevectors', 'quantizer.weight_proj.bias', 'project_q.bias', 'project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.weight', 'project_hid.weight']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 10000
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 6250
  Number of trainable parameters = 311262369
  0%|                                                                                                                                                | 0/6250 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 16.0258, 'learning_rate': 1.1999999999999999e-05, 'epoch': 0.02}                                                                                                     
{'loss': 17.8052, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.03}                                                                                                     
{'loss': 19.6137, 'learning_rate': 4.05e-05, 'epoch': 0.05}                                                                                                                   
{'loss': 21.0772, 'learning_rate': 5.5499999999999994e-05, 'epoch': 0.06}                                                                                                     
{'loss': 16.7631, 'learning_rate': 6.9e-05, 'epoch': 0.08}                                                                                                                    
{'loss': 6.7098, 'learning_rate': 8.4e-05, 'epoch': 0.1}                                                                                                                      
{'loss': 4.4816, 'learning_rate': 9.9e-05, 'epoch': 0.11}                                                                                                                     
{'loss': 3.5993, 'learning_rate': 0.00011399999999999999, 'epoch': 0.13}                                                                                                      
{'loss': 3.3402, 'learning_rate': 0.000129, 'epoch': 0.14}                                                                                                                    
{'loss': 3.0923, 'learning_rate': 0.00014399999999999998, 'epoch': 0.16}                                                                                                      
  2%|██                                                                                                                                  | 100/6250 [02:56<2:02:29,  1.20s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 3.0586678981781006, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 135.9545, 'eval_samples_per_second': 14.711, 'eval_steps_per_second': 1.839, 'epoch': 0.16}                                                                                                                                                              
{'loss': 3.049, 'learning_rate': 0.000159, 'epoch': 0.18}                                                                                                                     
{'loss': 2.989, 'learning_rate': 0.00017399999999999997, 'epoch': 0.19}                                                                                                       
{'loss': 2.996, 'learning_rate': 0.00018899999999999999, 'epoch': 0.21}                                                                                                       
{'loss': 2.9806, 'learning_rate': 0.000204, 'epoch': 0.22}                                                                                                                    
{'loss': 2.9642, 'learning_rate': 0.00021899999999999998, 'epoch': 0.24}                                                                                                      
{'loss': 3.09, 'learning_rate': 0.000234, 'epoch': 0.26}                                                                                                                      
{'loss': 2.9755, 'learning_rate': 0.000249, 'epoch': 0.27}                                                                                                                    
{'loss': 2.967, 'learning_rate': 0.00026399999999999997, 'epoch': 0.29}                                                                                                       
{'loss': 2.9807, 'learning_rate': 0.000279, 'epoch': 0.3}                                                                                                                     
{'loss': 2.9769, 'learning_rate': 0.000294, 'epoch': 0.32}                                                                                                                    
  3%|████▏                                                                                                                               | 200/6250 [08:09<2:06:36,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 3.027151584625244, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 136.1934, 'eval_samples_per_second': 14.685, 'eval_steps_per_second': 1.836, 'epoch': 0.32}                                                                                                                                                               
{'loss': 3.0806, 'learning_rate': 0.0002997024793388429, 'epoch': 0.34}                                                                                                       
{'loss': 2.9778, 'learning_rate': 0.0002992066115702479, 'epoch': 0.35}                                                                                                       
{'loss': 2.9666, 'learning_rate': 0.00029871074380165286, 'epoch': 0.37}                                                                                                      
{'loss': 2.9712, 'learning_rate': 0.0002982148760330578, 'epoch': 0.38}                                                                                                       
{'loss': 2.9633, 'learning_rate': 0.0002977190082644628, 'epoch': 0.4}                                                                                                        
{'loss': 3.0821, 'learning_rate': 0.00029722314049586776, 'epoch': 0.42}                                                                                                      
{'loss': 3.0153, 'learning_rate': 0.0002967272727272727, 'epoch': 0.43}                                                                                                       
{'loss': 2.9697, 'learning_rate': 0.00029623140495867764, 'epoch': 0.45}                                                                                                      
{'loss': 2.967, 'learning_rate': 0.0002957355371900826, 'epoch': 0.46}                                                                                                        
{'loss': 2.9699, 'learning_rate': 0.00029523966942148757, 'epoch': 0.48}                                                                                                      
  5%|██████▎                                                                                                                             | 300/6250 [13:23<1:59:59,  1.21s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 3.0271973609924316, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 136.2176, 'eval_samples_per_second': 14.682, 'eval_steps_per_second': 1.835, 'epoch': 0.48}                                                                                                                                                              
{'loss': 3.0941, 'learning_rate': 0.00029474380165289254, 'epoch': 0.5}                                                                                                       
{'loss': 2.9795, 'learning_rate': 0.0002942479338842975, 'epoch': 0.51}                                                                                                       
{'loss': 2.9752, 'learning_rate': 0.0002937520661157025, 'epoch': 0.53}                                                                                                       
{'loss': 2.9606, 'learning_rate': 0.0002932561983471074, 'epoch': 0.54}                                                                                                       
{'loss': 2.9588, 'learning_rate': 0.00029276033057851235, 'epoch': 0.56}                                                                                                      
{'loss': 3.0431, 'learning_rate': 0.0002922644628099173, 'epoch': 0.58}                                                                                                       
{'loss': 2.9919, 'learning_rate': 0.0002917685950413223, 'epoch': 0.59}                                                                                                       
{'loss': 2.979, 'learning_rate': 0.00029127272727272726, 'epoch': 0.61}                                                                                                       
{'loss': 2.9577, 'learning_rate': 0.0002907768595041322, 'epoch': 0.62}                                                                                                       
{'loss': 2.9614, 'learning_rate': 0.0002902809917355372, 'epoch': 0.64}                                                                                                       
  6%|████████▍                                                                                                                           | 400/6250 [18:37<1:59:45,  1.23s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 3.0256335735321045, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 136.7644, 'eval_samples_per_second': 14.624, 'eval_steps_per_second': 1.828, 'epoch': 0.64}                                                                                                                                                              
{'loss': 3.099, 'learning_rate': 0.0002897851239669421, 'epoch': 0.66}                                                                                                        
{'loss': 2.9893, 'learning_rate': 0.00028928925619834707, 'epoch': 0.67}                                                                                                      
{'loss': 2.9688, 'learning_rate': 0.00028879338842975204, 'epoch': 0.69}                                                                                                      
{'loss': 2.9561, 'learning_rate': 0.000288297520661157, 'epoch': 0.7}                                                                                                         
{'loss': 2.9538, 'learning_rate': 0.00028780165289256197, 'epoch': 0.72}                                                                                                      
{'loss': 3.7568, 'learning_rate': 0.00028730578512396694, 'epoch': 0.74}                                                                                                      
{'loss': 2.9733, 'learning_rate': 0.0002868099173553719, 'epoch': 0.75}                                                                                                       
{'loss': 2.9444, 'learning_rate': 0.0002863140495867768, 'epoch': 0.77}                                                                                                       
{'loss': 2.9328, 'learning_rate': 0.0002858181818181818, 'epoch': 0.78}                                                                                                       
{'loss': 2.9264, 'learning_rate': 0.00028532231404958675, 'epoch': 0.8}                                                                                                       
  8%|██████████▌                                                                                                                         | 500/6250 [23:50<1:58:46,  1.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.981891632080078, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 136.561, 'eval_samples_per_second': 14.645, 'eval_steps_per_second': 1.831, 'epoch': 0.8}                                                                                                                                                                 
{'loss': 3.023, 'learning_rate': 0.0002848264462809917, 'epoch': 0.82}                                                                                                        
{'loss': 2.9674, 'learning_rate': 0.00028433057851239663, 'epoch': 0.83}                                                                                                      
{'loss': 2.9217, 'learning_rate': 0.00028383471074380166, 'epoch': 0.85}                                                                                                      
{'loss': 2.9258, 'learning_rate': 0.00028333884297520657, 'epoch': 0.86}                                                                                                      
{'loss': 2.9127, 'learning_rate': 0.00028284297520661154, 'epoch': 0.88}                                                                                                      
{'loss': 3.042, 'learning_rate': 0.0002823471074380165, 'epoch': 0.9}                                                                                                         
{'loss': 2.9686, 'learning_rate': 0.00028185123966942147, 'epoch': 0.91}                                                                                                      
{'loss': 2.9348, 'learning_rate': 0.00028135537190082644, 'epoch': 0.93}                                                                                                      
{'loss': 2.9231, 'learning_rate': 0.00028085950413223135, 'epoch': 0.94}                                                                                                      
{'loss': 2.8946, 'learning_rate': 0.00028036363636363637, 'epoch': 0.96}                                                                                                      
 10%|████████████▋                                                                                                                       | 600/6250 [29:01<1:54:45,  1.22s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.9481728076934814, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 136.6879, 'eval_samples_per_second': 14.632, 'eval_steps_per_second': 1.829, 'epoch': 0.96}                                                                                                                                                              
{'loss': 2.9974, 'learning_rate': 0.0002798677685950413, 'epoch': 0.98}                                                                                                       
{'loss': 2.9255, 'learning_rate': 0.00027937190082644625, 'epoch': 0.99}                                                                                                      
 10%|█████████████▏                                                                                                                      | 625/6250 [32:02<2:05:04,  1.33s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-625
Configuration saved in russian_portuguese_low/checkpoint-625/config.json
Model weights saved in russian_portuguese_low/checkpoint-625/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-625/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 2.9645, 'learning_rate': 0.0002788760330578512, 'epoch': 1.01}                                                                                                       
{'loss': 2.9709, 'learning_rate': 0.0002783801652892562, 'epoch': 1.02}                                                                                                       
{'loss': 2.9361, 'learning_rate': 0.00027788429752066115, 'epoch': 1.04}                                                                                                      
{'loss': 2.9078, 'learning_rate': 0.00027738842975206607, 'epoch': 1.06}                                                                                                      
{'loss': 2.8889, 'learning_rate': 0.00027689256198347103, 'epoch': 1.07}                                                                                                      
{'loss': 2.9583, 'learning_rate': 0.000276396694214876, 'epoch': 1.09}                                                                                                        
{'loss': 2.9262, 'learning_rate': 0.00027590082644628097, 'epoch': 1.1}                                                                                                       
{'loss': 2.9014, 'learning_rate': 0.00027540495867768594, 'epoch': 1.12}                                                                                                      
 11%|██████████████▊                                                                                                                     | 700/6250 [34:26<2:43:16,  1.77s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.9025771617889404, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 137.78, 'eval_samples_per_second': 14.516, 'eval_steps_per_second': 1.814, 'epoch': 1.12}                                                                                                                                                                
{'loss': 2.9055, 'learning_rate': 0.0002749090909090909, 'epoch': 1.14}                                                                                                       
{'loss': 2.8908, 'learning_rate': 0.0002744132231404958, 'epoch': 1.15}                                                                                                       
{'loss': 2.9488, 'learning_rate': 0.0002739173553719008, 'epoch': 1.17}                                                                                                       
{'loss': 2.929, 'learning_rate': 0.00027342148760330575, 'epoch': 1.18}                                                                                                       
{'loss': 2.8811, 'learning_rate': 0.0002729256198347107, 'epoch': 1.2}                                                                                                        
{'loss': 2.8674, 'learning_rate': 0.0002724297520661157, 'epoch': 1.22}                                                                                                       
{'loss': 2.8415, 'learning_rate': 0.00027193388429752065, 'epoch': 1.23}                                                                                                      
{'loss': 2.8748, 'learning_rate': 0.0002714380165289256, 'epoch': 1.25}                                                                                                       
{'loss': 2.9066, 'learning_rate': 0.00027094214876033053, 'epoch': 1.26}                                                                                                      
{'loss': 2.8395, 'learning_rate': 0.0002704462809917355, 'epoch': 1.28}                                                                                                       
 13%|████████████████▉                                                                                                                   | 800/6250 [39:49<2:37:20,  1.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 2.734130620956421, 'eval_wer': 1.0, 'eval_cer': 0.9956496954786835, 'eval_runtime': 137.6397, 'eval_samples_per_second': 14.531, 'eval_steps_per_second': 1.816, 'epoch': 1.28}                                                                                                                                                               
{'loss': 2.6793, 'learning_rate': 0.00026995041322314047, 'epoch': 1.3}                                                                                                       
{'loss': 2.4854, 'learning_rate': 0.00026945454545454543, 'epoch': 1.31}                                                                                                      
{'loss': 2.2845, 'learning_rate': 0.00026895867768595035, 'epoch': 1.33}                                                                                                      
{'loss': 1.9785, 'learning_rate': 0.00026846280991735537, 'epoch': 1.34}                                                                                                      
{'loss': 1.6944, 'learning_rate': 0.00026796694214876034, 'epoch': 1.36}                                                                                                      
{'loss': 1.4555, 'learning_rate': 0.00026747107438016525, 'epoch': 1.38}                                                                                                      
{'loss': 1.3397, 'learning_rate': 0.0002669752066115702, 'epoch': 1.39}                                                                                                       
{'loss': 1.4151, 'learning_rate': 0.0002664793388429752, 'epoch': 1.41}                                                                                                       
{'loss': 1.4271, 'learning_rate': 0.00026598347107438015, 'epoch': 1.42}                                                                                                      
{'loss': 1.1624, 'learning_rate': 0.00026548760330578506, 'epoch': 1.44}                                                                                                      
 14%|███████████████████                                                                                                                 | 900/6250 [45:30<3:03:16,  2.06s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 1.0821563005447388, 'eval_wer': 0.9579328816763826, 'eval_cer': 0.33841618913323934, 'eval_runtime': 138.4226, 'eval_samples_per_second': 14.449, 'eval_steps_per_second': 1.806, 'epoch': 1.44}                                                                                                                                              
{'loss': 0.9982, 'learning_rate': 0.0002649917355371901, 'epoch': 1.46}                                                                                                       
{'loss': 1.0271, 'learning_rate': 0.000264495867768595, 'epoch': 1.47}                                                                                                        
{'loss': 1.0493, 'learning_rate': 0.00026399999999999997, 'epoch': 1.49}                                                                                                      
{'loss': 1.0877, 'learning_rate': 0.00026350413223140493, 'epoch': 1.5}                                                                                                       
{'loss': 0.9542, 'learning_rate': 0.0002630082644628099, 'epoch': 1.52}                                                                                                       
{'loss': 0.8214, 'learning_rate': 0.00026251239669421487, 'epoch': 1.54}                                                                                                      
{'loss': 0.7682, 'learning_rate': 0.0002620165289256198, 'epoch': 1.55}                                                                                                       
{'loss': 0.9137, 'learning_rate': 0.0002615206611570248, 'epoch': 1.57}                                                                                                       
{'loss': 0.9631, 'learning_rate': 0.0002610247933884297, 'epoch': 1.58}                                                                                                       
{'loss': 0.8888, 'learning_rate': 0.0002605289256198347, 'epoch': 1.6}                                                                                                        
 16%|████████████████████▉                                                                                                              | 1000/6250 [50:45<2:44:26,  1.88s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.8260554075241089, 'eval_wer': 0.8942807625649913, 'eval_cer': 0.27192403468242776, 'eval_runtime': 139.5149, 'eval_samples_per_second': 14.335, 'eval_steps_per_second': 1.792, 'epoch': 1.6}                                                                                                                                               
{'loss': 0.7501, 'learning_rate': 0.00026003305785123965, 'epoch': 1.62}                                                                                                      
{'loss': 0.6979, 'learning_rate': 0.0002595371900826446, 'epoch': 1.63}                                                                                                       
{'loss': 0.7453, 'learning_rate': 0.00025904132231404953, 'epoch': 1.65}                                                                                                      
{'loss': 0.8577, 'learning_rate': 0.0002585454545454545, 'epoch': 1.66}                                                                                                       
{'loss': 0.7885, 'learning_rate': 0.0002580495867768595, 'epoch': 1.68}                                                                                                       
{'loss': 0.6601, 'learning_rate': 0.00025755371900826443, 'epoch': 1.7}                                                                                                       
{'loss': 0.6494, 'learning_rate': 0.0002570578512396694, 'epoch': 1.71}                                                                                                       
{'loss': 0.7392, 'learning_rate': 0.00025656198347107437, 'epoch': 1.73}                                                                                                      
{'loss': 0.7967, 'learning_rate': 0.00025606611570247933, 'epoch': 1.74}                                                                                                      
{'loss': 0.7214, 'learning_rate': 0.00025557024793388425, 'epoch': 1.76}                                                                                                      
 18%|███████████████████████                                                                                                            | 1100/6250 [56:27<2:33:51,  1.79s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.7375935912132263, 'eval_wer': 0.8460164907305289, 'eval_cer': 0.24426209834688428, 'eval_runtime': 137.2742, 'eval_samples_per_second': 14.569, 'eval_steps_per_second': 1.821, 'epoch': 1.76}                                                                                                                                              
{'loss': 0.6247, 'learning_rate': 0.0002550743801652892, 'epoch': 1.78}                                                                                                       
{'loss': 0.5578, 'learning_rate': 0.0002545785123966942, 'epoch': 1.79}                                                                                                       
{'loss': 0.6874, 'learning_rate': 0.00025408264462809915, 'epoch': 1.81}                                                                                                      
{'loss': 0.7816, 'learning_rate': 0.0002535867768595041, 'epoch': 1.82}                                                                                                       
{'loss': 0.6639, 'learning_rate': 0.0002530909090909091, 'epoch': 1.84}                                                                                                       
{'loss': 0.5725, 'learning_rate': 0.00025259504132231405, 'epoch': 1.86}                                                                                                      
{'loss': 0.4887, 'learning_rate': 0.00025209917355371896, 'epoch': 1.87}                                                                                                      
{'loss': 0.583, 'learning_rate': 0.00025160330578512393, 'epoch': 1.89}                                                                                                       
{'loss': 0.6935, 'learning_rate': 0.0002511074380165289, 'epoch': 1.9}                                                                                                        
{'loss': 0.6787, 'learning_rate': 0.00025061157024793386, 'epoch': 1.92}                                                                                                      
 19%|████████████████████████▊                                                                                                        | 1200/6250 [1:02:06<2:25:48,  1.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6839957237243652, 'eval_wer': 0.8203875846856783, 'eval_cer': 0.2292985508985629, 'eval_runtime': 137.85, 'eval_samples_per_second': 14.509, 'eval_steps_per_second': 1.814, 'epoch': 1.92}                                                                                                                                                 
{'loss': 0.5474, 'learning_rate': 0.00025011570247933883, 'epoch': 1.94}                                                                                                      
{'loss': 0.4799, 'learning_rate': 0.0002496198347107438, 'epoch': 1.95}                                                                                                       
{'loss': 0.5626, 'learning_rate': 0.0002491239669421487, 'epoch': 1.97}                                                                                                       
{'loss': 0.6539, 'learning_rate': 0.0002486280991735537, 'epoch': 1.98}                                                                                                       
{'loss': 0.3932, 'learning_rate': 0.00024813223140495865, 'epoch': 2.0}                                                                                                       
 20%|█████████████████████████▊                                                                                                       | 1250/6250 [1:05:46<1:49:32,  1.31s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-1250
Configuration saved in russian_portuguese_low/checkpoint-1250/config.json
Model weights saved in russian_portuguese_low/checkpoint-1250/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-1250/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.6769, 'learning_rate': 0.0002476363636363636, 'epoch': 2.02}                                                                                                       
{'loss': 0.5792, 'learning_rate': 0.0002471404958677686, 'epoch': 2.03}                                                                                                       
{'loss': 0.5065, 'learning_rate': 0.00024664462809917355, 'epoch': 2.05}                                                                                                      
{'loss': 0.44, 'learning_rate': 0.0002461487603305785, 'epoch': 2.06}                                                                                                         
{'loss': 0.3568, 'learning_rate': 0.00024565289256198343, 'epoch': 2.08}                                                                                                      
 21%|██████████████████████████▊                                                                                                      | 1300/6250 [1:07:17<1:43:56,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6670917272567749, 'eval_wer': 0.8044220366577386, 'eval_cer': 0.2158276079325553, 'eval_runtime': 138.0865, 'eval_samples_per_second': 14.484, 'eval_steps_per_second': 1.81, 'epoch': 2.08}                                                                                                                                                
{'loss': 0.6417, 'learning_rate': 0.0002451570247933884, 'epoch': 2.1}                                                                                                        
{'loss': 0.5167, 'learning_rate': 0.00024466115702479336, 'epoch': 2.11}                                                                                                      
{'loss': 0.4227, 'learning_rate': 0.00024416528925619833, 'epoch': 2.13}                                                                                                      
{'loss': 0.3785, 'learning_rate': 0.0002436694214876033, 'epoch': 2.14}                                                                                                       
{'loss': 0.2842, 'learning_rate': 0.00024317355371900824, 'epoch': 2.16}                                                                                                      
{'loss': 0.6812, 'learning_rate': 0.0002426776859504132, 'epoch': 2.18}                                                                                                       
{'loss': 0.512, 'learning_rate': 0.00024218181818181814, 'epoch': 2.19}                                                                                                       
{'loss': 0.4582, 'learning_rate': 0.00024168595041322314, 'epoch': 2.21}                                                                                                      
{'loss': 0.3894, 'learning_rate': 0.00024119008264462808, 'epoch': 2.22}                                                                                                      
{'loss': 0.322, 'learning_rate': 0.00024069421487603305, 'epoch': 2.24}                                                                                                       
 22%|████████████████████████████▉                                                                                                    | 1400/6250 [1:12:36<2:21:59,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6519848704338074, 'eval_wer': 0.7937083136389895, 'eval_cer': 0.21178482493774564, 'eval_runtime': 160.0051, 'eval_samples_per_second': 12.5, 'eval_steps_per_second': 1.562, 'epoch': 2.24}                                                                                                                                                
{'loss': 0.5829, 'learning_rate': 0.000240198347107438, 'epoch': 2.26}                                                                                                        
{'loss': 0.527, 'learning_rate': 0.00023970247933884295, 'epoch': 2.27}                                                                                                       
{'loss': 0.421, 'learning_rate': 0.0002392066115702479, 'epoch': 2.29}                                                                                                        
{'loss': 0.322, 'learning_rate': 0.00023871074380165286, 'epoch': 2.3}                                                                                                        
{'loss': 0.2949, 'learning_rate': 0.00023821487603305786, 'epoch': 2.32}                                                                                                      
{'loss': 0.6056, 'learning_rate': 0.0002377190082644628, 'epoch': 2.34}                                                                                                       
{'loss': 0.5064, 'learning_rate': 0.00023722314049586776, 'epoch': 2.35}                                                                                                      
{'loss': 0.4373, 'learning_rate': 0.0002367272727272727, 'epoch': 2.37}                                                                                                       
{'loss': 0.3733, 'learning_rate': 0.00023623140495867767, 'epoch': 2.38}                                                                                                      
{'loss': 0.309, 'learning_rate': 0.0002357355371900826, 'epoch': 2.4}                                                                                                         
 24%|██████████████████████████████▉                                                                                                  | 1500/6250 [1:18:15<1:39:08,  1.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6977602243423462, 'eval_wer': 0.7777427656110498, 'eval_cer': 0.21535507485523986, 'eval_runtime': 171.5908, 'eval_samples_per_second': 11.656, 'eval_steps_per_second': 1.457, 'epoch': 2.4}                                                                                                                                               
{'loss': 0.5744, 'learning_rate': 0.00023523966942148758, 'epoch': 2.42}                                                                                                      
{'loss': 0.5164, 'learning_rate': 0.00023474380165289252, 'epoch': 2.43}                                                                                                      
{'loss': 0.4258, 'learning_rate': 0.0002342479338842975, 'epoch': 2.45}                                                                                                       
{'loss': 0.3212, 'learning_rate': 0.00023375206611570248, 'epoch': 2.46}                                                                                                      
{'loss': 0.3032, 'learning_rate': 0.00023325619834710742, 'epoch': 2.48}                                                                                                      
{'loss': 0.5489, 'learning_rate': 0.0002327603305785124, 'epoch': 2.5}                                                                                                        
{'loss': 0.4991, 'learning_rate': 0.00023226446280991733, 'epoch': 2.51}                                                                                                      
{'loss': 0.4166, 'learning_rate': 0.0002317685950413223, 'epoch': 2.53}                                                                                                       
{'loss': 0.3429, 'learning_rate': 0.00023127272727272723, 'epoch': 2.54}                                                                                                      
{'loss': 0.2792, 'learning_rate': 0.00023077685950413223, 'epoch': 2.56}                                                                                                      
 26%|█████████████████████████████████                                                                                                | 1600/6250 [1:24:13<3:23:39,  2.63s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6266748309135437, 'eval_wer': 0.7558426553227247, 'eval_cer': 0.20448681407698538, 'eval_runtime': 167.7318, 'eval_samples_per_second': 11.924, 'eval_steps_per_second': 1.49, 'epoch': 2.56}                                                                                                                                               
{'loss': 0.4717, 'learning_rate': 0.00023028099173553717, 'epoch': 2.58}                                                                                                      
{'loss': 0.5334, 'learning_rate': 0.00022978512396694214, 'epoch': 2.59}                                                                                                      
{'loss': 0.4194, 'learning_rate': 0.00022928925619834708, 'epoch': 2.61}                                                                                                      
{'loss': 0.3364, 'learning_rate': 0.00022879338842975204, 'epoch': 2.62}                                                                                                      
{'loss': 0.2674, 'learning_rate': 0.000228297520661157, 'epoch': 2.64}                                                                                                        
{'loss': 0.5347, 'learning_rate': 0.00022780165289256195, 'epoch': 2.66}                                                                                                      
{'loss': 0.4324, 'learning_rate': 0.00022730578512396694, 'epoch': 2.67}                                                                                                      
{'loss': 0.3813, 'learning_rate': 0.00022680991735537189, 'epoch': 2.69}                                                                                                      
{'loss': 0.2875, 'learning_rate': 0.00022631404958677685, 'epoch': 2.7}                                                                                                       
{'loss': 0.2483, 'learning_rate': 0.0002258181818181818, 'epoch': 2.72}                                                                                                       
 27%|███████████████████████████████████                                                                                              | 1700/6250 [1:30:01<1:35:48,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5973005890846252, 'eval_wer': 0.7530591880678535, 'eval_cer': 0.19946896282739793, 'eval_runtime': 139.3764, 'eval_samples_per_second': 14.35, 'eval_steps_per_second': 1.794, 'epoch': 2.72}                                                                                                                                               
{'loss': 0.4962, 'learning_rate': 0.00022532231404958676, 'epoch': 2.74}                                                                                                      
{'loss': 0.456, 'learning_rate': 0.0002248264462809917, 'epoch': 2.75}                                                                                                        
{'loss': 0.4249, 'learning_rate': 0.00022433057851239667, 'epoch': 2.77}                                                                                                      
{'loss': 0.2855, 'learning_rate': 0.00022383471074380166, 'epoch': 2.78}                                                                                                      
{'loss': 0.2718, 'learning_rate': 0.0002233388429752066, 'epoch': 2.8}                                                                                                        
{'loss': 0.5335, 'learning_rate': 0.00022284297520661157, 'epoch': 2.82}                                                                                                      
{'loss': 0.4303, 'learning_rate': 0.0002223471074380165, 'epoch': 2.83}                                                                                                       
{'loss': 0.3572, 'learning_rate': 0.00022185123966942148, 'epoch': 2.85}                                                                                                      
{'loss': 0.3378, 'learning_rate': 0.00022135537190082642, 'epoch': 2.86}                                                                                                      
{'loss': 0.2561, 'learning_rate': 0.00022085950413223138, 'epoch': 2.88}                                                                                                      
 29%|█████████████████████████████████████▏                                                                                           | 1800/6250 [1:35:21<1:35:32,  1.29s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5892357230186462, 'eval_wer': 0.7345202457854104, 'eval_cer': 0.18632804296300742, 'eval_runtime': 157.4596, 'eval_samples_per_second': 12.702, 'eval_steps_per_second': 1.588, 'epoch': 2.88}                                                                                                                                              
{'loss': 0.4777, 'learning_rate': 0.00022036363636363632, 'epoch': 2.9}                                                                                                       
{'loss': 0.4169, 'learning_rate': 0.00021986776859504132, 'epoch': 2.91}                                                                                                      
{'loss': 0.3941, 'learning_rate': 0.00021937190082644626, 'epoch': 2.93}                                                                                                      
{'loss': 0.2968, 'learning_rate': 0.00021887603305785123, 'epoch': 2.94}                                                                                                      
{'loss': 0.301, 'learning_rate': 0.0002183801652892562, 'epoch': 2.96}                                                                                                        
{'loss': 0.468, 'learning_rate': 0.00021788429752066113, 'epoch': 2.98}                                                                                                       
{'loss': 0.3025, 'learning_rate': 0.0002173884297520661, 'epoch': 2.99}                                                                                                       
 30%|██████████████████████████████████████▋                                                                                          | 1875/6250 [1:40:14<1:34:09,  1.29s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-1875
Configuration saved in russian_portuguese_low/checkpoint-1875/config.json
Model weights saved in russian_portuguese_low/checkpoint-1875/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-1875/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3756, 'learning_rate': 0.00021689256198347104, 'epoch': 3.01}                                                                                                      
{'loss': 0.4116, 'learning_rate': 0.000216396694214876, 'epoch': 3.02}                                                                                                        
{'loss': 0.3458, 'learning_rate': 0.00021590082644628097, 'epoch': 3.04}                                                                                                      
 30%|███████████████████████████████████████▏                                                                                         | 1900/6250 [1:41:09<2:05:08,  1.73s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5643027424812317, 'eval_wer': 0.6918229084606901, 'eval_cer': 0.17954006780474632, 'eval_runtime': 138.8851, 'eval_samples_per_second': 14.4, 'eval_steps_per_second': 1.8, 'epoch': 3.04}                                                                                                                                                  
{'loss': 0.2774, 'learning_rate': 0.00021540495867768594, 'epoch': 3.06}                                                                                                      
{'loss': 0.2151, 'learning_rate': 0.00021490909090909088, 'epoch': 3.07}                                                                                                      
{'loss': 0.3591, 'learning_rate': 0.00021441322314049585, 'epoch': 3.09}                                                                                                      
{'loss': 0.3533, 'learning_rate': 0.00021391735537190082, 'epoch': 3.1}                                                                                                       
{'loss': 0.3212, 'learning_rate': 0.00021342148760330576, 'epoch': 3.12}                                                                                                      
{'loss': 0.236, 'learning_rate': 0.00021292561983471072, 'epoch': 3.14}                                                                                                       
{'loss': 0.2503, 'learning_rate': 0.00021242975206611566, 'epoch': 3.15}                                                                                                      
{'loss': 0.2827, 'learning_rate': 0.00021193388429752066, 'epoch': 3.17}                                                                                                      
{'loss': 0.3877, 'learning_rate': 0.0002114380165289256, 'epoch': 3.18}                                                                                                       
{'loss': 0.3208, 'learning_rate': 0.00021094214876033057, 'epoch': 3.2}                                                                                                       
 32%|█████████████████████████████████████████▎                                                                                       | 2000/6250 [1:46:27<2:01:52,  1.72s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5648346543312073, 'eval_wer': 0.6862034557008561, 'eval_cer': 0.1765098556898983, 'eval_runtime': 139.0966, 'eval_samples_per_second': 14.378, 'eval_steps_per_second': 1.797, 'epoch': 3.2}                                                                                                                                                
{'loss': 0.2166, 'learning_rate': 0.0002104462809917355, 'epoch': 3.22}                                                                                                       
{'loss': 0.2204, 'learning_rate': 0.00020995041322314047, 'epoch': 3.23}                                                                                                      
{'loss': 0.2866, 'learning_rate': 0.00020945454545454544, 'epoch': 3.25}                                                                                                      
{'loss': 0.3816, 'learning_rate': 0.00020895867768595038, 'epoch': 3.26}                                                                                                      
{'loss': 0.3568, 'learning_rate': 0.00020846280991735537, 'epoch': 3.28}                                                                                                      
{'loss': 0.2481, 'learning_rate': 0.00020796694214876031, 'epoch': 3.3}                                                                                                       
{'loss': 0.2401, 'learning_rate': 0.00020747107438016528, 'epoch': 3.31}                                                                                                      
{'loss': 0.2842, 'learning_rate': 0.00020697520661157022, 'epoch': 3.33}                                                                                                      
{'loss': 0.4249, 'learning_rate': 0.0002064793388429752, 'epoch': 3.34}                                                                                                       
{'loss': 0.325, 'learning_rate': 0.00020598347107438013, 'epoch': 3.36}                                                                                                       
 34%|███████████████████████████████████████████▎                                                                                     | 2100/6250 [1:51:43<2:00:37,  1.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.6052395105361938, 'eval_wer': 0.6915603172102306, 'eval_cer': 0.17626233836368546, 'eval_runtime': 137.6924, 'eval_samples_per_second': 14.525, 'eval_steps_per_second': 1.816, 'epoch': 3.36}                                                                                                                                              
{'loss': 0.2968, 'learning_rate': 0.0002054876033057851, 'epoch': 3.38}                                                                                                       
{'loss': 0.215, 'learning_rate': 0.00020499173553719004, 'epoch': 3.39}                                                                                                       
{'loss': 0.3337, 'learning_rate': 0.00020449586776859503, 'epoch': 3.41}                                                                                                      
{'loss': 0.3589, 'learning_rate': 0.000204, 'epoch': 3.42}                                                                                                                    
{'loss': 0.2986, 'learning_rate': 0.00020350413223140494, 'epoch': 3.44}                                                                                                      
{'loss': 0.2231, 'learning_rate': 0.0002030082644628099, 'epoch': 3.46}                                                                                                       
{'loss': 0.1937, 'learning_rate': 0.00020251239669421485, 'epoch': 3.47}                                                                                                      
{'loss': 0.3038, 'learning_rate': 0.0002020165289256198, 'epoch': 3.49}                                                                                                       
{'loss': 0.3732, 'learning_rate': 0.00020152066115702475, 'epoch': 3.5}                                                                                                       
{'loss': 0.3385, 'learning_rate': 0.00020102479338842975, 'epoch': 3.52}                                                                                                      
 35%|█████████████████████████████████████████████▍                                                                                   | 2200/6250 [1:57:00<1:58:59,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5389045476913452, 'eval_wer': 0.6647234914132661, 'eval_cer': 0.17262458372086045, 'eval_runtime': 138.1181, 'eval_samples_per_second': 14.48, 'eval_steps_per_second': 1.81, 'epoch': 3.52}                                                                                                                                                
{'loss': 0.2278, 'learning_rate': 0.0002005289256198347, 'epoch': 3.54}                                                                                                       
{'loss': 0.1991, 'learning_rate': 0.00020003305785123965, 'epoch': 3.55}                                                                                                      
{'loss': 0.3114, 'learning_rate': 0.00019953719008264462, 'epoch': 3.57}                                                                                                      
{'loss': 0.332, 'learning_rate': 0.00019904132231404956, 'epoch': 3.58}                                                                                                       
{'loss': 0.3308, 'learning_rate': 0.00019854545454545453, 'epoch': 3.6}                                                                                                       
{'loss': 0.2479, 'learning_rate': 0.00019804958677685947, 'epoch': 3.62}                                                                                                      
{'loss': 0.1929, 'learning_rate': 0.00019755371900826446, 'epoch': 3.63}                                                                                                      
{'loss': 0.2597, 'learning_rate': 0.0001970578512396694, 'epoch': 3.65}                                                                                                       
{'loss': 0.3707, 'learning_rate': 0.00019656198347107437, 'epoch': 3.66}                                                                                                      
{'loss': 0.3267, 'learning_rate': 0.0001960661157024793, 'epoch': 3.68}                                                                                                       
 37%|███████████████████████████████████████████████▍                                                                                 | 2300/6250 [2:02:17<1:55:36,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5339257121086121, 'eval_wer': 0.6703429441731001, 'eval_cer': 0.17106447451321594, 'eval_runtime': 138.432, 'eval_samples_per_second': 14.448, 'eval_steps_per_second': 1.806, 'epoch': 3.68}                                                                                                                                               
{'loss': 0.2215, 'learning_rate': 0.00019557024793388428, 'epoch': 3.7}                                                                                                       
{'loss': 0.1829, 'learning_rate': 0.00019507438016528922, 'epoch': 3.71}                                                                                                      
{'loss': 0.2676, 'learning_rate': 0.00019457851239669419, 'epoch': 3.73}                                                                                                      
{'loss': 0.3813, 'learning_rate': 0.00019408264462809918, 'epoch': 3.74}                                                                                                      
{'loss': 0.353, 'learning_rate': 0.00019358677685950412, 'epoch': 3.76}                                                                                                       
{'loss': 0.237, 'learning_rate': 0.0001930909090909091, 'epoch': 3.78}                                                                                                        
{'loss': 0.1998, 'learning_rate': 0.00019259504132231403, 'epoch': 3.79}                                                                                                      
{'loss': 0.3105, 'learning_rate': 0.000192099173553719, 'epoch': 3.81}                                                                                                        
{'loss': 0.353, 'learning_rate': 0.00019160330578512394, 'epoch': 3.82}                                                                                                       
{'loss': 0.2635, 'learning_rate': 0.0001911074380165289, 'epoch': 3.84}                                                                                                       
 38%|█████████████████████████████████████████████████▌                                                                               | 2400/6250 [2:07:35<1:54:51,  1.79s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.549476683139801, 'eval_wer': 0.6640932724121632, 'eval_cer': 0.17078695508685607, 'eval_runtime': 138.6399, 'eval_samples_per_second': 14.426, 'eval_steps_per_second': 1.803, 'epoch': 3.84}                                                                                                                                               
{'loss': 0.2354, 'learning_rate': 0.00019061157024793384, 'epoch': 3.86}                                                                                                      
{'loss': 0.1707, 'learning_rate': 0.00019011570247933884, 'epoch': 3.87}                                                                                                      
{'loss': 0.2628, 'learning_rate': 0.0001896198347107438, 'epoch': 3.89}                                                                                                       
{'loss': 0.3964, 'learning_rate': 0.00018912396694214874, 'epoch': 3.9}                                                                                                       
{'loss': 0.3336, 'learning_rate': 0.0001886280991735537, 'epoch': 3.92}                                                                                                       
{'loss': 0.2133, 'learning_rate': 0.00018813223140495865, 'epoch': 3.94}                                                                                                      
{'loss': 0.179, 'learning_rate': 0.00018763636363636362, 'epoch': 3.95}                                                                                                       
{'loss': 0.2896, 'learning_rate': 0.00018714049586776856, 'epoch': 3.97}                                                                                                      
{'loss': 0.2806, 'learning_rate': 0.00018664462809917355, 'epoch': 3.98}                                                                                                      
{'loss': 0.2239, 'learning_rate': 0.0001861487603305785, 'epoch': 4.0}                                                                                                        
 40%|███████████████████████████████████████████████████▌                                                                             | 2500/6250 [2:12:43<1:21:04,  1.30s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5889551043510437, 'eval_wer': 0.6672968856677696, 'eval_cer': 0.1679067534727431, 'eval_runtime': 138.4007, 'eval_samples_per_second': 14.451, 'eval_steps_per_second': 1.806, 'epoch': 4.0}                                                                                                                                                
 40%|███████████████████████████████████████████████████▌                                                                             | 2500/6250 [2:15:01<1:21:04,  1.30s/it]
Saving model checkpoint to russian_portuguese_low/checkpoint-2500                                                                                                             
Configuration saved in russian_portuguese_low/checkpoint-2500/config.json
Model weights saved in russian_portuguese_low/checkpoint-2500/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-2500/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3422, 'learning_rate': 0.00018565289256198346, 'epoch': 4.02}                                                                                                      
{'loss': 0.2764, 'learning_rate': 0.0001851570247933884, 'epoch': 4.03}                                                                                                       
{'loss': 0.2257, 'learning_rate': 0.00018466115702479337, 'epoch': 4.05}                                                                                                      
{'loss': 0.1772, 'learning_rate': 0.00018416528925619834, 'epoch': 4.06}                                                                                                      
{'loss': 0.1185, 'learning_rate': 0.00018366942148760328, 'epoch': 4.08}                                                                                                      
{'loss': 0.3198, 'learning_rate': 0.00018317355371900827, 'epoch': 4.1}                                                                                                       
{'loss': 0.299, 'learning_rate': 0.0001826776859504132, 'epoch': 4.11}                                                                                                        
{'loss': 0.1928, 'learning_rate': 0.00018218181818181818, 'epoch': 4.13}                                                                                                      
{'loss': 0.185, 'learning_rate': 0.00018168595041322312, 'epoch': 4.14}                                                                                                       
{'loss': 0.1435, 'learning_rate': 0.00018119008264462808, 'epoch': 4.16}                                                                                                      
 42%|█████████████████████████████████████████████████████▋                                                                           | 2600/6250 [2:18:03<1:17:43,  1.28s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5266422629356384, 'eval_wer': 0.661940024158395, 'eval_cer': 0.1689043233026312, 'eval_runtime': 140.1268, 'eval_samples_per_second': 14.273, 'eval_steps_per_second': 1.784, 'epoch': 4.16}                                                                                                                                                
{'loss': 0.3046, 'learning_rate': 0.00018069421487603302, 'epoch': 4.18}                                                                                                      
{'loss': 0.3212, 'learning_rate': 0.000180198347107438, 'epoch': 4.19}                                                                                                        
{'loss': 0.1909, 'learning_rate': 0.00017970247933884299, 'epoch': 4.21}                                                                                                      
{'loss': 0.1427, 'learning_rate': 0.00017920661157024793, 'epoch': 4.22}                                                                                                      
{'loss': 0.1249, 'learning_rate': 0.0001787107438016529, 'epoch': 4.24}                                                                                                       
{'loss': 0.3185, 'learning_rate': 0.00017821487603305783, 'epoch': 4.26}                                                                                                      
{'loss': 0.2429, 'learning_rate': 0.0001777190082644628, 'epoch': 4.27}                                                                                                       
{'loss': 0.1778, 'learning_rate': 0.00017722314049586774, 'epoch': 4.29}                                                                                                      
{'loss': 0.156, 'learning_rate': 0.0001767272727272727, 'epoch': 4.3}                                                                                                         
{'loss': 0.1463, 'learning_rate': 0.00017623140495867765, 'epoch': 4.32}                                                                                                      
 43%|███████████████████████████████████████████████████████▋                                                                         | 2700/6250 [2:23:22<1:12:58,  1.23s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5733122825622559, 'eval_wer': 0.669345097421354, 'eval_cer': 0.16713419939395757, 'eval_runtime': 138.9939, 'eval_samples_per_second': 14.389, 'eval_steps_per_second': 1.799, 'epoch': 4.32}                                                                                                                                               
{'loss': 0.3133, 'learning_rate': 0.00017573553719008264, 'epoch': 4.34}                                                                                                      
{'loss': 0.2908, 'learning_rate': 0.00017523966942148758, 'epoch': 4.35}                                                                                                      
{'loss': 0.1985, 'learning_rate': 0.00017474380165289255, 'epoch': 4.37}                                                                                                      
{'loss': 0.1675, 'learning_rate': 0.00017424793388429752, 'epoch': 4.38}                                                                                                      
{'loss': 0.1426, 'learning_rate': 0.00017375206611570246, 'epoch': 4.4}                                                                                                       
{'loss': 0.3405, 'learning_rate': 0.00017325619834710742, 'epoch': 4.42}                                                                                                      
{'loss': 0.261, 'learning_rate': 0.00017276033057851236, 'epoch': 4.43}                                                                                                       
{'loss': 0.2232, 'learning_rate': 0.00017226446280991736, 'epoch': 4.45}                                                                                                      
{'loss': 0.1706, 'learning_rate': 0.0001717685950413223, 'epoch': 4.46}                                                                                                       
{'loss': 0.1382, 'learning_rate': 0.00017127272727272727, 'epoch': 4.48}                                                                                                      
 45%|█████████████████████████████████████████████████████████▊                                                                       | 2800/6250 [2:28:39<1:11:20,  1.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5596138834953308, 'eval_wer': 0.6495457171367051, 'eval_cer': 0.1652965707599532, 'eval_runtime': 139.6729, 'eval_samples_per_second': 14.319, 'eval_steps_per_second': 1.79, 'epoch': 4.48}                                                                                                                                                
{'loss': 0.2813, 'learning_rate': 0.0001707768595041322, 'epoch': 4.5}                                                                                                        
{'loss': 0.2648, 'learning_rate': 0.00017028099173553717, 'epoch': 4.51}                                                                                                      
{'loss': 0.2246, 'learning_rate': 0.00016978512396694214, 'epoch': 4.53}                                                                                                      
{'loss': 0.1459, 'learning_rate': 0.00016928925619834708, 'epoch': 4.54}                                                                                                      
{'loss': 0.1668, 'learning_rate': 0.00016879338842975208, 'epoch': 4.56}                                                                                                      
{'loss': 0.3238, 'learning_rate': 0.00016829752066115702, 'epoch': 4.58}                                                                                                      
{'loss': 0.261, 'learning_rate': 0.00016780165289256198, 'epoch': 4.59}                                                                                                       
{'loss': 0.1777, 'learning_rate': 0.00016730578512396692, 'epoch': 4.61}                                                                                                      
{'loss': 0.1695, 'learning_rate': 0.0001668099173553719, 'epoch': 4.62}                                                                                                       
{'loss': 0.1287, 'learning_rate': 0.00016631404958677683, 'epoch': 4.64}                                                                                                      
 46%|███████████████████████████████████████████████████████████▊                                                                     | 2900/6250 [2:33:59<1:10:48,  1.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5662062764167786, 'eval_wer': 0.6346830523606953, 'eval_cer': 0.16321892532477272, 'eval_runtime': 139.4303, 'eval_samples_per_second': 14.344, 'eval_steps_per_second': 1.793, 'epoch': 4.64}                                                                                                                                              
{'loss': 0.2787, 'learning_rate': 0.0001658181818181818, 'epoch': 4.66}                                                                                                       
{'loss': 0.2399, 'learning_rate': 0.00016532231404958674, 'epoch': 4.67}                                                                                                      
{'loss': 0.2033, 'learning_rate': 0.00016482644628099173, 'epoch': 4.69}                                                                                                      
{'loss': 0.1482, 'learning_rate': 0.0001643305785123967, 'epoch': 4.7}                                                                                                        
{'loss': 0.1296, 'learning_rate': 0.00016383471074380164, 'epoch': 4.72}                                                                                                      
{'loss': 0.3064, 'learning_rate': 0.0001633388429752066, 'epoch': 4.74}                                                                                                       
{'loss': 0.2796, 'learning_rate': 0.00016284297520661155, 'epoch': 4.75}                                                                                                      
{'loss': 0.1891, 'learning_rate': 0.00016234710743801651, 'epoch': 4.77}                                                                                                      
{'loss': 0.1551, 'learning_rate': 0.00016185123966942145, 'epoch': 4.78}                                                                                                      
{'loss': 0.1413, 'learning_rate': 0.00016135537190082645, 'epoch': 4.8}                                                                                                       
 48%|█████████████████████████████████████████████████████████████▉                                                                   | 3000/6250 [2:39:19<1:07:42,  1.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5633472800254822, 'eval_wer': 0.6607321044062812, 'eval_cer': 0.16503405238366686, 'eval_runtime': 139.3802, 'eval_samples_per_second': 14.349, 'eval_steps_per_second': 1.794, 'epoch': 4.8}                                                                                                                                               
{'loss': 0.3417, 'learning_rate': 0.0001608595041322314, 'epoch': 4.82}                                                                                                       
{'loss': 0.2483, 'learning_rate': 0.00016036363636363636, 'epoch': 4.83}                                                                                                      
{'loss': 0.2057, 'learning_rate': 0.00015986776859504132, 'epoch': 4.85}                                                                                                      
{'loss': 0.1638, 'learning_rate': 0.00015937190082644626, 'epoch': 4.86}                                                                                                      
{'loss': 0.1319, 'learning_rate': 0.00015887603305785123, 'epoch': 4.88}                                                                                                      
{'loss': 0.2899, 'learning_rate': 0.00015838016528925617, 'epoch': 4.9}                                                                                                       
{'loss': 0.2354, 'learning_rate': 0.00015788429752066117, 'epoch': 4.91}                                                                                                      
{'loss': 0.2065, 'learning_rate': 0.0001573884297520661, 'epoch': 4.93}                                                                                                       
{'loss': 0.1271, 'learning_rate': 0.00015689256198347107, 'epoch': 4.94}                                                                                                      
{'loss': 0.1329, 'learning_rate': 0.000156396694214876, 'epoch': 4.96}                                                                                                        
 50%|███████████████████████████████████████████████████████████████▉                                                                 | 3100/6250 [2:44:36<1:05:05,  1.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5541229248046875, 'eval_wer': 0.6359434903629011, 'eval_cer': 0.1629564069484864, 'eval_runtime': 138.4499, 'eval_samples_per_second': 14.446, 'eval_steps_per_second': 1.806, 'epoch': 4.96}                                                                                                                                               
{'loss': 0.2963, 'learning_rate': 0.00015590082644628098, 'epoch': 4.98}                                                                                                      
{'loss': 0.1772, 'learning_rate': 0.00015540495867768595, 'epoch': 4.99}                                                                                                      
 50%|████████████████████████████████████████████████████████████████▌                                                                | 3125/6250 [2:47:40<1:10:41,  1.36s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-3125
Configuration saved in russian_portuguese_low/checkpoint-3125/config.json
Model weights saved in russian_portuguese_low/checkpoint-3125/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-3125/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2196, 'learning_rate': 0.0001549090909090909, 'epoch': 5.01}                                                                                                       
{'loss': 0.2684, 'learning_rate': 0.00015441322314049585, 'epoch': 5.02}                                                                                                      
{'loss': 0.2004, 'learning_rate': 0.0001539173553719008, 'epoch': 5.04}                                                                                                       
{'loss': 0.1534, 'learning_rate': 0.0001534214876033058, 'epoch': 5.06}                                                                                                       
{'loss': 0.1282, 'learning_rate': 0.00015292561983471073, 'epoch': 5.07}                                                                                                      
{'loss': 0.2039, 'learning_rate': 0.0001524297520661157, 'epoch': 5.09}                                                                                                       
{'loss': 0.2791, 'learning_rate': 0.00015193388429752064, 'epoch': 5.1}                                                                                                       
{'loss': 0.1871, 'learning_rate': 0.0001514380165289256, 'epoch': 5.12}                                                                                                       
 51%|██████████████████████████████████████████████████████████████████                                                               | 3200/6250 [2:50:04<1:29:49,  1.77s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5691125392913818, 'eval_wer': 0.6278031615986556, 'eval_cer': 0.15983618853319734, 'eval_runtime': 138.9378, 'eval_samples_per_second': 14.395, 'eval_steps_per_second': 1.799, 'epoch': 5.12}                                                                                                                                              
{'loss': 0.1451, 'learning_rate': 0.00015094214876033054, 'epoch': 5.14}                                                                                                      
{'loss': 0.1116, 'learning_rate': 0.0001504462809917355, 'epoch': 5.15}                                                                                                       
{'loss': 0.1781, 'learning_rate': 0.00014995041322314048, 'epoch': 5.17}                                                                                                      
{'loss': 0.2356, 'learning_rate': 0.00014945454545454545, 'epoch': 5.18}                                                                                                      
{'loss': 0.1985, 'learning_rate': 0.00014895867768595039, 'epoch': 5.2}                                                                                                       
{'loss': 0.1094, 'learning_rate': 0.00014846280991735535, 'epoch': 5.22}                                                                                                      
{'loss': 0.0989, 'learning_rate': 0.00014796694214876032, 'epoch': 5.23}                                                                                                      
{'loss': 0.1902, 'learning_rate': 0.0001474710743801653, 'epoch': 5.25}                                                                                                       
{'loss': 0.2278, 'learning_rate': 0.00014697520661157023, 'epoch': 5.26}                                                                                                      
{'loss': 0.2023, 'learning_rate': 0.0001464793388429752, 'epoch': 5.28}                                                                                                       
 53%|████████████████████████████████████████████████████████████████████                                                             | 3300/6250 [2:55:21<1:25:37,  1.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5651755928993225, 'eval_wer': 0.6436111548763195, 'eval_cer': 0.15934115388077166, 'eval_runtime': 139.4043, 'eval_samples_per_second': 14.347, 'eval_steps_per_second': 1.793, 'epoch': 5.28}                                                                                                                                              
{'loss': 0.1413, 'learning_rate': 0.00014598347107438016, 'epoch': 5.3}                                                                                                       
{'loss': 0.1307, 'learning_rate': 0.0001454876033057851, 'epoch': 5.31}                                                                                                       
{'loss': 0.1778, 'learning_rate': 0.00014499173553719007, 'epoch': 5.33}                                                                                                      
{'loss': 0.2223, 'learning_rate': 0.00014449586776859504, 'epoch': 5.34}                                                                                                      
{'loss': 0.2212, 'learning_rate': 0.00014399999999999998, 'epoch': 5.36}                                                                                                      
{'loss': 0.1312, 'learning_rate': 0.00014350413223140494, 'epoch': 5.38}                                                                                                      
{'loss': 0.1346, 'learning_rate': 0.0001430082644628099, 'epoch': 5.39}                                                                                                       
{'loss': 0.1624, 'learning_rate': 0.00014251239669421488, 'epoch': 5.41}                                                                                                      
{'loss': 0.2703, 'learning_rate': 0.00014201652892561982, 'epoch': 5.42}                                                                                                      
{'loss': 0.1833, 'learning_rate': 0.00014152066115702479, 'epoch': 5.44}                                                                                                      
 54%|██████████████████████████████████████████████████████████████████████▏                                                          | 3400/6250 [3:00:40<1:23:47,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5388615727424622, 'eval_wer': 0.6429809358752167, 'eval_cer': 0.15547088296180733, 'eval_runtime': 138.389, 'eval_samples_per_second': 14.452, 'eval_steps_per_second': 1.807, 'epoch': 5.44}                                                                                                                                               
{'loss': 0.1463, 'learning_rate': 0.00014102479338842975, 'epoch': 5.46}                                                                                                      
{'loss': 0.1428, 'learning_rate': 0.0001405289256198347, 'epoch': 5.47}                                                                                                       
{'loss': 0.1784, 'learning_rate': 0.00014003305785123966, 'epoch': 5.49}                                                                                                      
{'loss': 0.246, 'learning_rate': 0.0001395371900826446, 'epoch': 5.5}                                                                                                         
{'loss': 0.1731, 'learning_rate': 0.00013904132231404957, 'epoch': 5.52}                                                                                                      
{'loss': 0.1519, 'learning_rate': 0.00013854545454545453, 'epoch': 5.54}                                                                                                      
{'loss': 0.1338, 'learning_rate': 0.0001380495867768595, 'epoch': 5.55}                                                                                                       
{'loss': 0.1613, 'learning_rate': 0.00013755371900826447, 'epoch': 5.57}                                                                                                      
{'loss': 0.2239, 'learning_rate': 0.0001370578512396694, 'epoch': 5.58}                                                                                                       
{'loss': 0.2378, 'learning_rate': 0.00013656198347107438, 'epoch': 5.6}                                                                                                       
 56%|████████████████████████████████████████████████████████████████████████▏                                                        | 3500/6250 [3:05:57<1:20:15,  1.75s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.535161018371582, 'eval_wer': 0.638201775116853, 'eval_cer': 0.1539257748042363, 'eval_runtime': 139.6576, 'eval_samples_per_second': 14.321, 'eval_steps_per_second': 1.79, 'epoch': 5.6}                                                                                                                                                   
{'loss': 0.1261, 'learning_rate': 0.00013606611570247932, 'epoch': 5.62}                                                                                                      
{'loss': 0.0964, 'learning_rate': 0.00013557024793388428, 'epoch': 5.63}                                                                                                      
{'loss': 0.2053, 'learning_rate': 0.00013507438016528925, 'epoch': 5.65}                                                                                                      
{'loss': 0.2075, 'learning_rate': 0.0001345785123966942, 'epoch': 5.66}                                                                                                       
{'loss': 0.186, 'learning_rate': 0.00013408264462809916, 'epoch': 5.68}                                                                                                       
{'loss': 0.142, 'learning_rate': 0.00013358677685950413, 'epoch': 5.7}                                                                                                        
{'loss': 0.1396, 'learning_rate': 0.0001330909090909091, 'epoch': 5.71}                                                                                                       
{'loss': 0.1841, 'learning_rate': 0.00013259504132231403, 'epoch': 5.73}                                                                                                      
{'loss': 0.2361, 'learning_rate': 0.000132099173553719, 'epoch': 5.74}                                                                                                        
{'loss': 0.1803, 'learning_rate': 0.00013160330578512397, 'epoch': 5.76}                                                                                                      
 58%|██████████████████████████████████████████████████████████████████████████▎                                                      | 3600/6250 [3:11:16<1:17:25,  1.75s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.551264762878418, 'eval_wer': 0.6299564098524237, 'eval_cer': 0.15775104257298012, 'eval_runtime': 139.9294, 'eval_samples_per_second': 14.293, 'eval_steps_per_second': 1.787, 'epoch': 5.76}                                                                                                                                               
{'loss': 0.1362, 'learning_rate': 0.0001311074380165289, 'epoch': 5.78}                                                                                                       
{'loss': 0.1156, 'learning_rate': 0.00013061157024793388, 'epoch': 5.79}                                                                                                      
{'loss': 0.2242, 'learning_rate': 0.00013011570247933884, 'epoch': 5.81}                                                                                                      
{'loss': 0.2632, 'learning_rate': 0.00012961983471074378, 'epoch': 5.82}                                                                                                      
{'loss': 0.1835, 'learning_rate': 0.00012912396694214875, 'epoch': 5.84}                                                                                                      
{'loss': 0.1391, 'learning_rate': 0.0001286280991735537, 'epoch': 5.86}                                                                                                       
{'loss': 0.1126, 'learning_rate': 0.00012813223140495868, 'epoch': 5.87}                                                                                                      
{'loss': 0.1512, 'learning_rate': 0.00012763636363636362, 'epoch': 5.89}                                                                                                      
{'loss': 0.2604, 'learning_rate': 0.0001271404958677686, 'epoch': 5.9}                                                                                                        
{'loss': 0.1723, 'learning_rate': 0.00012664462809917356, 'epoch': 5.92}                                                                                                      
 59%|████████████████████████████████████████████████████████████████████████████▎                                                    | 3700/6250 [3:16:36<1:17:31,  1.82s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5354524850845337, 'eval_wer': 0.6154613728270574, 'eval_cer': 0.15514836038522697, 'eval_runtime': 139.3672, 'eval_samples_per_second': 14.351, 'eval_steps_per_second': 1.794, 'epoch': 5.92}                                                                                                                                              
{'loss': 0.1524, 'learning_rate': 0.0001261487603305785, 'epoch': 5.94}                                                                                                       
{'loss': 0.1112, 'learning_rate': 0.00012565289256198347, 'epoch': 5.95}                                                                                                      
{'loss': 0.1805, 'learning_rate': 0.0001251570247933884, 'epoch': 5.97}                                                                                                       
{'loss': 0.1921, 'learning_rate': 0.00012466115702479337, 'epoch': 5.98}                                                                                                      
{'loss': 0.0946, 'learning_rate': 0.00012416528925619834, 'epoch': 6.0}                                                                                                       
 60%|██████████████████████████████████████████████████████████████████████████████▌                                                    | 3750/6250 [3:20:17<55:40,  1.34s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-3750
Configuration saved in russian_portuguese_low/checkpoint-3750/config.json
Model weights saved in russian_portuguese_low/checkpoint-3750/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-3750/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.237, 'learning_rate': 0.00012366942148760328, 'epoch': 6.02}                                                                                                       
{'loss': 0.2106, 'learning_rate': 0.00012317355371900825, 'epoch': 6.03}                                                                                                      
{'loss': 0.1711, 'learning_rate': 0.00012267768595041322, 'epoch': 6.05}                                                                                                      
{'loss': 0.0927, 'learning_rate': 0.00012218181818181818, 'epoch': 6.06}                                                                                                      
{'loss': 0.1155, 'learning_rate': 0.00012168595041322314, 'epoch': 6.08}                                                                                                      
 61%|███████████████████████████████████████████████████████████████████████████████▋                                                   | 3800/6250 [3:21:50<51:31,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5663042068481445, 'eval_wer': 0.6416154613728271, 'eval_cer': 0.15763853469742883, 'eval_runtime': 138.976, 'eval_samples_per_second': 14.391, 'eval_steps_per_second': 1.799, 'epoch': 6.08}                                                                                                                                               
{'loss': 0.2062, 'learning_rate': 0.00012119008264462809, 'epoch': 6.1}                                                                                                       
{'loss': 0.1725, 'learning_rate': 0.00012069421487603304, 'epoch': 6.11}                                                                                                      
{'loss': 0.1291, 'learning_rate': 0.000120198347107438, 'epoch': 6.13}                                                                                                        
{'loss': 0.094, 'learning_rate': 0.00011970247933884296, 'epoch': 6.14}                                                                                                       
{'loss': 0.0815, 'learning_rate': 0.00011920661157024792, 'epoch': 6.16}                                                                                                      
{'loss': 0.2142, 'learning_rate': 0.00011871074380165287, 'epoch': 6.18}                                                                                                      
{'loss': 0.1787, 'learning_rate': 0.00011821487603305785, 'epoch': 6.19}                                                                                                      
{'loss': 0.1451, 'learning_rate': 0.0001177190082644628, 'epoch': 6.21}                                                                                                       
{'loss': 0.1065, 'learning_rate': 0.00011722314049586776, 'epoch': 6.22}                                                                                                      
{'loss': 0.0776, 'learning_rate': 0.00011672727272727271, 'epoch': 6.24}                                                                                                      
 62%|█████████████████████████████████████████████████████████████████████████████████▋                                                 | 3900/6250 [3:27:08<49:32,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5940037965774536, 'eval_wer': 0.6394622131190588, 'eval_cer': 0.1576085325972818, 'eval_runtime': 139.9659, 'eval_samples_per_second': 14.289, 'eval_steps_per_second': 1.786, 'epoch': 6.24}                                                                                                                                               
{'loss': 0.239, 'learning_rate': 0.00011623140495867768, 'epoch': 6.26}                                                                                                       
{'loss': 0.2169, 'learning_rate': 0.00011573553719008263, 'epoch': 6.27}                                                                                                      
{'loss': 0.124, 'learning_rate': 0.00011523966942148759, 'epoch': 6.29}                                                                                                       
{'loss': 0.0851, 'learning_rate': 0.00011474380165289254, 'epoch': 6.3}                                                                                                       
{'loss': 0.0791, 'learning_rate': 0.00011424793388429751, 'epoch': 6.32}                                                                                                      
{'loss': 0.2392, 'learning_rate': 0.00011375206611570246, 'epoch': 6.34}                                                                                                      
{'loss': 0.1834, 'learning_rate': 0.00011325619834710743, 'epoch': 6.35}                                                                                                      
{'loss': 0.1607, 'learning_rate': 0.0001127603305785124, 'epoch': 6.37}                                                                                                       
{'loss': 0.1124, 'learning_rate': 0.00011226446280991735, 'epoch': 6.38}                                                                                                      
{'loss': 0.1034, 'learning_rate': 0.0001117685950413223, 'epoch': 6.4}                                                                                                        
 64%|███████████████████████████████████████████████████████████████████████████████████▊                                               | 4000/6250 [3:32:27<45:52,  1.22s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5787088871002197, 'eval_wer': 0.6115750223202563, 'eval_cer': 0.15301821127478923, 'eval_runtime': 139.5642, 'eval_samples_per_second': 14.33, 'eval_steps_per_second': 1.791, 'epoch': 6.4}                                                                                                                                                
{'loss': 0.2051, 'learning_rate': 0.00011127272727272726, 'epoch': 6.42}                                                                                                      
{'loss': 0.1716, 'learning_rate': 0.00011077685950413223, 'epoch': 6.43}                                                                                                      
{'loss': 0.1215, 'learning_rate': 0.00011028099173553718, 'epoch': 6.45}                                                                                                      
{'loss': 0.103, 'learning_rate': 0.00010978512396694213, 'epoch': 6.46}                                                                                                       
{'loss': 0.0901, 'learning_rate': 0.00010928925619834709, 'epoch': 6.48}                                                                                                      
{'loss': 0.2345, 'learning_rate': 0.00010879338842975205, 'epoch': 6.5}                                                                                                       
{'loss': 0.1737, 'learning_rate': 0.00010829752066115702, 'epoch': 6.51}                                                                                                      
{'loss': 0.1266, 'learning_rate': 0.00010780165289256197, 'epoch': 6.53}                                                                                                      
{'loss': 0.1053, 'learning_rate': 0.00010730578512396694, 'epoch': 6.54}                                                                                                      
{'loss': 0.0946, 'learning_rate': 0.0001068099173553719, 'epoch': 6.56}                                                                                                       
 66%|█████████████████████████████████████████████████████████████████████████████████████▉                                             | 4100/6250 [3:37:46<45:04,  1.26s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5745288729667664, 'eval_wer': 0.6208182343364319, 'eval_cer': 0.1513755962917404, 'eval_runtime': 139.9422, 'eval_samples_per_second': 14.292, 'eval_steps_per_second': 1.786, 'epoch': 6.56}                                                                                                                                               
{'loss': 0.221, 'learning_rate': 0.00010631404958677685, 'epoch': 6.58}                                                                                                       
{'loss': 0.211, 'learning_rate': 0.0001058181818181818, 'epoch': 6.59}                                                                                                        
{'loss': 0.1512, 'learning_rate': 0.00010532231404958677, 'epoch': 6.61}                                                                                                      
{'loss': 0.0939, 'learning_rate': 0.00010482644628099172, 'epoch': 6.62}                                                                                                      
{'loss': 0.1067, 'learning_rate': 0.00010433057851239668, 'epoch': 6.64}                                                                                                      
{'loss': 0.1895, 'learning_rate': 0.00010383471074380163, 'epoch': 6.66}                                                                                                      
{'loss': 0.1709, 'learning_rate': 0.00010333884297520661, 'epoch': 6.67}                                                                                                      
{'loss': 0.1309, 'learning_rate': 0.00010284297520661157, 'epoch': 6.69}                                                                                                      
{'loss': 0.088, 'learning_rate': 0.00010234710743801652, 'epoch': 6.7}                                                                                                        
{'loss': 0.0763, 'learning_rate': 0.00010185123966942149, 'epoch': 6.72}                                                                                                      
 67%|████████████████████████████████████████████████████████████████████████████████████████                                           | 4200/6250 [3:43:07<43:55,  1.29s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5836904048919678, 'eval_wer': 0.630901738354078, 'eval_cer': 0.1533407338513696, 'eval_runtime': 139.7204, 'eval_samples_per_second': 14.314, 'eval_steps_per_second': 1.789, 'epoch': 6.72}                                                                                                                                                
{'loss': 0.228, 'learning_rate': 0.00010135537190082644, 'epoch': 6.74}                                                                                                       
{'loss': 0.2347, 'learning_rate': 0.0001008595041322314, 'epoch': 6.75}                                                                                                       
{'loss': 0.1238, 'learning_rate': 0.00010036363636363635, 'epoch': 6.77}                                                                                                      
{'loss': 0.1115, 'learning_rate': 9.986776859504131e-05, 'epoch': 6.78}                                                                                                       
{'loss': 0.0997, 'learning_rate': 9.937190082644627e-05, 'epoch': 6.8}                                                                                                        
{'loss': 0.2289, 'learning_rate': 9.887603305785122e-05, 'epoch': 6.82}                                                                                                       
{'loss': 0.1948, 'learning_rate': 9.83801652892562e-05, 'epoch': 6.83}                                                                                                        
{'loss': 0.1272, 'learning_rate': 9.788429752066116e-05, 'epoch': 6.85}                                                                                                       
{'loss': 0.1152, 'learning_rate': 9.738842975206611e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.0987, 'learning_rate': 9.689256198347106e-05, 'epoch': 6.88}                                                                                                       
 69%|██████████████████████████████████████████████████████████████████████████████████████████▏                                        | 4300/6250 [3:48:24<40:33,  1.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5471288561820984, 'eval_wer': 0.627015387847277, 'eval_cer': 0.15361075275269268, 'eval_runtime': 139.1245, 'eval_samples_per_second': 14.376, 'eval_steps_per_second': 1.797, 'epoch': 6.88}                                                                                                                                               
{'loss': 0.1973, 'learning_rate': 9.639669421487603e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.1807, 'learning_rate': 9.590082644628099e-05, 'epoch': 6.91}                                                                                                       
{'loss': 0.1494, 'learning_rate': 9.540495867768594e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1222, 'learning_rate': 9.490909090909089e-05, 'epoch': 6.94}                                                                                                       
{'loss': 0.0877, 'learning_rate': 9.441322314049585e-05, 'epoch': 6.96}                                                                                                       
{'loss': 0.2423, 'learning_rate': 9.391735537190083e-05, 'epoch': 6.98}                                                                                                       
{'loss': 0.1165, 'learning_rate': 9.342148760330578e-05, 'epoch': 6.99}                                                                                                       
 70%|███████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4375/6250 [3:52:57<40:32,  1.30s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-4375
Configuration saved in russian_portuguese_low/checkpoint-4375/config.json
Model weights saved in russian_portuguese_low/checkpoint-4375/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-4375/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1366, 'learning_rate': 9.292561983471073e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.1666, 'learning_rate': 9.24297520661157e-05, 'epoch': 7.02}                                                                                                        
{'loss': 0.1259, 'learning_rate': 9.193388429752066e-05, 'epoch': 7.04}                                                                                                       
 70%|████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4400/6250 [3:53:54<53:52,  1.75s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5527278780937195, 'eval_wer': 0.6206081613360643, 'eval_cer': 0.15331823227625935, 'eval_runtime': 139.9081, 'eval_samples_per_second': 14.295, 'eval_steps_per_second': 1.787, 'epoch': 7.04}                                                                                                                                              
{'loss': 0.1076, 'learning_rate': 9.143801652892561e-05, 'epoch': 7.06}                                                                                                       
{'loss': 0.074, 'learning_rate': 9.094214876033056e-05, 'epoch': 7.07}                                                                                                        
{'loss': 0.1288, 'learning_rate': 9.044628099173553e-05, 'epoch': 7.09}                                                                                                       
{'loss': 0.1599, 'learning_rate': 8.995041322314048e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.1659, 'learning_rate': 8.945454545454544e-05, 'epoch': 7.12}                                                                                                       
{'loss': 0.103, 'learning_rate': 8.895867768595042e-05, 'epoch': 7.14}                                                                                                        
{'loss': 0.0754, 'learning_rate': 8.846280991735537e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.1626, 'learning_rate': 8.796694214876033e-05, 'epoch': 7.17}                                                                                                       
{'loss': 0.1528, 'learning_rate': 8.747107438016528e-05, 'epoch': 7.18}                                                                                                       
{'loss': 0.1611, 'learning_rate': 8.697520661157025e-05, 'epoch': 7.2}                                                                                                        
 72%|██████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4500/6250 [3:59:15<52:17,  1.79s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5684956312179565, 'eval_wer': 0.6191376503334909, 'eval_cer': 0.15179562569379856, 'eval_runtime': 140.1577, 'eval_samples_per_second': 14.27, 'eval_steps_per_second': 1.784, 'epoch': 7.2}                                                                                                                                                
{'loss': 0.1015, 'learning_rate': 8.64793388429752e-05, 'epoch': 7.22}                                                                                                        
{'loss': 0.1098, 'learning_rate': 8.598347107438015e-05, 'epoch': 7.23}                                                                                                       
{'loss': 0.1447, 'learning_rate': 8.548760330578511e-05, 'epoch': 7.25}                                                                                                       
{'loss': 0.1782, 'learning_rate': 8.499173553719007e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.107, 'learning_rate': 8.449586776859503e-05, 'epoch': 7.28}                                                                                                        
{'loss': 0.0826, 'learning_rate': 8.4e-05, 'epoch': 7.3}                                                                                                                      
{'loss': 0.1025, 'learning_rate': 8.350413223140496e-05, 'epoch': 7.31}                                                                                                       
{'loss': 0.1259, 'learning_rate': 8.300826446280992e-05, 'epoch': 7.33}                                                                                                       
{'loss': 0.1785, 'learning_rate': 8.251239669421487e-05, 'epoch': 7.34}                                                                                                       
{'loss': 0.1546, 'learning_rate': 8.201652892561982e-05, 'epoch': 7.36}                                                                                                       
 74%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4600/6250 [4:04:35<47:59,  1.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5535292029380798, 'eval_wer': 0.6194002415839505, 'eval_cer': 0.15279319552368667, 'eval_runtime': 140.3987, 'eval_samples_per_second': 14.245, 'eval_steps_per_second': 1.781, 'epoch': 7.36}                                                                                                                                              
{'loss': 0.0986, 'learning_rate': 8.152066115702479e-05, 'epoch': 7.38}                                                                                                       
{'loss': 0.0882, 'learning_rate': 8.102479338842974e-05, 'epoch': 7.39}                                                                                                       
{'loss': 0.1469, 'learning_rate': 8.05289256198347e-05, 'epoch': 7.41}                                                                                                        
{'loss': 0.1659, 'learning_rate': 8.003305785123965e-05, 'epoch': 7.42}                                                                                                       
{'loss': 0.1355, 'learning_rate': 7.953719008264462e-05, 'epoch': 7.44}                                                                                                       
{'loss': 0.1141, 'learning_rate': 7.904132231404959e-05, 'epoch': 7.46}                                                                                                       
{'loss': 0.0889, 'learning_rate': 7.854545454545454e-05, 'epoch': 7.47}                                                                                                       
{'loss': 0.1227, 'learning_rate': 7.804958677685951e-05, 'epoch': 7.49}                                                                                                       
{'loss': 0.1765, 'learning_rate': 7.755371900826446e-05, 'epoch': 7.5}                                                                                                        
{'loss': 0.148, 'learning_rate': 7.705785123966941e-05, 'epoch': 7.52}                                                                                                        
 75%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4700/6250 [4:09:56<45:27,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5483058094978333, 'eval_wer': 0.6192952050837666, 'eval_cer': 0.15166811676817377, 'eval_runtime': 139.6659, 'eval_samples_per_second': 14.32, 'eval_steps_per_second': 1.79, 'epoch': 7.52}                                                                                                                                                
{'loss': 0.0874, 'learning_rate': 7.656198347107437e-05, 'epoch': 7.54}                                                                                                       
{'loss': 0.0797, 'learning_rate': 7.606611570247934e-05, 'epoch': 7.55}                                                                                                       
{'loss': 0.1122, 'learning_rate': 7.557024793388429e-05, 'epoch': 7.57}                                                                                                       
{'loss': 0.1903, 'learning_rate': 7.507438016528924e-05, 'epoch': 7.58}                                                                                                       
{'loss': 0.1454, 'learning_rate': 7.457851239669421e-05, 'epoch': 7.6}                                                                                                        
{'loss': 0.1139, 'learning_rate': 7.408264462809916e-05, 'epoch': 7.62}                                                                                                       
{'loss': 0.0943, 'learning_rate': 7.358677685950412e-05, 'epoch': 7.63}                                                                                                       
{'loss': 0.1442, 'learning_rate': 7.309090909090908e-05, 'epoch': 7.65}                                                                                                       
{'loss': 0.1809, 'learning_rate': 7.259504132231405e-05, 'epoch': 7.66}                                                                                                       
{'loss': 0.1425, 'learning_rate': 7.2099173553719e-05, 'epoch': 7.68}                                                                                                         
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 4800/6250 [4:15:12<42:09,  1.74s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5508018732070923, 'eval_wer': 0.6152512998266898, 'eval_cer': 0.15107557529027033, 'eval_runtime': 138.7307, 'eval_samples_per_second': 14.416, 'eval_steps_per_second': 1.802, 'epoch': 7.68}                                                                                                                                              
{'loss': 0.1003, 'learning_rate': 7.160330578512396e-05, 'epoch': 7.7}                                                                                                        
{'loss': 0.0738, 'learning_rate': 7.110743801652891e-05, 'epoch': 7.71}                                                                                                       
{'loss': 0.1245, 'learning_rate': 7.061157024793388e-05, 'epoch': 7.73}                                                                                                       
{'loss': 0.1899, 'learning_rate': 7.011570247933883e-05, 'epoch': 7.74}                                                                                                       
{'loss': 0.1578, 'learning_rate': 6.96198347107438e-05, 'epoch': 7.76}                                                                                                        
{'loss': 0.1062, 'learning_rate': 6.912396694214875e-05, 'epoch': 7.78}                                                                                                       
{'loss': 0.067, 'learning_rate': 6.862809917355371e-05, 'epoch': 7.79}                                                                                                        
{'loss': 0.1339, 'learning_rate': 6.813223140495866e-05, 'epoch': 7.81}                                                                                                       
{'loss': 0.2029, 'learning_rate': 6.763636363636363e-05, 'epoch': 7.82}                                                                                                       
{'loss': 0.1365, 'learning_rate': 6.71404958677686e-05, 'epoch': 7.84}                                                                                                        
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                            | 4900/6250 [4:20:30<39:25,  1.75s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5473841428756714, 'eval_wer': 0.6283808623496665, 'eval_cer': 0.1498154870840959, 'eval_runtime': 139.1528, 'eval_samples_per_second': 14.373, 'eval_steps_per_second': 1.797, 'epoch': 7.84}                                                                                                                                               
{'loss': 0.0849, 'learning_rate': 6.664462809917355e-05, 'epoch': 7.86}                                                                                                       
{'loss': 0.0804, 'learning_rate': 6.61487603305785e-05, 'epoch': 7.87}                                                                                                        
{'loss': 0.1241, 'learning_rate': 6.565289256198347e-05, 'epoch': 7.89}                                                                                                       
{'loss': 0.1706, 'learning_rate': 6.515702479338842e-05, 'epoch': 7.9}                                                                                                        
{'loss': 0.1233, 'learning_rate': 6.466115702479338e-05, 'epoch': 7.92}                                                                                                       
{'loss': 0.111, 'learning_rate': 6.416528925619835e-05, 'epoch': 7.94}                                                                                                        
{'loss': 0.0788, 'learning_rate': 6.36694214876033e-05, 'epoch': 7.95}                                                                                                        
{'loss': 0.1285, 'learning_rate': 6.317355371900827e-05, 'epoch': 7.97}                                                                                                       
{'loss': 0.1348, 'learning_rate': 6.267768595041322e-05, 'epoch': 7.98}                                                                                                       
{'loss': 0.0668, 'learning_rate': 6.218181818181817e-05, 'epoch': 8.0}                                                                                                        
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 5000/6250 [4:25:39<27:43,  1.33s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5652136206626892, 'eval_wer': 0.5930885982879051, 'eval_cer': 0.1472503075215265, 'eval_runtime': 138.8268, 'eval_samples_per_second': 14.406, 'eval_steps_per_second': 1.801, 'epoch': 8.0}                                                                                                                                                
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 5000/6250 [4:27:58<27:43,  1.33s/it]
Saving model checkpoint to russian_portuguese_low/checkpoint-5000                                                                                                             
Configuration saved in russian_portuguese_low/checkpoint-5000/config.json
Model weights saved in russian_portuguese_low/checkpoint-5000/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-5000/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1558, 'learning_rate': 6.168595041322313e-05, 'epoch': 8.02}                                                                                                       
{'loss': 0.1367, 'learning_rate': 6.11900826446281e-05, 'epoch': 8.03}                                                                                                        
{'loss': 0.1061, 'learning_rate': 6.0694214876033056e-05, 'epoch': 8.05}                                                                                                      
{'loss': 0.0919, 'learning_rate': 6.0198347107438016e-05, 'epoch': 8.06}                                                                                                      
{'loss': 0.0498, 'learning_rate': 5.970247933884297e-05, 'epoch': 8.08}                                                                                                       
{'loss': 0.1859, 'learning_rate': 5.920661157024793e-05, 'epoch': 8.1}                                                                                                        
{'loss': 0.1491, 'learning_rate': 5.8710743801652884e-05, 'epoch': 8.11}                                                                                                      
{'loss': 0.1052, 'learning_rate': 5.821487603305785e-05, 'epoch': 8.13}                                                                                                       
{'loss': 0.1, 'learning_rate': 5.7719008264462805e-05, 'epoch': 8.14}                                                                                                         
{'loss': 0.0653, 'learning_rate': 5.7223140495867765e-05, 'epoch': 8.16}                                                                                                      
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                        | 5100/6250 [4:31:00<23:48,  1.24s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5792580842971802, 'eval_wer': 0.6140433800745759, 'eval_cer': 0.14760283219825387, 'eval_runtime': 139.9659, 'eval_samples_per_second': 14.289, 'eval_steps_per_second': 1.786, 'epoch': 8.16}                                                                                                                                              
{'loss': 0.1612, 'learning_rate': 5.672727272727272e-05, 'epoch': 8.18}                                                                                                       
{'loss': 0.154, 'learning_rate': 5.623140495867768e-05, 'epoch': 8.19}                                                                                                        
{'loss': 0.0998, 'learning_rate': 5.5735537190082647e-05, 'epoch': 8.21}                                                                                                      
{'loss': 0.0648, 'learning_rate': 5.52396694214876e-05, 'epoch': 8.22}                                                                                                        
{'loss': 0.075, 'learning_rate': 5.474380165289256e-05, 'epoch': 8.24}                                                                                                        
{'loss': 0.1569, 'learning_rate': 5.4247933884297514e-05, 'epoch': 8.26}                                                                                                      
{'loss': 0.1428, 'learning_rate': 5.3752066115702475e-05, 'epoch': 8.27}                                                                                                      
{'loss': 0.1212, 'learning_rate': 5.3256198347107435e-05, 'epoch': 8.29}                                                                                                      
{'loss': 0.0645, 'learning_rate': 5.2760330578512396e-05, 'epoch': 8.3}                                                                                                       
{'loss': 0.0701, 'learning_rate': 5.226446280991735e-05, 'epoch': 8.32}                                                                                                       
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 5200/6250 [4:36:19<21:53,  1.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5748046636581421, 'eval_wer': 0.598813087547923, 'eval_cer': 0.14602772194053584, 'eval_runtime': 139.9095, 'eval_samples_per_second': 14.295, 'eval_steps_per_second': 1.787, 'epoch': 8.32}                                                                                                                                               
{'loss': 0.1573, 'learning_rate': 5.176859504132231e-05, 'epoch': 8.34}                                                                                                       
{'loss': 0.1363, 'learning_rate': 5.1272727272727264e-05, 'epoch': 8.35}                                                                                                      
{'loss': 0.1229, 'learning_rate': 5.077685950413223e-05, 'epoch': 8.37}                                                                                                       
{'loss': 0.0934, 'learning_rate': 5.0280991735537184e-05, 'epoch': 8.38}                                                                                                      
{'loss': 0.077, 'learning_rate': 4.9785123966942145e-05, 'epoch': 8.4}                                                                                                        
{'loss': 0.1723, 'learning_rate': 4.92892561983471e-05, 'epoch': 8.42}                                                                                                        
{'loss': 0.1136, 'learning_rate': 4.879338842975206e-05, 'epoch': 8.43}                                                                                                       
{'loss': 0.0912, 'learning_rate': 4.8297520661157026e-05, 'epoch': 8.45}                                                                                                      
{'loss': 0.0836, 'learning_rate': 4.780165289256198e-05, 'epoch': 8.46}                                                                                                       
{'loss': 0.061, 'learning_rate': 4.730578512396694e-05, 'epoch': 8.48}                                                                                                        
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 5300/6250 [4:41:39<20:29,  1.29s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5546247959136963, 'eval_wer': 0.5971325035449819, 'eval_cer': 0.14577270408928625, 'eval_runtime': 140.4899, 'eval_samples_per_second': 14.236, 'eval_steps_per_second': 1.779, 'epoch': 8.48}                                                                                                                                              
{'loss': 0.1622, 'learning_rate': 4.6809917355371894e-05, 'epoch': 8.5}                                                                                                       
{'loss': 0.1394, 'learning_rate': 4.6314049586776855e-05, 'epoch': 8.51}                                                                                                      
{'loss': 0.1002, 'learning_rate': 4.5818181818181815e-05, 'epoch': 8.53}                                                                                                      
{'loss': 0.0566, 'learning_rate': 4.5322314049586775e-05, 'epoch': 8.54}                                                                                                      
{'loss': 0.0775, 'learning_rate': 4.482644628099173e-05, 'epoch': 8.56}                                                                                                       
{'loss': 0.1787, 'learning_rate': 4.433057851239669e-05, 'epoch': 8.58}                                                                                                       
{'loss': 0.125, 'learning_rate': 4.383471074380164e-05, 'epoch': 8.59}                                                                                                        
{'loss': 0.0941, 'learning_rate': 4.333884297520661e-05, 'epoch': 8.61}                                                                                                       
{'loss': 0.0979, 'learning_rate': 4.284297520661157e-05, 'epoch': 8.62}                                                                                                       
{'loss': 0.0414, 'learning_rate': 4.2347107438016525e-05, 'epoch': 8.64}                                                                                                      
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 5400/6250 [4:46:58<17:57,  1.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5513724684715271, 'eval_wer': 0.5949267370411218, 'eval_cer': 0.14522516576160333, 'eval_runtime': 138.8661, 'eval_samples_per_second': 14.402, 'eval_steps_per_second': 1.8, 'epoch': 8.64}                                                                                                                                                
{'loss': 0.134, 'learning_rate': 4.1851239669421485e-05, 'epoch': 8.66}                                                                                                       
{'loss': 0.1292, 'learning_rate': 4.135537190082644e-05, 'epoch': 8.67}                                                                                                       
{'loss': 0.1038, 'learning_rate': 4.0859504132231406e-05, 'epoch': 8.69}                                                                                                      
{'loss': 0.0746, 'learning_rate': 4.036363636363636e-05, 'epoch': 8.7}                                                                                                        
{'loss': 0.0796, 'learning_rate': 3.986776859504132e-05, 'epoch': 8.72}                                                                                                       
{'loss': 0.183, 'learning_rate': 3.9371900826446274e-05, 'epoch': 8.74}                                                                                                       
{'loss': 0.1368, 'learning_rate': 3.8876033057851234e-05, 'epoch': 8.75}                                                                                                      
{'loss': 0.1099, 'learning_rate': 3.83801652892562e-05, 'epoch': 8.77}                                                                                                        
{'loss': 0.0649, 'learning_rate': 3.7884297520661155e-05, 'epoch': 8.78}                                                                                                      
{'loss': 0.0706, 'learning_rate': 3.7388429752066116e-05, 'epoch': 8.8}                                                                                                       
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 5500/6250 [4:52:16<15:50,  1.27s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5587500929832458, 'eval_wer': 0.590305131033034, 'eval_cer': 0.14497014791035373, 'eval_runtime': 140.3429, 'eval_samples_per_second': 14.251, 'eval_steps_per_second': 1.781, 'epoch': 8.8}                                                                                                                                                
{'loss': 0.1892, 'learning_rate': 3.689256198347107e-05, 'epoch': 8.82}                                                                                                       
{'loss': 0.1382, 'learning_rate': 3.639669421487603e-05, 'epoch': 8.83}                                                                                                       
{'loss': 0.078, 'learning_rate': 3.590082644628099e-05, 'epoch': 8.85}                                                                                                        
{'loss': 0.0742, 'learning_rate': 3.540495867768595e-05, 'epoch': 8.86}                                                                                                       
{'loss': 0.0471, 'learning_rate': 3.4909090909090904e-05, 'epoch': 8.88}                                                                                                      
{'loss': 0.1838, 'learning_rate': 3.4413223140495865e-05, 'epoch': 8.9}                                                                                                       
{'loss': 0.114, 'learning_rate': 3.3917355371900825e-05, 'epoch': 8.91}                                                                                                       
{'loss': 0.0903, 'learning_rate': 3.342148760330578e-05, 'epoch': 8.93}                                                                                                       
{'loss': 0.0633, 'learning_rate': 3.292561983471074e-05, 'epoch': 8.94}                                                                                                       
{'loss': 0.0604, 'learning_rate': 3.24297520661157e-05, 'epoch': 8.96}                                                                                                        
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 5600/6250 [4:57:35<13:30,  1.25s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5871818661689758, 'eval_wer': 0.5997584160495772, 'eval_cer': 0.14673277129399057, 'eval_runtime': 139.2265, 'eval_samples_per_second': 14.365, 'eval_steps_per_second': 1.796, 'epoch': 8.96}                                                                                                                                              
{'loss': 0.1551, 'learning_rate': 3.1933884297520654e-05, 'epoch': 8.98}                                                                                                      
{'loss': 0.0829, 'learning_rate': 3.143801652892562e-05, 'epoch': 8.99}                                                                                                       
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉             | 5625/6250 [5:00:39<13:44,  1.32s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-5625
Configuration saved in russian_portuguese_low/checkpoint-5625/config.json
Model weights saved in russian_portuguese_low/checkpoint-5625/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-5625/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.0968, 'learning_rate': 3.0942148760330575e-05, 'epoch': 9.01}                                                                                                      
{'loss': 0.1357, 'learning_rate': 3.0446280991735535e-05, 'epoch': 9.02}                                                                                                      
{'loss': 0.1256, 'learning_rate': 2.9950413223140492e-05, 'epoch': 9.04}                                                                                                      
{'loss': 0.0797, 'learning_rate': 2.945454545454545e-05, 'epoch': 9.06}                                                                                                       
{'loss': 0.0633, 'learning_rate': 2.8958677685950413e-05, 'epoch': 9.07}                                                                                                      
{'loss': 0.1035, 'learning_rate': 2.846280991735537e-05, 'epoch': 9.09}                                                                                                       
{'loss': 0.174, 'learning_rate': 2.796694214876033e-05, 'epoch': 9.1}                                                                                                         
{'loss': 0.1127, 'learning_rate': 2.7471074380165288e-05, 'epoch': 9.12}                                                                                                      
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 5700/6250 [5:03:05<16:47,  1.83s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5691826343536377, 'eval_wer': 0.5928260070374455, 'eval_cer': 0.1453226725870811, 'eval_runtime': 141.001, 'eval_samples_per_second': 14.184, 'eval_steps_per_second': 1.773, 'epoch': 9.12}                                                                                                                                                
{'loss': 0.0807, 'learning_rate': 2.6975206611570245e-05, 'epoch': 9.14}                                                                                                      
{'loss': 0.0633, 'learning_rate': 2.6479338842975205e-05, 'epoch': 9.15}                                                                                                      
{'loss': 0.1113, 'learning_rate': 2.5983471074380162e-05, 'epoch': 9.17}                                                                                                      
{'loss': 0.1417, 'learning_rate': 2.5487603305785123e-05, 'epoch': 9.18}                                                                                                      
{'loss': 0.1246, 'learning_rate': 2.499173553719008e-05, 'epoch': 9.2}                                                                                                        
{'loss': 0.0736, 'learning_rate': 2.4495867768595037e-05, 'epoch': 9.22}                                                                                                      
{'loss': 0.0454, 'learning_rate': 2.3999999999999997e-05, 'epoch': 9.23}                                                                                                      
{'loss': 0.1088, 'learning_rate': 2.3504132231404954e-05, 'epoch': 9.25}                                                                                                      
{'loss': 0.1539, 'learning_rate': 2.3008264462809918e-05, 'epoch': 9.26}                                                                                                      
{'loss': 0.122, 'learning_rate': 2.2512396694214875e-05, 'epoch': 9.28}                                                                                                       
 93%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌         | 5800/6250 [5:08:27<13:29,  1.80s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5673205852508545, 'eval_wer': 0.6025944015545402, 'eval_cer': 0.1462227355914914, 'eval_runtime': 140.3573, 'eval_samples_per_second': 14.249, 'eval_steps_per_second': 1.781, 'epoch': 9.28}                                                                                                                                               
{'loss': 0.0785, 'learning_rate': 2.2016528925619832e-05, 'epoch': 9.3}                                                                                                       
{'loss': 0.059, 'learning_rate': 2.1520661157024793e-05, 'epoch': 9.31}                                                                                                       
{'loss': 0.101, 'learning_rate': 2.102479338842975e-05, 'epoch': 9.33}                                                                                                        
{'loss': 0.1293, 'learning_rate': 2.052892561983471e-05, 'epoch': 9.34}                                                                                                       
{'loss': 0.078, 'learning_rate': 2.0033057851239667e-05, 'epoch': 9.36}                                                                                                       
{'loss': 0.0631, 'learning_rate': 1.9537190082644628e-05, 'epoch': 9.38}                                                                                                      
{'loss': 0.0748, 'learning_rate': 1.9041322314049585e-05, 'epoch': 9.39}                                                                                                      
{'loss': 0.1165, 'learning_rate': 1.8545454545454545e-05, 'epoch': 9.41}                                                                                                      
{'loss': 0.156, 'learning_rate': 1.8049586776859502e-05, 'epoch': 9.42}                                                                                                       
{'loss': 0.105, 'learning_rate': 1.755371900826446e-05, 'epoch': 9.44}                                                                                                        
 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 5900/6250 [5:13:46<10:24,  1.78s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5557699799537659, 'eval_wer': 0.6056404600598708, 'eval_cer': 0.145780204614323, 'eval_runtime': 140.2146, 'eval_samples_per_second': 14.264, 'eval_steps_per_second': 1.783, 'epoch': 9.44}                                                                                                                                                
{'loss': 0.083, 'learning_rate': 1.705785123966942e-05, 'epoch': 9.46}                                                                                                        
{'loss': 0.0724, 'learning_rate': 1.656198347107438e-05, 'epoch': 9.47}                                                                                                       
{'loss': 0.1014, 'learning_rate': 1.6066115702479337e-05, 'epoch': 9.49}                                                                                                      
{'loss': 0.1499, 'learning_rate': 1.5570247933884294e-05, 'epoch': 9.5}                                                                                                       
{'loss': 0.1038, 'learning_rate': 1.5074380165289255e-05, 'epoch': 9.52}                                                                                                      
{'loss': 0.0667, 'learning_rate': 1.4578512396694214e-05, 'epoch': 9.54}                                                                                                      
{'loss': 0.0571, 'learning_rate': 1.4082644628099172e-05, 'epoch': 9.55}                                                                                                      
{'loss': 0.1003, 'learning_rate': 1.3586776859504131e-05, 'epoch': 9.57}                                                                                                      
{'loss': 0.1436, 'learning_rate': 1.309090909090909e-05, 'epoch': 9.58}                                                                                                       
{'loss': 0.0925, 'learning_rate': 1.2595041322314047e-05, 'epoch': 9.6}                                                                                                       
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 6000/6250 [5:19:06<07:19,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5773935317993164, 'eval_wer': 0.6005461898009559, 'eval_cer': 0.14605772404068285, 'eval_runtime': 139.7187, 'eval_samples_per_second': 14.314, 'eval_steps_per_second': 1.789, 'epoch': 9.6}                                                                                                                                               
{'loss': 0.0755, 'learning_rate': 1.2099173553719008e-05, 'epoch': 9.62}                                                                                                      
{'loss': 0.0658, 'learning_rate': 1.1603305785123966e-05, 'epoch': 9.63}                                                                                                      
{'loss': 0.0976, 'learning_rate': 1.1107438016528925e-05, 'epoch': 9.65}                                                                                                      
{'loss': 0.117, 'learning_rate': 1.0611570247933884e-05, 'epoch': 9.66}                                                                                                       
{'loss': 0.0984, 'learning_rate': 1.0115702479338841e-05, 'epoch': 9.68}                                                                                                      
{'loss': 0.0683, 'learning_rate': 9.6198347107438e-06, 'epoch': 9.7}                                                                                                          
{'loss': 0.0567, 'learning_rate': 9.12396694214876e-06, 'epoch': 9.71}                                                                                                        
{'loss': 0.0961, 'learning_rate': 8.628099173553719e-06, 'epoch': 9.73}                                                                                                       
{'loss': 0.1285, 'learning_rate': 8.132231404958678e-06, 'epoch': 9.74}                                                                                                       
{'loss': 0.1098, 'learning_rate': 7.636363636363636e-06, 'epoch': 9.76}                                                                                                       
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 6100/6250 [5:24:26<04:27,  1.79s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.5774593353271484, 'eval_wer': 0.600493671550864, 'eval_cer': 0.14554018781314693, 'eval_runtime': 140.3946, 'eval_samples_per_second': 14.246, 'eval_steps_per_second': 1.781, 'epoch': 9.76}                                                                                                                                               
{'loss': 0.0506, 'learning_rate': 7.140495867768594e-06, 'epoch': 9.78}                                                                                                       
{'loss': 0.0631, 'learning_rate': 6.644628099173553e-06, 'epoch': 9.79}                                                                                                       
{'loss': 0.0864, 'learning_rate': 6.148760330578513e-06, 'epoch': 9.81}                                                                                                       
{'loss': 0.1531, 'learning_rate': 5.652892561983471e-06, 'epoch': 9.82}                                                                                                       
{'loss': 0.1134, 'learning_rate': 5.157024793388429e-06, 'epoch': 9.84}                                                                                                       
{'loss': 0.0767, 'learning_rate': 4.661157024793388e-06, 'epoch': 9.86}                                                                                                       
{'loss': 0.0642, 'learning_rate': 4.165289256198347e-06, 'epoch': 9.87}                                                                                                       
{'loss': 0.0735, 'learning_rate': 3.6694214876033052e-06, 'epoch': 9.89}                                                                                                      
{'loss': 0.1264, 'learning_rate': 3.1735537190082644e-06, 'epoch': 9.9}                                                                                                       
{'loss': 0.0989, 'learning_rate': 2.677685950413223e-06, 'epoch': 9.92}                                                                                                       
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 6200/6250 [5:29:47<01:27,  1.76s/it]***** Running Evaluation *****
  Num examples = 2000
  Batch size = 8
{'eval_loss': 0.574562132358551, 'eval_wer': 0.5995483430492096, 'eval_cer': 0.1453976778374486, 'eval_runtime': 140.7719, 'eval_samples_per_second': 14.207, 'eval_steps_per_second': 1.776, 'epoch': 9.92}                                                                                                                                                
{'loss': 0.0636, 'learning_rate': 2.1818181818181815e-06, 'epoch': 9.94}                                                                                                      
{'loss': 0.0465, 'learning_rate': 1.6859504132231403e-06, 'epoch': 9.95}                                                                                                      
{'loss': 0.1435, 'learning_rate': 1.190082644628099e-06, 'epoch': 9.97}                                                                                                       
{'loss': 0.1032, 'learning_rate': 6.942148760330578e-07, 'epoch': 9.98}                                                                                                       
{'loss': 0.0606, 'learning_rate': 1.9834710743801653e-07, 'epoch': 10.0}                                                                                                      
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6250/6250 [5:33:31<00:00,  1.37s/it]Saving model checkpoint to russian_portuguese_low/checkpoint-6250
Configuration saved in russian_portuguese_low/checkpoint-6250/config.json
Model weights saved in russian_portuguese_low/checkpoint-6250/pytorch_model.bin
Feature extractor saved in russian_portuguese_low/checkpoint-6250/preprocessor_config.json


Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 20013.9715, 'train_samples_per_second': 4.997, 'train_steps_per_second': 0.312, 'train_loss': 0.7415639805936813, 'epoch': 10.0}                            
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6250/6250 [5:33:33<00:00,  3.20s/it]
----------------- Training complete. -----------------


(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ 


