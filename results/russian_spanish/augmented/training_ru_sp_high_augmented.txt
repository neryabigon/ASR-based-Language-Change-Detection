(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ python3 training_script.py 
2023-04-02 20:59:12.382704: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-02 20:59:12.512226: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-02 20:59:12.515768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-04-02 20:59:12.515784: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-04-02 20:59:13.027882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-04-02 20:59:13.027946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-04-02 20:59:13.027953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
----------------- Checking if cuda is available... -----------------
Cuda Available = True


----------------- Loading Datasets complete. -----------------
----------------- Loading Datasets complete. -----------------


----------------- Extracting all characters... -----------------
Parameter 'function'=<function extract_all_chars at 0x7f0ca30ca430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 95/96 [12:54<00:08,  8.15s/ba]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 11/12 [01:42<00:09,  9.35s/ba]
----------------- Extracting all characters complete. -----------------


----------------- Preparing vocab... -----------------
Vocab_dict: {'m': 0, 'h': 1, 'q': 2, 'x': 3, "'": 4, 's': 5, 'f': 6, '<': 7, 'i': 8, 'd': 9, '-': 10, '>': 11, '!': 12, 'b': 13, 'v': 14, 'p': 15, 'l': 16, 'n': 17, 'o': 18, 'k': 19, 'y': 20, 'c': 21, 't': 22, 'a': 23, 'u': 24, 'g': 25, 'w': 26, 'r': 27, '?': 28, 'e': 29, 'z': 30, 'j': 31, ' ': 32}
Vocab_len: 35
----------------- Preparing vocab complete. -----------------


----------------- Saving vocab to jason... -----------------
----------------- Saving vocab to jason complete. -----------------


----------------- Preparing datasets... -----------------
#0:   0%|                                                                                                                                            | 0/3047 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                            | 0/3046 [00:00<?, ?ex/s]
  warnings.warn(
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                    | 1/3046 [00:00<11:19,  4.48ex/s]
  warnings.warn(
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3046/3046 [09:31<00:00,  5.33ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [09:56<00:00,  5.10ex/s]
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [10:02<00:00,  5.06ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3047/3047 [10:05<00:00,  5.03ex/s]
#0:   0%|                                                                                                                                             | 0/375 [00:00<?, ?ex/s]
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|                                                                                                                                             | 0/375 [00:00<?, ?ex/s]
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.%|â–Ž                                                                                                                                    | 1/375 [00:00<01:29,  4.17ex/s]
  warnings.warn(

/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
#1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:18<00:00,  4.77ex/s]
#0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:19<00:00,  4.73ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:19<00:00,  4.71ex/s]
#3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:20<00:00,  4.68ex/s]
#2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:19<00:00,  4.36ex/s]
#3:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 373/375 [01:19<00:00,  5.07ex/s]
----------------- Preparing datasets complete. -----------------â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [01:20<00:00,  4.49ex/s]


----------------- Loading Metrics... -----------------
/home/or/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-/training_script.py:173: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  wer_metric = load_metric("wer")
----------------- Loading Metrics complete. -----------------


----------------- Loading Model... -----------------
Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['project_hid.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'project_hid.weight', 'project_q.bias', 'quantizer.codevectors', 'quantizer.weight_proj.weight']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
----------------- Loading Model complete. -----------------


Using cuda_amp half precision backend
----------------- Training... -----------------
/home/or/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 12187
  Num Epochs = 10
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 16
  Gradient Accumulation steps = 2
  Total optimization steps = 7620
  Number of trainable parameters = 311264419
  0%|                                                                                                                                                | 0/7620 [00:00<?, ?it/s]/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 12.6206, 'learning_rate': 1.3499999999999998e-05, 'epoch': 0.01}                                                                                                     
{'loss': 13.5696, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.03}                                                                                                     
{'loss': 14.8325, 'learning_rate': 4.2e-05, 'epoch': 0.04}                                                                                                                    
{'loss': 16.1432, 'learning_rate': 5.5499999999999994e-05, 'epoch': 0.05}                                                                                                     
{'loss': 14.9326, 'learning_rate': 6.9e-05, 'epoch': 0.07}                                                                                                                    
{'loss': 5.7347, 'learning_rate': 8.4e-05, 'epoch': 0.08}                                                                                                                     
{'loss': 4.0757, 'learning_rate': 9.9e-05, 'epoch': 0.09}                                                                                                                     
{'loss': 3.5293, 'learning_rate': 0.00011399999999999999, 'epoch': 0.1}                                                                                                       
{'loss': 3.2649, 'learning_rate': 0.000129, 'epoch': 0.12}                                                                                                                    
{'loss': 3.0665, 'learning_rate': 0.00014399999999999998, 'epoch': 0.13}                                                                                                      
  1%|â–ˆâ–‹                                                                                                                                  | 100/7620 [05:46<5:01:28,  2.41s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 3.1011576652526855, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 296.5182, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 0.634, 'epoch': 0.13}                                                                                                                                                               
{'loss': 3.1082, 'learning_rate': 0.000159, 'epoch': 0.14}                                                                                                                    
{'loss': 2.9728, 'learning_rate': 0.00017399999999999997, 'epoch': 0.16}                                                                                                      
{'loss': 2.9505, 'learning_rate': 0.00018899999999999999, 'epoch': 0.17}                                                                                                      
{'loss': 2.9491, 'learning_rate': 0.000204, 'epoch': 0.18}                                                                                                                    
{'loss': 2.9599, 'learning_rate': 0.00021899999999999998, 'epoch': 0.2}                                                                                                       
{'loss': 3.1024, 'learning_rate': 0.000234, 'epoch': 0.21}                                                                                                                    
{'loss': 3.0021, 'learning_rate': 0.000249, 'epoch': 0.22}                                                                                                                    
{'loss': 2.9381, 'learning_rate': 0.00026399999999999997, 'epoch': 0.24}                                                                                                      
{'loss': 2.9474, 'learning_rate': 0.000279, 'epoch': 0.25}                                                                                                                    
{'loss': 2.9506, 'learning_rate': 0.000294, 'epoch': 0.26}                                                                                                                    
  3%|â–ˆâ–ˆâ–ˆâ–                                                                                                                                | 200/7620 [16:44<4:57:21,  2.40s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 3.0489981174468994, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 304.4212, 'eval_samples_per_second': 4.927, 'eval_steps_per_second': 0.618, 'epoch': 0.26}                                                                                                                                                               
{'loss': 3.0973, 'learning_rate': 0.0002997574123989218, 'epoch': 0.28}                                                                                                       
{'loss': 2.9977, 'learning_rate': 0.0002993530997304582, 'epoch': 0.29}                                                                                                       
{'loss': 2.9401, 'learning_rate': 0.00029894878706199457, 'epoch': 0.3}                                                                                                       
{'loss': 2.931, 'learning_rate': 0.000298544474393531, 'epoch': 0.31}                                                                                                         
{'loss': 2.9615, 'learning_rate': 0.0002981401617250673, 'epoch': 0.33}                                                                                                       
{'loss': 3.0928, 'learning_rate': 0.00029773584905660376, 'epoch': 0.34}                                                                                                      
{'loss': 2.9415, 'learning_rate': 0.00029733153638814014, 'epoch': 0.35}                                                                                                      
{'loss': 2.9461, 'learning_rate': 0.0002969272237196765, 'epoch': 0.37}                                                                                                       
{'loss': 2.9513, 'learning_rate': 0.0002965229110512129, 'epoch': 0.38}                                                                                                       
{'loss': 2.9535, 'learning_rate': 0.00029611859838274933, 'epoch': 0.39}                                                                                                      
  4%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                              | 300/7620 [27:51<4:47:50,  2.36s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 3.018505096435547, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 278.984, 'eval_samples_per_second': 5.377, 'eval_steps_per_second': 0.674, 'epoch': 0.39}                                                                                                                                                                 
{'loss': 3.132, 'learning_rate': 0.0002957142857142857, 'epoch': 0.41}                                                                                                        
{'loss': 2.9475, 'learning_rate': 0.0002953099730458221, 'epoch': 0.42}                                                                                                       
{'loss': 2.9237, 'learning_rate': 0.00029490566037735847, 'epoch': 0.43}                                                                                                      
{'loss': 2.9517, 'learning_rate': 0.00029450134770889484, 'epoch': 0.45}                                                                                                      
{'loss': 2.9724, 'learning_rate': 0.0002940970350404312, 'epoch': 0.46}                                                                                                       
{'loss': 3.1688, 'learning_rate': 0.0002936927223719676, 'epoch': 0.47}                                                                                                       
{'loss': 2.9482, 'learning_rate': 0.00029328840970350403, 'epoch': 0.49}                                                                                                      
{'loss': 2.9517, 'learning_rate': 0.0002928840970350404, 'epoch': 0.5}                                                                                                        
{'loss': 2.9464, 'learning_rate': 0.0002924797843665768, 'epoch': 0.51}                                                                                                       
{'loss': 2.976, 'learning_rate': 0.00029207547169811317, 'epoch': 0.52}                                                                                                       
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                             | 400/7620 [38:13<4:34:32,  2.28s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 3.0643815994262695, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 279.4396, 'eval_samples_per_second': 5.368, 'eval_steps_per_second': 0.673, 'epoch': 0.52}                                                                                                                                                               
{'loss': 3.0807, 'learning_rate': 0.0002916711590296496, 'epoch': 0.54}                                                                                                       
{'loss': 2.9641, 'learning_rate': 0.00029126684636118593, 'epoch': 0.55}                                                                                                      
{'loss': 2.9359, 'learning_rate': 0.00029086253369272236, 'epoch': 0.56}                                                                                                      
{'loss': 2.9329, 'learning_rate': 0.00029045822102425874, 'epoch': 0.58}                                                                                                      
{'loss': 2.933, 'learning_rate': 0.0002900539083557951, 'epoch': 0.59}                                                                                                        
{'loss': 3.0437, 'learning_rate': 0.0002896495956873315, 'epoch': 0.6}                                                                                                        
{'loss': 2.9436, 'learning_rate': 0.0002892452830188679, 'epoch': 0.62}                                                                                                       
{'loss': 2.9086, 'learning_rate': 0.0002888409703504043, 'epoch': 0.63}                                                                                                       
{'loss': 2.9388, 'learning_rate': 0.0002884366576819407, 'epoch': 0.64}                                                                                                       
{'loss': 2.9169, 'learning_rate': 0.00028803234501347707, 'epoch': 0.66}                                                                                                      
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                           | 500/7620 [48:35<4:29:26,  2.27s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 2.988123655319214, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 296.3552, 'eval_samples_per_second': 5.061, 'eval_steps_per_second': 0.634, 'epoch': 0.66}                                                                                                                                                                
{'loss': 3.0081, 'learning_rate': 0.00028762803234501345, 'epoch': 0.67}                                                                                                      
{'loss': 2.948, 'learning_rate': 0.0002872237196765498, 'epoch': 0.68}                                                                                                        
{'loss': 2.9224, 'learning_rate': 0.0002868194070080862, 'epoch': 0.7}                                                                                                        
{'loss': 2.9224, 'learning_rate': 0.00028641509433962264, 'epoch': 0.71}                                                                                                      
{'loss': 2.9414, 'learning_rate': 0.000286010781671159, 'epoch': 0.72}                                                                                                        
{'loss': 2.9498, 'learning_rate': 0.0002856064690026954, 'epoch': 0.73}                                                                                                       
{'loss': 2.9272, 'learning_rate': 0.00028520215633423177, 'epoch': 0.75}                                                                                                      
{'loss': 2.9159, 'learning_rate': 0.00028479784366576815, 'epoch': 0.76}                                                                                                      
{'loss': 2.9175, 'learning_rate': 0.00028439353099730453, 'epoch': 0.77}                                                                                                      
{'loss': 2.9661, 'learning_rate': 0.00028398921832884096, 'epoch': 0.79}                                                                                                      
  8%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                         | 600/7620 [59:34<4:47:11,  2.45s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 3.003894567489624, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 287.901, 'eval_samples_per_second': 5.21, 'eval_steps_per_second': 0.653, 'epoch': 0.79}                                                                                                                                                                  
{'loss': 2.9679, 'learning_rate': 0.00028358490566037734, 'epoch': 0.8}                                                                                                       
{'loss': 2.9394, 'learning_rate': 0.0002831805929919137, 'epoch': 0.81}                                                                                                       
{'loss': 2.9117, 'learning_rate': 0.0002827762803234501, 'epoch': 0.83}                                                                                                       
{'loss': 2.9017, 'learning_rate': 0.0002823719676549865, 'epoch': 0.84}                                                                                                       
{'loss': 2.9262, 'learning_rate': 0.0002819676549865229, 'epoch': 0.85}                                                                                                       
{'loss': 2.921, 'learning_rate': 0.00028156334231805924, 'epoch': 0.87}                                                                                                       
{'loss': 2.9127, 'learning_rate': 0.00028115902964959567, 'epoch': 0.88}                                                                                                      
{'loss': 2.9155, 'learning_rate': 0.00028075471698113205, 'epoch': 0.89}                                                                                                      
{'loss': 2.9202, 'learning_rate': 0.0002803504043126685, 'epoch': 0.91}                                                                                                       
{'loss': 2.8922, 'learning_rate': 0.0002799460916442048, 'epoch': 0.92}                                                                                                       
  9%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                      | 700/7620 [1:10:13<4:19:57,  2.25s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 2.908308982849121, 'eval_wer': 1.0, 'eval_cer': 0.9918635447274452, 'eval_runtime': 286.9302, 'eval_samples_per_second': 5.228, 'eval_steps_per_second': 0.655, 'epoch': 0.92}                                                                                                                                                                
{'loss': 2.9173, 'learning_rate': 0.00027954177897574124, 'epoch': 0.93}                                                                                                      
{'loss': 2.913, 'learning_rate': 0.0002791374663072776, 'epoch': 0.94}                                                                                                        
{'loss': 2.8949, 'learning_rate': 0.000278733153638814, 'epoch': 0.96}                                                                                                        
{'loss': 2.8867, 'learning_rate': 0.0002783288409703504, 'epoch': 0.97}                                                                                                       
{'loss': 2.907, 'learning_rate': 0.00027792452830188675, 'epoch': 0.98}                                                                                                       
{'loss': 2.8895, 'learning_rate': 0.0002775202156334232, 'epoch': 1.0}                                                                                                        
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                     | 761/7620 [1:18:33<5:40:34,  2.98s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-761
Configuration saved in russian_spanish_high_augmented/checkpoint-761/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-761/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-761/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 2.8755, 'learning_rate': 0.0002771159029649595, 'epoch': 1.01}                                                                                                       
{'loss': 2.8705, 'learning_rate': 0.00027671159029649594, 'epoch': 1.02}                                                                                                      
{'loss': 2.7969, 'learning_rate': 0.0002763072776280323, 'epoch': 1.04}                                                                                                       
{'loss': 2.7285, 'learning_rate': 0.0002759029649595687, 'epoch': 1.05}                                                                                                       
 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                                    | 800/7620 [1:21:22<6:01:30,  3.18s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 2.617154121398926, 'eval_wer': 1.0, 'eval_cer': 0.9918437800587669, 'eval_runtime': 298.0107, 'eval_samples_per_second': 5.033, 'eval_steps_per_second': 0.631, 'epoch': 1.05}                                                                                                                                                                
{'loss': 2.5757, 'learning_rate': 0.0002754986522911051, 'epoch': 1.06}                                                                                                       
{'loss': 2.4353, 'learning_rate': 0.0002750943396226415, 'epoch': 1.08}                                                                                                       
{'loss': 2.2671, 'learning_rate': 0.0002746900269541779, 'epoch': 1.09}                                                                                                       
{'loss': 1.9853, 'learning_rate': 0.00027428571428571427, 'epoch': 1.1}                                                                                                       
{'loss': 1.8058, 'learning_rate': 0.00027388140161725065, 'epoch': 1.12}                                                                                                      
{'loss': 1.7583, 'learning_rate': 0.000273477088948787, 'epoch': 1.13}                                                                                                        
{'loss': 1.7032, 'learning_rate': 0.0002730727762803234, 'epoch': 1.14}                                                                                                       
{'loss': 1.5475, 'learning_rate': 0.0002726684636118598, 'epoch': 1.15}                                                                                                       
{'loss': 1.4369, 'learning_rate': 0.0002722641509433962, 'epoch': 1.17}                                                                                                       
{'loss': 1.3654, 'learning_rate': 0.0002718598382749326, 'epoch': 1.18}                                                                                                       
 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                  | 900/7620 [1:32:26<5:49:40,  3.12s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 1.0773580074310303, 'eval_wer': 0.9765957446808511, 'eval_cer': 0.34730475801457317, 'eval_runtime': 293.097, 'eval_samples_per_second': 5.118, 'eval_steps_per_second': 0.641, 'epoch': 1.18}                                                                                                                                                
{'loss': 1.2852, 'learning_rate': 0.000271455525606469, 'epoch': 1.19}                                                                                                        
{'loss': 1.2837, 'learning_rate': 0.00027105121293800535, 'epoch': 1.21}                                                                                                      
{'loss': 1.1663, 'learning_rate': 0.0002706469002695418, 'epoch': 1.22}                                                                                                       
{'loss': 1.1222, 'learning_rate': 0.0002702425876010781, 'epoch': 1.23}                                                                                                       
{'loss': 1.1198, 'learning_rate': 0.00026983827493261454, 'epoch': 1.25}                                                                                                      
{'loss': 1.0981, 'learning_rate': 0.0002694339622641509, 'epoch': 1.26}                                                                                                       
{'loss': 1.1493, 'learning_rate': 0.0002690296495956873, 'epoch': 1.27}                                                                                                       
{'loss': 1.0156, 'learning_rate': 0.0002686253369272237, 'epoch': 1.29}                                                                                                       
{'loss': 0.9831, 'learning_rate': 0.0002682210242587601, 'epoch': 1.3}                                                                                                        
{'loss': 0.9542, 'learning_rate': 0.0002678167115902965, 'epoch': 1.31}                                                                                                       
 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                                                | 1000/7620 [1:43:21<5:36:33,  3.05s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.7042989730834961, 'eval_wer': 0.7236702127659574, 'eval_cer': 0.21244383539983924, 'eval_runtime': 294.0911, 'eval_samples_per_second': 5.1, 'eval_steps_per_second': 0.639, 'epoch': 1.31}                                                                                                                                                 
{'loss': 0.9646, 'learning_rate': 0.00026741239892183287, 'epoch': 1.33}                                                                                                      
{'loss': 0.9606, 'learning_rate': 0.00026700808625336925, 'epoch': 1.34}                                                                                                      
{'loss': 0.867, 'learning_rate': 0.00026660377358490563, 'epoch': 1.35}                                                                                                       
{'loss': 0.8329, 'learning_rate': 0.000266199460916442, 'epoch': 1.36}                                                                                                        
{'loss': 0.8895, 'learning_rate': 0.0002657951482479784, 'epoch': 1.38}                                                                                                       
{'loss': 0.7448, 'learning_rate': 0.0002653908355795148, 'epoch': 1.39}                                                                                                       
{'loss': 0.8471, 'learning_rate': 0.0002649865229110512, 'epoch': 1.4}                                                                                                        
{'loss': 0.7862, 'learning_rate': 0.0002645822102425876, 'epoch': 1.42}                                                                                                       
{'loss': 0.7948, 'learning_rate': 0.00026417789757412396, 'epoch': 1.43}                                                                                                      
{'loss': 0.7287, 'learning_rate': 0.0002637735849056604, 'epoch': 1.44}                                                                                                       
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                              | 1100/7620 [1:54:13<5:24:44,  2.99s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.5672255754470825, 'eval_wer': 0.6304521276595745, 'eval_cer': 0.17078650204893733, 'eval_runtime': 292.7914, 'eval_samples_per_second': 5.123, 'eval_steps_per_second': 0.642, 'epoch': 1.44}                                                                                                                                               
{'loss': 0.6916, 'learning_rate': 0.0002633692722371967, 'epoch': 1.46}                                                                                                       
{'loss': 0.7411, 'learning_rate': 0.00026296495956873315, 'epoch': 1.47}                                                                                                      
{'loss': 0.7316, 'learning_rate': 0.0002625606469002695, 'epoch': 1.48}                                                                                                       
{'loss': 0.7283, 'learning_rate': 0.0002621563342318059, 'epoch': 1.5}                                                                                                        
{'loss': 0.7043, 'learning_rate': 0.0002617520215633423, 'epoch': 1.51}                                                                                                       
{'loss': 0.6283, 'learning_rate': 0.00026134770889487866, 'epoch': 1.52}                                                                                                      
{'loss': 0.7532, 'learning_rate': 0.0002609433962264151, 'epoch': 1.54}                                                                                                       
{'loss': 0.7188, 'learning_rate': 0.0002605390835579514, 'epoch': 1.55}                                                                                                       
{'loss': 0.7123, 'learning_rate': 0.00026013477088948785, 'epoch': 1.56}                                                                                                      
{'loss': 0.6638, 'learning_rate': 0.00025973045822102423, 'epoch': 1.57}                                                                                                      
 16%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                            | 1200/7620 [2:05:00<5:22:31,  3.01s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.48897191882133484, 'eval_wer': 0.5682624113475178, 'eval_cer': 0.15401288656397824, 'eval_runtime': 290.1706, 'eval_samples_per_second': 5.169, 'eval_steps_per_second': 0.648, 'epoch': 1.57}                                                                                                                                              
{'loss': 0.5805, 'learning_rate': 0.00025932614555256066, 'epoch': 1.59}                                                                                                      
{'loss': 0.6439, 'learning_rate': 0.000258921832884097, 'epoch': 1.6}                                                                                                         
{'loss': 0.6501, 'learning_rate': 0.0002585175202156334, 'epoch': 1.61}                                                                                                       
{'loss': 0.6062, 'learning_rate': 0.0002581132075471698, 'epoch': 1.63}                                                                                                       
{'loss': 0.6214, 'learning_rate': 0.0002577088948787062, 'epoch': 1.64}                                                                                                       
{'loss': 0.5876, 'learning_rate': 0.00025730458221024256, 'epoch': 1.65}                                                                                                      
{'loss': 0.6391, 'learning_rate': 0.00025690026954177894, 'epoch': 1.67}                                                                                                      
{'loss': 0.6002, 'learning_rate': 0.00025649595687331537, 'epoch': 1.68}                                                                                                      
{'loss': 0.653, 'learning_rate': 0.00025609164420485175, 'epoch': 1.69}                                                                                                       
{'loss': 0.6424, 'learning_rate': 0.0002556873315363881, 'epoch': 1.71}                                                                                                       
 17%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                           | 1300/7620 [2:15:41<5:15:44,  3.00s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.4423101842403412, 'eval_wer': 0.5368351063829787, 'eval_cer': 0.14117244014599503, 'eval_runtime': 299.353, 'eval_samples_per_second': 5.011, 'eval_steps_per_second': 0.628, 'epoch': 1.71}                                                                                                                                                
{'loss': 0.5566, 'learning_rate': 0.0002552830188679245, 'epoch': 1.72}                                                                                                       
{'loss': 0.584, 'learning_rate': 0.0002548787061994609, 'epoch': 1.73}                                                                                                        
{'loss': 0.5582, 'learning_rate': 0.00025447439353099726, 'epoch': 1.75}                                                                                                      
{'loss': 0.5671, 'learning_rate': 0.0002540700808625337, 'epoch': 1.76}                                                                                                       
{'loss': 0.599, 'learning_rate': 0.0002536657681940701, 'epoch': 1.77}                                                                                                        
{'loss': 0.4989, 'learning_rate': 0.00025326145552560645, 'epoch': 1.78}                                                                                                      
{'loss': 0.6252, 'learning_rate': 0.00025285714285714283, 'epoch': 1.8}                                                                                                       
{'loss': 0.5815, 'learning_rate': 0.0002524528301886792, 'epoch': 1.81}                                                                                                       
{'loss': 0.5282, 'learning_rate': 0.0002520485175202156, 'epoch': 1.82}                                                                                                       
{'loss': 0.5519, 'learning_rate': 0.000251644204851752, 'epoch': 1.84}                                                                                                        
 18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                                         | 1400/7620 [2:26:38<5:20:08,  3.09s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.40487614274024963, 'eval_wer': 0.5005762411347517, 'eval_cer': 0.12991316722227347, 'eval_runtime': 298.8554, 'eval_samples_per_second': 5.019, 'eval_steps_per_second': 0.629, 'epoch': 1.84}                                                                                                                                              
{'loss': 0.5156, 'learning_rate': 0.0002512398921832884, 'epoch': 1.85}                                                                                                       
{'loss': 0.5532, 'learning_rate': 0.0002508355795148248, 'epoch': 1.86}                                                                                                       
{'loss': 0.5516, 'learning_rate': 0.00025043126684636116, 'epoch': 1.88}                                                                                                      
{'loss': 0.5966, 'learning_rate': 0.00025002695417789754, 'epoch': 1.89}                                                                                                      
{'loss': 0.5537, 'learning_rate': 0.00024962264150943397, 'epoch': 1.9}                                                                                                       
{'loss': 0.4766, 'learning_rate': 0.0002492183288409703, 'epoch': 1.92}                                                                                                       
{'loss': 0.5733, 'learning_rate': 0.0002488140161725067, 'epoch': 1.93}                                                                                                       
{'loss': 0.564, 'learning_rate': 0.0002484097035040431, 'epoch': 1.94}                                                                                                        
{'loss': 0.5032, 'learning_rate': 0.0002480053908355795, 'epoch': 1.96}                                                                                                       
{'loss': 0.514, 'learning_rate': 0.00024760107816711586, 'epoch': 1.97}                                                                                                       
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                       | 1500/7620 [2:37:42<5:20:51,  3.15s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3929491341114044, 'eval_wer': 0.48271276595744683, 'eval_cer': 0.12853622863768727, 'eval_runtime': 304.6796, 'eval_samples_per_second': 4.923, 'eval_steps_per_second': 0.617, 'epoch': 1.97}                                                                                                                                              
{'loss': 0.4479, 'learning_rate': 0.0002471967654986523, 'epoch': 1.98}                                                                                                       
{'loss': 0.4828, 'learning_rate': 0.0002467924528301887, 'epoch': 1.99}                                                                                                       
 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                       | 1522/7620 [2:43:56<5:35:54,  3.31s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-1522
Configuration saved in russian_spanish_high_augmented/checkpoint-1522/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-1522/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-1522/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.4544, 'learning_rate': 0.00024638814016172505, 'epoch': 2.01}                                                                                                      
{'loss': 0.4453, 'learning_rate': 0.00024598382749326143, 'epoch': 2.02}                                                                                                      
{'loss': 0.4244, 'learning_rate': 0.0002455795148247978, 'epoch': 2.03}                                                                                                       
{'loss': 0.5075, 'learning_rate': 0.0002451752021563342, 'epoch': 2.05}                                                                                                       
{'loss': 0.4376, 'learning_rate': 0.00024477088948787057, 'epoch': 2.06}                                                                                                      
{'loss': 0.4421, 'learning_rate': 0.000244366576819407, 'epoch': 2.07}                                                                                                        
{'loss': 0.4913, 'learning_rate': 0.00024396226415094338, 'epoch': 2.09}                                                                                                      
{'loss': 0.4704, 'learning_rate': 0.00024355795148247976, 'epoch': 2.1}                                                                                                       
 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                                      | 1600/7620 [2:49:17<6:03:17,  3.62s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3681887984275818, 'eval_wer': 0.4604609929078014, 'eval_cer': 0.11571554688838233, 'eval_runtime': 308.5321, 'eval_samples_per_second': 4.862, 'eval_steps_per_second': 0.609, 'epoch': 2.1}                                                                                                                                                
{'loss': 0.426, 'learning_rate': 0.00024315363881401614, 'epoch': 2.11}                                                                                                       
{'loss': 0.4055, 'learning_rate': 0.00024274932614555254, 'epoch': 2.13}                                                                                                      
{'loss': 0.4257, 'learning_rate': 0.00024234501347708892, 'epoch': 2.14}                                                                                                      
{'loss': 0.4586, 'learning_rate': 0.0002419407008086253, 'epoch': 2.15}                                                                                                       
{'loss': 0.3891, 'learning_rate': 0.0002415363881401617, 'epoch': 2.17}                                                                                                       
{'loss': 0.4546, 'learning_rate': 0.0002411320754716981, 'epoch': 2.18}                                                                                                       
{'loss': 0.3607, 'learning_rate': 0.00024072776280323446, 'epoch': 2.19}                                                                                                      
{'loss': 0.3864, 'learning_rate': 0.00024032345013477087, 'epoch': 2.2}                                                                                                       
{'loss': 0.4, 'learning_rate': 0.00023991913746630728, 'epoch': 2.22}                                                                                                         
{'loss': 0.4329, 'learning_rate': 0.00023951482479784363, 'epoch': 2.23}                                                                                                      
 22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                    | 1700/7620 [3:00:27<5:58:30,  3.63s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.35502538084983826, 'eval_wer': 0.4481826241134752, 'eval_cer': 0.11812683646713136, 'eval_runtime': 344.841, 'eval_samples_per_second': 4.35, 'eval_steps_per_second': 0.545, 'epoch': 2.23}                                                                                                                                                
{'loss': 0.3811, 'learning_rate': 0.00023911051212938003, 'epoch': 2.24}                                                                                                      
{'loss': 0.4024, 'learning_rate': 0.0002387061994609164, 'epoch': 2.26}                                                                                                       
{'loss': 0.4216, 'learning_rate': 0.00023830188679245282, 'epoch': 2.27}                                                                                                      
{'loss': 0.429, 'learning_rate': 0.0002378975741239892, 'epoch': 2.28}                                                                                                        
{'loss': 0.3976, 'learning_rate': 0.00023749326145552558, 'epoch': 2.3}                                                                                                       
{'loss': 0.4888, 'learning_rate': 0.00023708894878706198, 'epoch': 2.31}                                                                                                      
{'loss': 0.3508, 'learning_rate': 0.00023668463611859836, 'epoch': 2.32}                                                                                                      
{'loss': 0.374, 'learning_rate': 0.00023628032345013474, 'epoch': 2.34}                                                                                                       
{'loss': 0.3683, 'learning_rate': 0.00023587601078167115, 'epoch': 2.35}                                                                                                      
{'loss': 0.4224, 'learning_rate': 0.00023547169811320755, 'epoch': 2.36}                                                                                                      
 24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 1800/7620 [3:12:41<6:23:24,  3.95s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.35093891620635986, 'eval_wer': 0.4340425531914894, 'eval_cer': 0.11389719736998143, 'eval_runtime': 323.761, 'eval_samples_per_second': 4.633, 'eval_steps_per_second': 0.581, 'epoch': 2.36}                                                                                                                                               
{'loss': 0.4017, 'learning_rate': 0.0002350673854447439, 'epoch': 2.38}                                                                                                       
{'loss': 0.3418, 'learning_rate': 0.0002346630727762803, 'epoch': 2.39}                                                                                                       
{'loss': 0.3635, 'learning_rate': 0.00023425876010781671, 'epoch': 2.4}                                                                                                       
{'loss': 0.4038, 'learning_rate': 0.00023385444743935307, 'epoch': 2.41}                                                                                                      
{'loss': 0.3295, 'learning_rate': 0.00023345013477088947, 'epoch': 2.43}                                                                                                      
{'loss': 0.3818, 'learning_rate': 0.00023304582210242585, 'epoch': 2.44}                                                                                                      
{'loss': 0.355, 'learning_rate': 0.00023264150943396226, 'epoch': 2.45}                                                                                                       
{'loss': 0.3867, 'learning_rate': 0.00023223719676549864, 'epoch': 2.47}                                                                                                      
{'loss': 0.3847, 'learning_rate': 0.00023183288409703501, 'epoch': 2.48}                                                                                                      
{'loss': 0.369, 'learning_rate': 0.00023142857142857142, 'epoch': 2.49}                                                                                                       
 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                | 1900/7620 [3:24:35<6:07:16,  3.85s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3394348919391632, 'eval_wer': 0.42477836879432623, 'eval_cer': 0.10782285586285956, 'eval_runtime': 304.3629, 'eval_samples_per_second': 4.928, 'eval_steps_per_second': 0.618, 'epoch': 2.49}                                                                                                                                              
{'loss': 0.4115, 'learning_rate': 0.00023102425876010777, 'epoch': 2.51}                                                                                                      
{'loss': 0.316, 'learning_rate': 0.00023061994609164418, 'epoch': 2.52}                                                                                                       
{'loss': 0.3569, 'learning_rate': 0.00023021563342318058, 'epoch': 2.53}                                                                                                      
{'loss': 0.3989, 'learning_rate': 0.000229811320754717, 'epoch': 2.55}                                                                                                        
{'loss': 0.391, 'learning_rate': 0.00022940700808625334, 'epoch': 2.56}                                                                                                       
{'loss': 0.3951, 'learning_rate': 0.00022900269541778975, 'epoch': 2.57}                                                                                                      
{'loss': 0.3397, 'learning_rate': 0.00022859838274932613, 'epoch': 2.59}                                                                                                      
{'loss': 0.3744, 'learning_rate': 0.0002281940700808625, 'epoch': 2.6}                                                                                                        
{'loss': 0.3729, 'learning_rate': 0.0002277897574123989, 'epoch': 2.61}                                                                                                       
{'loss': 0.3939, 'learning_rate': 0.0002273854447439353, 'epoch': 2.62}                                                                                                       
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                               | 2000/7620 [3:35:56<5:51:13,  3.75s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3317593038082123, 'eval_wer': 0.41906028368794324, 'eval_cer': 0.10697956333258667, 'eval_runtime': 311.6745, 'eval_samples_per_second': 4.813, 'eval_steps_per_second': 0.603, 'epoch': 2.62}                                                                                                                                              
{'loss': 0.3864, 'learning_rate': 0.0002269811320754717, 'epoch': 2.64}                                                                                                       
{'loss': 0.3006, 'learning_rate': 0.00022657681940700805, 'epoch': 2.65}                                                                                                      
{'loss': 0.3864, 'learning_rate': 0.00022617250673854445, 'epoch': 2.66}                                                                                                      
{'loss': 0.3963, 'learning_rate': 0.00022576819407008086, 'epoch': 2.68}                                                                                                      
{'loss': 0.3374, 'learning_rate': 0.0002253638814016172, 'epoch': 2.69}                                                                                                       
{'loss': 0.404, 'learning_rate': 0.00022495956873315362, 'epoch': 2.7}                                                                                                        
{'loss': 0.4127, 'learning_rate': 0.00022455525606469002, 'epoch': 2.72}                                                                                                      
{'loss': 0.3486, 'learning_rate': 0.00022415094339622637, 'epoch': 2.73}                                                                                                      
{'loss': 0.355, 'learning_rate': 0.00022374663072776278, 'epoch': 2.74}                                                                                                       
{'loss': 0.32, 'learning_rate': 0.00022334231805929918, 'epoch': 2.76}                                                                                                        
 28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                             | 2100/7620 [3:47:11<5:30:52,  3.60s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3371075391769409, 'eval_wer': 0.39831560283687945, 'eval_cer': 0.10121486830142437, 'eval_runtime': 303.7345, 'eval_samples_per_second': 4.939, 'eval_steps_per_second': 0.619, 'epoch': 2.76}                                                                                                                                              
{'loss': 0.3429, 'learning_rate': 0.00022293800539083556, 'epoch': 2.77}                                                                                                      
{'loss': 0.3026, 'learning_rate': 0.00022253369272237194, 'epoch': 2.78}                                                                                                      
{'loss': 0.3508, 'learning_rate': 0.00022212938005390835, 'epoch': 2.8}                                                                                                       
{'loss': 0.3821, 'learning_rate': 0.00022172506738544473, 'epoch': 2.81}                                                                                                      
{'loss': 0.363, 'learning_rate': 0.0002213207547169811, 'epoch': 2.82}                                                                                                        
{'loss': 0.349, 'learning_rate': 0.00022091644204851748, 'epoch': 2.83}                                                                                                       
{'loss': 0.3079, 'learning_rate': 0.0002205121293800539, 'epoch': 2.85}                                                                                                       
{'loss': 0.3727, 'learning_rate': 0.0002201078167115903, 'epoch': 2.86}                                                                                                       
{'loss': 0.3885, 'learning_rate': 0.00021970350404312665, 'epoch': 2.87}                                                                                                      
{'loss': 0.3406, 'learning_rate': 0.00021929919137466305, 'epoch': 2.89}                                                                                                      
 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                           | 2200/7620 [3:58:11<5:20:49,  3.55s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3099915683269501, 'eval_wer': 0.4088209219858156, 'eval_cer': 0.1054774485130381, 'eval_runtime': 296.617, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 0.634, 'epoch': 2.89}                                                                                                                                                 
{'loss': 0.3693, 'learning_rate': 0.00021889487870619946, 'epoch': 2.9}                                                                                                       
{'loss': 0.3362, 'learning_rate': 0.0002184905660377358, 'epoch': 2.91}                                                                                                       
{'loss': 0.3022, 'learning_rate': 0.00021808625336927222, 'epoch': 2.93}                                                                                                      
{'loss': 0.3553, 'learning_rate': 0.00021768194070080862, 'epoch': 2.94}                                                                                                      
{'loss': 0.3844, 'learning_rate': 0.000217277628032345, 'epoch': 2.95}                                                                                                        
{'loss': 0.369, 'learning_rate': 0.00021687331536388138, 'epoch': 2.97}                                                                                                       
{'loss': 0.2594, 'learning_rate': 0.00021646900269541776, 'epoch': 2.98}                                                                                                      
{'loss': 0.3448, 'learning_rate': 0.00021606469002695416, 'epoch': 2.99}                                                                                                      
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                          | 2283/7620 [4:07:51<4:45:29,  3.21s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-2283
Configuration saved in russian_spanish_high_augmented/checkpoint-2283/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-2283/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-2283/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.3264, 'learning_rate': 0.00021566037735849054, 'epoch': 3.01}                                                                                                      
{'loss': 0.288, 'learning_rate': 0.00021525606469002692, 'epoch': 3.02}                                                                                                       
 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                                          | 2300/7620 [4:09:20<6:29:56,  4.40s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3173327147960663, 'eval_wer': 0.3906914893617021, 'eval_cer': 0.10383698101274162, 'eval_runtime': 297.2843, 'eval_samples_per_second': 5.046, 'eval_steps_per_second': 0.632, 'epoch': 3.02}                                                                                                                                               
{'loss': 0.3243, 'learning_rate': 0.00021485175202156333, 'epoch': 3.03}                                                                                                      
{'loss': 0.3252, 'learning_rate': 0.00021444743935309973, 'epoch': 3.04}                                                                                                      
{'loss': 0.2695, 'learning_rate': 0.00021404312668463609, 'epoch': 3.06}                                                                                                      
{'loss': 0.2382, 'learning_rate': 0.0002136388140161725, 'epoch': 3.07}                                                                                                       
{'loss': 0.3339, 'learning_rate': 0.0002132345013477089, 'epoch': 3.08}                                                                                                       
{'loss': 0.2692, 'learning_rate': 0.00021283018867924525, 'epoch': 3.1}                                                                                                       
{'loss': 0.3241, 'learning_rate': 0.00021242587601078165, 'epoch': 3.11}                                                                                                      
{'loss': 0.2552, 'learning_rate': 0.00021202156334231803, 'epoch': 3.12}                                                                                                      
{'loss': 0.2584, 'learning_rate': 0.00021161725067385444, 'epoch': 3.14}                                                                                                      
{'loss': 0.3018, 'learning_rate': 0.00021121293800539082, 'epoch': 3.15}                                                                                                      
 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                        | 2400/7620 [4:20:10<6:00:45,  4.15s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.30381739139556885, 'eval_wer': 0.39667553191489363, 'eval_cer': 0.10136639742795778, 'eval_runtime': 308.8739, 'eval_samples_per_second': 4.856, 'eval_steps_per_second': 0.609, 'epoch': 3.15}                                                                                                                                             
{'loss': 0.3192, 'learning_rate': 0.0002108086253369272, 'epoch': 3.16}                                                                                                       
{'loss': 0.292, 'learning_rate': 0.0002104043126684636, 'epoch': 3.18}                                                                                                        
{'loss': 0.2441, 'learning_rate': 0.00020999999999999998, 'epoch': 3.19}                                                                                                      
{'loss': 0.2315, 'learning_rate': 0.00020959568733153636, 'epoch': 3.2}                                                                                                       
{'loss': 0.276, 'learning_rate': 0.00020919137466307277, 'epoch': 3.22}                                                                                                       
{'loss': 0.2401, 'learning_rate': 0.00020878706199460917, 'epoch': 3.23}                                                                                                      
{'loss': 0.2643, 'learning_rate': 0.00020838274932614552, 'epoch': 3.24}                                                                                                      
{'loss': 0.305, 'learning_rate': 0.00020797843665768193, 'epoch': 3.25}                                                                                                       
{'loss': 0.2251, 'learning_rate': 0.0002075741239892183, 'epoch': 3.27}                                                                                                       
{'loss': 0.303, 'learning_rate': 0.0002071698113207547, 'epoch': 3.28}                                                                                                        
 33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                      | 2500/7620 [4:31:25<5:53:52,  4.15s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.300982266664505, 'eval_wer': 0.3834663120567376, 'eval_cer': 0.0979536979695097, 'eval_runtime': 289.2306, 'eval_samples_per_second': 5.186, 'eval_steps_per_second': 0.65, 'epoch': 3.28}                                                                                                                                                  
{'loss': 0.2699, 'learning_rate': 0.0002067654986522911, 'epoch': 3.29}                                                                                                       
{'loss': 0.3062, 'learning_rate': 0.00020636118598382747, 'epoch': 3.31}                                                                                                      
{'loss': 0.288, 'learning_rate': 0.00020595687331536388, 'epoch': 3.32}                                                                                                       
{'loss': 0.2375, 'learning_rate': 0.00020555256064690026, 'epoch': 3.33}                                                                                                      
{'loss': 0.3031, 'learning_rate': 0.00020514824797843664, 'epoch': 3.35}                                                                                                      
{'loss': 0.2753, 'learning_rate': 0.00020474393530997304, 'epoch': 3.36}                                                                                                      
{'loss': 0.3306, 'learning_rate': 0.0002043396226415094, 'epoch': 3.37}                                                                                                       
{'loss': 0.271, 'learning_rate': 0.0002039353099730458, 'epoch': 3.39}                                                                                                        
{'loss': 0.2247, 'learning_rate': 0.0002035309973045822, 'epoch': 3.4}                                                                                                        
{'loss': 0.29, 'learning_rate': 0.00020312668463611856, 'epoch': 3.41}                                                                                                        
 34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                     | 2600/7620 [4:42:18<5:54:16,  4.23s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2977805435657501, 'eval_wer': 0.3769503546099291, 'eval_cer': 0.0966689945054221, 'eval_runtime': 295.044, 'eval_samples_per_second': 5.084, 'eval_steps_per_second': 0.637, 'epoch': 3.41}                                                                                                                                                 
{'loss': 0.2503, 'learning_rate': 0.00020272237196765496, 'epoch': 3.43}                                                                                                      
{'loss': 0.2835, 'learning_rate': 0.00020231805929919137, 'epoch': 3.44}                                                                                                      
{'loss': 0.2234, 'learning_rate': 0.00020191374663072775, 'epoch': 3.45}                                                                                                      
{'loss': 0.24, 'learning_rate': 0.00020150943396226413, 'epoch': 3.46}                                                                                                        
{'loss': 0.2757, 'learning_rate': 0.00020110512129380053, 'epoch': 3.48}                                                                                                      
{'loss': 0.2974, 'learning_rate': 0.0002007008086253369, 'epoch': 3.49}                                                                                                       
{'loss': 0.2919, 'learning_rate': 0.0002002964959568733, 'epoch': 3.5}                                                                                                        
{'loss': 0.2418, 'learning_rate': 0.00019989218328840967, 'epoch': 3.52}                                                                                                      
{'loss': 0.2258, 'learning_rate': 0.00019948787061994607, 'epoch': 3.53}                                                                                                      
{'loss': 0.2548, 'learning_rate': 0.00019908355795148248, 'epoch': 3.54}                                                                                                      
 35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                                   | 2700/7620 [4:53:20<6:00:51,  4.40s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.29869577288627625, 'eval_wer': 0.3725177304964539, 'eval_cer': 0.09609581911375226, 'eval_runtime': 289.2404, 'eval_samples_per_second': 5.186, 'eval_steps_per_second': 0.65, 'epoch': 3.54}                                                                                                                                               
{'loss': 0.3002, 'learning_rate': 0.00019867924528301883, 'epoch': 3.56}                                                                                                      
{'loss': 0.2581, 'learning_rate': 0.00019827493261455524, 'epoch': 3.57}                                                                                                      
{'loss': 0.2919, 'learning_rate': 0.00019787061994609164, 'epoch': 3.58}                                                                                                      
{'loss': 0.203, 'learning_rate': 0.000197466307277628, 'epoch': 3.6}                                                                                                          
{'loss': 0.2897, 'learning_rate': 0.0001970619946091644, 'epoch': 3.61}                                                                                                       
{'loss': 0.2642, 'learning_rate': 0.0001966576819407008, 'epoch': 3.62}                                                                                                       
{'loss': 0.2628, 'learning_rate': 0.00019625336927223718, 'epoch': 3.64}                                                                                                      
{'loss': 0.2376, 'learning_rate': 0.00019584905660377356, 'epoch': 3.65}                                                                                                      
{'loss': 0.2627, 'learning_rate': 0.00019544474393530994, 'epoch': 3.66}                                                                                                      
{'loss': 0.2658, 'learning_rate': 0.00019504043126684635, 'epoch': 3.67}                                                                                                      
 37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                 | 2800/7620 [5:04:00<5:30:49,  4.12s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2896752953529358, 'eval_wer': 0.368218085106383, 'eval_cer': 0.09479135098098639, 'eval_runtime': 280.4552, 'eval_samples_per_second': 5.348, 'eval_steps_per_second': 0.67, 'epoch': 3.67}                                                                                                                                                 
{'loss': 0.268, 'learning_rate': 0.00019463611859838273, 'epoch': 3.69}                                                                                                       
{'loss': 0.2701, 'learning_rate': 0.0001942318059299191, 'epoch': 3.7}                                                                                                        
{'loss': 0.2595, 'learning_rate': 0.0001938274932614555, 'epoch': 3.71}                                                                                                       
{'loss': 0.2337, 'learning_rate': 0.00019342318059299192, 'epoch': 3.73}                                                                                                      
{'loss': 0.2407, 'learning_rate': 0.00019301886792452827, 'epoch': 3.74}                                                                                                      
{'loss': 0.2603, 'learning_rate': 0.00019261455525606467, 'epoch': 3.75}                                                                                                      
{'loss': 0.2489, 'learning_rate': 0.00019221024258760108, 'epoch': 3.77}                                                                                                      
{'loss': 0.2224, 'learning_rate': 0.00019180592991913743, 'epoch': 3.78}                                                                                                      
{'loss': 0.2403, 'learning_rate': 0.00019140161725067384, 'epoch': 3.79}                                                                                                      
{'loss': 0.2535, 'learning_rate': 0.00019099730458221024, 'epoch': 3.81}                                                                                                      
 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                                                | 2900/7620 [5:14:25<5:22:41,  4.10s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3025922477245331, 'eval_wer': 0.36861702127659574, 'eval_cer': 0.09389535266757144, 'eval_runtime': 287.3422, 'eval_samples_per_second': 5.22, 'eval_steps_per_second': 0.654, 'epoch': 3.81}                                                                                                                                               
{'loss': 0.2835, 'learning_rate': 0.00019059299191374662, 'epoch': 3.82}                                                                                                      
{'loss': 0.2706, 'learning_rate': 0.000190188679245283, 'epoch': 3.83}                                                                                                        
{'loss': 0.2138, 'learning_rate': 0.00018978436657681938, 'epoch': 3.85}                                                                                                      
{'loss': 0.2461, 'learning_rate': 0.00018938005390835579, 'epoch': 3.86}                                                                                                      
{'loss': 0.2385, 'learning_rate': 0.00018897574123989216, 'epoch': 3.87}                                                                                                      
{'loss': 0.2954, 'learning_rate': 0.00018857142857142854, 'epoch': 3.88}                                                                                                      
{'loss': 0.236, 'learning_rate': 0.00018816711590296495, 'epoch': 3.9}                                                                                                        
{'loss': 0.236, 'learning_rate': 0.00018776280323450136, 'epoch': 3.91}                                                                                                       
{'loss': 0.2934, 'learning_rate': 0.0001873584905660377, 'epoch': 3.92}                                                                                                       
{'loss': 0.2676, 'learning_rate': 0.0001869541778975741, 'epoch': 3.94}                                                                                                       
 39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                              | 3000/7620 [5:25:07<5:25:43,  4.23s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28148123621940613, 'eval_wer': 0.3588209219858156, 'eval_cer': 0.09209017959495605, 'eval_runtime': 290.4407, 'eval_samples_per_second': 5.165, 'eval_steps_per_second': 0.647, 'epoch': 3.94}                                                                                                                                              
{'loss': 0.2488, 'learning_rate': 0.00018654986522911052, 'epoch': 3.95}                                                                                                      
{'loss': 0.2308, 'learning_rate': 0.00018614555256064687, 'epoch': 3.96}                                                                                                      
{'loss': 0.2503, 'learning_rate': 0.00018574123989218328, 'epoch': 3.98}                                                                                                      
{'loss': 0.2797, 'learning_rate': 0.00018533692722371965, 'epoch': 3.99}                                                                                                      
 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                             | 3044/7620 [5:32:17<4:22:02,  3.44s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-3044
Configuration saved in russian_spanish_high_augmented/checkpoint-3044/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-3044/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-3044/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2175, 'learning_rate': 0.00018493261455525606, 'epoch': 4.0}                                                                                                       
{'loss': 0.2337, 'learning_rate': 0.00018452830188679244, 'epoch': 4.02}                                                                                                      
{'loss': 0.2231, 'learning_rate': 0.00018412398921832882, 'epoch': 4.03}                                                                                                      
{'loss': 0.2063, 'learning_rate': 0.00018371967654986522, 'epoch': 4.04}                                                                                                      
{'loss': 0.1946, 'learning_rate': 0.0001833153638814016, 'epoch': 4.06}                                                                                                       
{'loss': 0.2037, 'learning_rate': 0.00018291105121293798, 'epoch': 4.07}                                                                                                      
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                            | 3100/7620 [5:35:50<5:02:08,  4.01s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2994278073310852, 'eval_wer': 0.36781914893617024, 'eval_cer': 0.0937504117639308, 'eval_runtime': 290.6519, 'eval_samples_per_second': 5.161, 'eval_steps_per_second': 0.647, 'epoch': 4.07}                                                                                                                                               
{'loss': 0.24, 'learning_rate': 0.0001825067385444744, 'epoch': 4.08}                                                                                                         
{'loss': 0.2551, 'learning_rate': 0.00018210242587601074, 'epoch': 4.09}                                                                                                      
{'loss': 0.2106, 'learning_rate': 0.00018169811320754714, 'epoch': 4.11}                                                                                                      
{'loss': 0.2011, 'learning_rate': 0.00018129380053908355, 'epoch': 4.12}                                                                                                      
{'loss': 0.1795, 'learning_rate': 0.00018088948787061993, 'epoch': 4.13}                                                                                                      
{'loss': 0.2118, 'learning_rate': 0.0001804851752021563, 'epoch': 4.15}                                                                                                       
{'loss': 0.2474, 'learning_rate': 0.00018008086253369271, 'epoch': 4.16}                                                                                                      
{'loss': 0.2345, 'learning_rate': 0.0001796765498652291, 'epoch': 4.17}                                                                                                       
{'loss': 0.2206, 'learning_rate': 0.00017927223719676547, 'epoch': 4.19}                                                                                                      
{'loss': 0.1454, 'learning_rate': 0.00017886792452830188, 'epoch': 4.2}                                                                                                       
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                          | 3200/7620 [5:46:41<5:05:06,  4.14s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.29689887166023254, 'eval_wer': 0.36812943262411346, 'eval_cer': 0.09510099745694596, 'eval_runtime': 308.7731, 'eval_samples_per_second': 4.858, 'eval_steps_per_second': 0.609, 'epoch': 4.2}                                                                                                                                              
{'loss': 0.2441, 'learning_rate': 0.00017846361185983826, 'epoch': 4.21}                                                                                                      
{'loss': 0.234, 'learning_rate': 0.00017805929919137466, 'epoch': 4.23}                                                                                                       
{'loss': 0.2404, 'learning_rate': 0.000177654986522911, 'epoch': 4.24}                                                                                                        
{'loss': 0.226, 'learning_rate': 0.00017725067385444742, 'epoch': 4.25}                                                                                                       
{'loss': 0.2059, 'learning_rate': 0.00017684636118598383, 'epoch': 4.27}                                                                                                      
{'loss': 0.2115, 'learning_rate': 0.00017644204851752018, 'epoch': 4.28}                                                                                                      
{'loss': 0.2185, 'learning_rate': 0.00017603773584905658, 'epoch': 4.29}                                                                                                      
{'loss': 0.2047, 'learning_rate': 0.000175633423180593, 'epoch': 4.3}                                                                                                         
{'loss': 0.2162, 'learning_rate': 0.00017522911051212937, 'epoch': 4.32}                                                                                                      
{'loss': 0.224, 'learning_rate': 0.00017482479784366575, 'epoch': 4.33}                                                                                                       
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                         | 3300/7620 [5:58:01<4:57:20,  4.13s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3081839680671692, 'eval_wer': 0.3670212765957447, 'eval_cer': 0.09481770387255742, 'eval_runtime': 298.792, 'eval_samples_per_second': 5.02, 'eval_steps_per_second': 0.629, 'epoch': 4.33}                                                                                                                                                 
{'loss': 0.273, 'learning_rate': 0.00017442048517520215, 'epoch': 4.34}                                                                                                       
{'loss': 0.2315, 'learning_rate': 0.00017401617250673853, 'epoch': 4.36}                                                                                                      
{'loss': 0.1971, 'learning_rate': 0.0001736118598382749, 'epoch': 4.37}                                                                                                       
{'loss': 0.1959, 'learning_rate': 0.0001732075471698113, 'epoch': 4.38}                                                                                                       
{'loss': 0.1743, 'learning_rate': 0.0001728032345013477, 'epoch': 4.4}                                                                                                        
{'loss': 0.216, 'learning_rate': 0.0001723989218328841, 'epoch': 4.41}                                                                                                        
{'loss': 0.2269, 'learning_rate': 0.00017199460916442045, 'epoch': 4.42}                                                                                                      
{'loss': 0.2685, 'learning_rate': 0.00017159029649595686, 'epoch': 4.44}                                                                                                      
{'loss': 0.1678, 'learning_rate': 0.00017118598382749326, 'epoch': 4.45}                                                                                                      
{'loss': 0.1803, 'learning_rate': 0.00017078167115902961, 'epoch': 4.46}                                                                                                      
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                       | 3400/7620 [6:09:01<4:56:12,  4.21s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3009585738182068, 'eval_wer': 0.3636968085106383, 'eval_cer': 0.09134571040807453, 'eval_runtime': 296.7595, 'eval_samples_per_second': 5.055, 'eval_steps_per_second': 0.634, 'epoch': 4.46}                                                                                                                                               
{'loss': 0.2241, 'learning_rate': 0.00017037735849056602, 'epoch': 4.48}                                                                                                      
{'loss': 0.2327, 'learning_rate': 0.00016997304582210243, 'epoch': 4.49}                                                                                                      
{'loss': 0.2186, 'learning_rate': 0.0001695687331536388, 'epoch': 4.5}                                                                                                        
{'loss': 0.1996, 'learning_rate': 0.00016916442048517518, 'epoch': 4.51}                                                                                                      
{'loss': 0.1587, 'learning_rate': 0.00016876010781671156, 'epoch': 4.53}                                                                                                      
{'loss': 0.2306, 'learning_rate': 0.00016835579514824797, 'epoch': 4.54}                                                                                                      
{'loss': 0.189, 'learning_rate': 0.00016795148247978435, 'epoch': 4.55}                                                                                                       
{'loss': 0.1935, 'learning_rate': 0.00016754716981132073, 'epoch': 4.57}                                                                                                      
{'loss': 0.2485, 'learning_rate': 0.00016714285714285713, 'epoch': 4.58}                                                                                                      
{'loss': 0.1469, 'learning_rate': 0.00016673854447439354, 'epoch': 4.59}                                                                                                      
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                     | 3500/7620 [6:19:56<4:33:16,  3.98s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2879522740840912, 'eval_wer': 0.35757978723404255, 'eval_cer': 0.0893758317631402, 'eval_runtime': 282.7464, 'eval_samples_per_second': 5.305, 'eval_steps_per_second': 0.665, 'epoch': 4.59}                                                                                                                                               
{'loss': 0.2067, 'learning_rate': 0.0001663342318059299, 'epoch': 4.61}                                                                                                       
{'loss': 0.179, 'learning_rate': 0.0001659299191374663, 'epoch': 4.62}                                                                                                        
{'loss': 0.2181, 'learning_rate': 0.0001655256064690027, 'epoch': 4.63}                                                                                                       
{'loss': 0.1873, 'learning_rate': 0.00016512129380053905, 'epoch': 4.65}                                                                                                      
{'loss': 0.1848, 'learning_rate': 0.00016471698113207546, 'epoch': 4.66}                                                                                                      
{'loss': 0.2144, 'learning_rate': 0.00016431266846361186, 'epoch': 4.67}                                                                                                      
{'loss': 0.2064, 'learning_rate': 0.00016390835579514824, 'epoch': 4.69}                                                                                                      
{'loss': 0.22, 'learning_rate': 0.00016350404312668462, 'epoch': 4.7}                                                                                                         
{'loss': 0.1549, 'learning_rate': 0.000163099730458221, 'epoch': 4.71}                                                                                                        
{'loss': 0.2436, 'learning_rate': 0.0001626954177897574, 'epoch': 4.72}                                                                                                       
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                    | 3600/7620 [6:30:25<4:21:30,  3.90s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2921854555606842, 'eval_wer': 0.3500886524822695, 'eval_cer': 0.09102288748632943, 'eval_runtime': 284.7768, 'eval_samples_per_second': 5.267, 'eval_steps_per_second': 0.66, 'epoch': 4.72}                                                                                                                                                
{'loss': 0.2022, 'learning_rate': 0.00016229110512129379, 'epoch': 4.74}                                                                                                      
{'loss': 0.2131, 'learning_rate': 0.00016188679245283016, 'epoch': 4.75}                                                                                                      
{'loss': 0.1982, 'learning_rate': 0.00016148247978436657, 'epoch': 4.76}                                                                                                      
{'loss': 0.1882, 'learning_rate': 0.00016107816711590298, 'epoch': 4.78}                                                                                                      
{'loss': 0.187, 'learning_rate': 0.00016067385444743933, 'epoch': 4.79}                                                                                                       
{'loss': 0.2212, 'learning_rate': 0.00016026954177897573, 'epoch': 4.8}                                                                                                       
{'loss': 0.243, 'learning_rate': 0.00015986522911051214, 'epoch': 4.82}                                                                                                       
{'loss': 0.2101, 'learning_rate': 0.0001594609164420485, 'epoch': 4.83}                                                                                                       
{'loss': 0.192, 'learning_rate': 0.0001590566037735849, 'epoch': 4.84}                                                                                                        
{'loss': 0.1894, 'learning_rate': 0.00015865229110512128, 'epoch': 4.86}                                                                                                      
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                                  | 3700/7620 [6:40:59<4:26:45,  4.08s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2857849895954132, 'eval_wer': 0.35713652482269503, 'eval_cer': 0.08986336025720422, 'eval_runtime': 286.7954, 'eval_samples_per_second': 5.23, 'eval_steps_per_second': 0.656, 'epoch': 4.86}                                                                                                                                               
{'loss': 0.1892, 'learning_rate': 0.00015824797843665765, 'epoch': 4.87}                                                                                                      
{'loss': 0.2109, 'learning_rate': 0.00015784366576819406, 'epoch': 4.88}                                                                                                      
{'loss': 0.2484, 'learning_rate': 0.00015743935309973044, 'epoch': 4.9}                                                                                                       
{'loss': 0.1875, 'learning_rate': 0.00015703504043126684, 'epoch': 4.91}                                                                                                      
{'loss': 0.1874, 'learning_rate': 0.0001566307277628032, 'epoch': 4.92}                                                                                                       
{'loss': 0.2281, 'learning_rate': 0.0001562264150943396, 'epoch': 4.93}                                                                                                       
{'loss': 0.2068, 'learning_rate': 0.000155822102425876, 'epoch': 4.95}                                                                                                        
{'loss': 0.2012, 'learning_rate': 0.00015541778975741236, 'epoch': 4.96}                                                                                                      
{'loss': 0.2194, 'learning_rate': 0.00015501347708894877, 'epoch': 4.97}                                                                                                      
{'loss': 0.153, 'learning_rate': 0.00015460916442048517, 'epoch': 4.99}                                                                                                       
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                | 3800/7620 [6:51:48<3:59:43,  3.77s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28598153591156006, 'eval_wer': 0.3442375886524823, 'eval_cer': 0.08611466143122554, 'eval_runtime': 292.4376, 'eval_samples_per_second': 5.129, 'eval_steps_per_second': 0.643, 'epoch': 4.99}                                                                                                                                              
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                                | 3805/7620 [6:56:59<26:00:43, 24.55s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-3805                                                                                                     
Configuration saved in russian_spanish_high_augmented/checkpoint-3805/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-3805/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-3805/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.2721, 'learning_rate': 0.00015420485175202155, 'epoch': 5.0}                                                                                                       
{'loss': 0.2163, 'learning_rate': 0.00015380053908355793, 'epoch': 5.01}                                                                                                      
{'loss': 0.1555, 'learning_rate': 0.00015339622641509433, 'epoch': 5.03}                                                                                                      
{'loss': 0.2062, 'learning_rate': 0.00015299191374663071, 'epoch': 5.04}                                                                                                      
{'loss': 0.1577, 'learning_rate': 0.0001525876010781671, 'epoch': 5.05}                                                                                                       
{'loss': 0.1407, 'learning_rate': 0.0001521832884097035, 'epoch': 5.07}                                                                                                       
{'loss': 0.1915, 'learning_rate': 0.00015177897574123988, 'epoch': 5.08}                                                                                                      
{'loss': 0.1796, 'learning_rate': 0.00015137466307277628, 'epoch': 5.09}                                                                                                      
{'loss': 0.1971, 'learning_rate': 0.00015097035040431263, 'epoch': 5.1}                                                                                                       
{'loss': 0.1642, 'learning_rate': 0.00015056603773584904, 'epoch': 5.12}                                                                                                      
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                               | 3900/7620 [7:03:10<3:20:50,  3.24s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.3054051399230957, 'eval_wer': 0.34698581560283687, 'eval_cer': 0.08961300778727946, 'eval_runtime': 304.854, 'eval_samples_per_second': 4.92, 'eval_steps_per_second': 0.617, 'epoch': 5.12}                                                                                                                                                
{'loss': 0.1453, 'learning_rate': 0.00015016172506738545, 'epoch': 5.13}                                                                                                      
{'loss': 0.2217, 'learning_rate': 0.00014975741239892182, 'epoch': 5.14}                                                                                                      
{'loss': 0.1787, 'learning_rate': 0.0001493530997304582, 'epoch': 5.16}                                                                                                       
{'loss': 0.1969, 'learning_rate': 0.0001489487870619946, 'epoch': 5.17}                                                                                                       
{'loss': 0.1794, 'learning_rate': 0.000148544474393531, 'epoch': 5.18}                                                                                                        
{'loss': 0.1096, 'learning_rate': 0.00014814016172506737, 'epoch': 5.2}                                                                                                       
{'loss': 0.186, 'learning_rate': 0.00014773584905660377, 'epoch': 5.21}                                                                                                       
{'loss': 0.1628, 'learning_rate': 0.00014733153638814015, 'epoch': 5.22}                                                                                                      
{'loss': 0.1566, 'learning_rate': 0.00014692722371967653, 'epoch': 5.24}                                                                                                      
{'loss': 0.1585, 'learning_rate': 0.0001465229110512129, 'epoch': 5.25}                                                                                                       
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                             | 4000/7620 [7:14:24<3:00:57,  3.00s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.30110302567481995, 'eval_wer': 0.3351507092198582, 'eval_cer': 0.08610148498544003, 'eval_runtime': 285.4815, 'eval_samples_per_second': 5.254, 'eval_steps_per_second': 0.659, 'epoch': 5.25}                                                                                                                                              
{'loss': 0.143, 'learning_rate': 0.00014611859838274932, 'epoch': 5.26}                                                                                                       
{'loss': 0.1754, 'learning_rate': 0.0001457142857142857, 'epoch': 5.28}                                                                                                       
{'loss': 0.2044, 'learning_rate': 0.0001453099730458221, 'epoch': 5.29}                                                                                                       
{'loss': 0.1642, 'learning_rate': 0.00014490566037735848, 'epoch': 5.3}                                                                                                       
{'loss': 0.1501, 'learning_rate': 0.00014450134770889486, 'epoch': 5.31}                                                                                                      
{'loss': 0.1697, 'learning_rate': 0.00014409703504043126, 'epoch': 5.33}                                                                                                      
{'loss': 0.1964, 'learning_rate': 0.00014369272237196764, 'epoch': 5.34}                                                                                                      
{'loss': 0.1896, 'learning_rate': 0.00014328840970350405, 'epoch': 5.35}                                                                                                      
{'loss': 0.1467, 'learning_rate': 0.00014288409703504043, 'epoch': 5.37}                                                                                                      
{'loss': 0.1879, 'learning_rate': 0.0001424797843665768, 'epoch': 5.38}                                                                                                       
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                           | 4100/7620 [7:25:19<2:46:51,  2.84s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.30300173163414, 'eval_wer': 0.3368351063829787, 'eval_cer': 0.08616077899147484, 'eval_runtime': 282.2193, 'eval_samples_per_second': 5.315, 'eval_steps_per_second': 0.666, 'epoch': 5.38}                                                                                                                                                 
{'loss': 0.1422, 'learning_rate': 0.00014207547169811318, 'epoch': 5.39}                                                                                                      
{'loss': 0.1775, 'learning_rate': 0.0001416711590296496, 'epoch': 5.41}                                                                                                       
{'loss': 0.1819, 'learning_rate': 0.00014126684636118597, 'epoch': 5.42}                                                                                                      
{'loss': 0.1628, 'learning_rate': 0.00014086253369272235, 'epoch': 5.43}                                                                                                      
{'loss': 0.1705, 'learning_rate': 0.00014045822102425875, 'epoch': 5.45}                                                                                                      
{'loss': 0.1043, 'learning_rate': 0.00014005390835579513, 'epoch': 5.46}                                                                                                      
{'loss': 0.2047, 'learning_rate': 0.0001396495956873315, 'epoch': 5.47}                                                                                                       
{'loss': 0.158, 'learning_rate': 0.00013924528301886792, 'epoch': 5.49}                                                                                                       
{'loss': 0.1302, 'learning_rate': 0.0001388409703504043, 'epoch': 5.5}                                                                                                        
{'loss': 0.1329, 'learning_rate': 0.0001384366576819407, 'epoch': 5.51}                                                                                                       
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                                          | 4200/7620 [7:36:03<2:51:22,  3.01s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.29427647590637207, 'eval_wer': 0.3334663120567376, 'eval_cer': 0.08455325260564216, 'eval_runtime': 291.8332, 'eval_samples_per_second': 5.14, 'eval_steps_per_second': 0.644, 'epoch': 5.51}                                                                                                                                               
{'loss': 0.1096, 'learning_rate': 0.00013803234501347708, 'epoch': 5.52}                                                                                                      
{'loss': 0.1755, 'learning_rate': 0.00013762803234501349, 'epoch': 5.54}                                                                                                      
{'loss': 0.1906, 'learning_rate': 0.00013722371967654986, 'epoch': 5.55}                                                                                                      
{'loss': 0.1789, 'learning_rate': 0.00013681940700808624, 'epoch': 5.56}                                                                                                      
{'loss': 0.142, 'learning_rate': 0.00013641509433962262, 'epoch': 5.58}                                                                                                       
{'loss': 0.1426, 'learning_rate': 0.000136010781671159, 'epoch': 5.59}                                                                                                        
{'loss': 0.208, 'learning_rate': 0.0001356064690026954, 'epoch': 5.6}                                                                                                         
{'loss': 0.2381, 'learning_rate': 0.00013520215633423179, 'epoch': 5.62}                                                                                                      
{'loss': 0.151, 'learning_rate': 0.0001347978436657682, 'epoch': 5.63}                                                                                                        
{'loss': 0.1521, 'learning_rate': 0.00013439353099730457, 'epoch': 5.64}                                                                                                      
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                        | 4300/7620 [7:46:51<2:40:06,  2.89s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28360816836357117, 'eval_wer': 0.32992021276595745, 'eval_cer': 0.0850210164310279, 'eval_runtime': 292.7543, 'eval_samples_per_second': 5.124, 'eval_steps_per_second': 0.642, 'epoch': 5.64}                                                                                                                                              
{'loss': 0.1559, 'learning_rate': 0.00013398921832884095, 'epoch': 5.66}                                                                                                      
{'loss': 0.2104, 'learning_rate': 0.00013358490566037735, 'epoch': 5.67}                                                                                                      
{'loss': 0.1854, 'learning_rate': 0.00013318059299191373, 'epoch': 5.68}                                                                                                      
{'loss': 0.1561, 'learning_rate': 0.00013277628032345014, 'epoch': 5.7}                                                                                                       
{'loss': 0.1444, 'learning_rate': 0.00013237196765498652, 'epoch': 5.71}                                                                                                      
{'loss': 0.1282, 'learning_rate': 0.0001319676549865229, 'epoch': 5.72}                                                                                                       
{'loss': 0.1896, 'learning_rate': 0.0001315633423180593, 'epoch': 5.73}                                                                                                       
{'loss': 0.1737, 'learning_rate': 0.00013115902964959568, 'epoch': 5.75}                                                                                                      
{'loss': 0.1703, 'learning_rate': 0.00013075471698113206, 'epoch': 5.76}                                                                                                      
{'loss': 0.1536, 'learning_rate': 0.00013035040431266844, 'epoch': 5.77}                                                                                                      
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                      | 4400/7620 [7:57:41<2:41:38,  3.01s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2900178134441376, 'eval_wer': 0.33235815602836877, 'eval_cer': 0.08487607552738724, 'eval_runtime': 279.3409, 'eval_samples_per_second': 5.37, 'eval_steps_per_second': 0.673, 'epoch': 5.77}                                                                                                                                               
{'loss': 0.1054, 'learning_rate': 0.00012994609164420484, 'epoch': 5.79}                                                                                                      
{'loss': 0.1766, 'learning_rate': 0.00012954177897574122, 'epoch': 5.8}                                                                                                       
{'loss': 0.1719, 'learning_rate': 0.0001291374663072776, 'epoch': 5.81}                                                                                                       
{'loss': 0.1836, 'learning_rate': 0.000128733153638814, 'epoch': 5.83}                                                                                                        
{'loss': 0.1601, 'learning_rate': 0.0001283288409703504, 'epoch': 5.84}                                                                                                       
{'loss': 0.1462, 'learning_rate': 0.0001279245283018868, 'epoch': 5.85}                                                                                                       
{'loss': 0.1914, 'learning_rate': 0.00012752021563342317, 'epoch': 5.87}                                                                                                      
{'loss': 0.2218, 'learning_rate': 0.00012711590296495958, 'epoch': 5.88}                                                                                                      
{'loss': 0.1294, 'learning_rate': 0.00012671159029649596, 'epoch': 5.89}                                                                                                      
{'loss': 0.1724, 'learning_rate': 0.00012630727762803233, 'epoch': 5.91}                                                                                                      
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                    | 4500/7620 [8:08:12<2:30:57,  2.90s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2782055735588074, 'eval_wer': 0.33568262411347516, 'eval_cer': 0.0876958349254872, 'eval_runtime': 288.3872, 'eval_samples_per_second': 5.201, 'eval_steps_per_second': 0.652, 'epoch': 5.91}                                                                                                                                               
{'loss': 0.1242, 'learning_rate': 0.0001259029649595687, 'epoch': 5.92}                                                                                                       
{'loss': 0.1671, 'learning_rate': 0.00012549865229110512, 'epoch': 5.93}                                                                                                      
{'loss': 0.1765, 'learning_rate': 0.0001250943396226415, 'epoch': 5.94}                                                                                                       
{'loss': 0.1902, 'learning_rate': 0.00012469002695417788, 'epoch': 5.96}                                                                                                      
{'loss': 0.1664, 'learning_rate': 0.00012428571428571428, 'epoch': 5.97}                                                                                                      
{'loss': 0.1798, 'learning_rate': 0.00012388140161725066, 'epoch': 5.98}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                   | 4566/7620 [8:16:51<3:11:35,  3.76s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-4566
Configuration saved in russian_spanish_high_augmented/checkpoint-4566/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-4566/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-4566/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1896, 'learning_rate': 0.00012347708894878704, 'epoch': 6.0}                                                                                                       
{'loss': 0.1629, 'learning_rate': 0.00012307277628032345, 'epoch': 6.01}                                                                                                      
{'loss': 0.1372, 'learning_rate': 0.00012266846361185982, 'epoch': 6.02}                                                                                                      
{'loss': 0.1379, 'learning_rate': 0.00012226415094339623, 'epoch': 6.04}                                                                                                      
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 4600/7620 [8:19:18<2:51:43,  3.41s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2927648723125458, 'eval_wer': 0.33129432624113475, 'eval_cer': 0.08546901558773537, 'eval_runtime': 280.9202, 'eval_samples_per_second': 5.34, 'eval_steps_per_second': 0.669, 'epoch': 6.04}                                                                                                                                               
{'loss': 0.1401, 'learning_rate': 0.00012185983827493261, 'epoch': 6.05}                                                                                                      
{'loss': 0.139, 'learning_rate': 0.00012145552560646899, 'epoch': 6.06}                                                                                                       
{'loss': 0.1412, 'learning_rate': 0.00012105121293800538, 'epoch': 6.08}                                                                                                      
{'loss': 0.1535, 'learning_rate': 0.00012064690026954176, 'epoch': 6.09}                                                                                                      
{'loss': 0.1666, 'learning_rate': 0.00012024258760107816, 'epoch': 6.1}                                                                                                       
{'loss': 0.1502, 'learning_rate': 0.00011983827493261454, 'epoch': 6.12}                                                                                                      
{'loss': 0.1331, 'learning_rate': 0.00011943396226415094, 'epoch': 6.13}                                                                                                      
{'loss': 0.15, 'learning_rate': 0.00011902964959568731, 'epoch': 6.14}                                                                                                        
{'loss': 0.1663, 'learning_rate': 0.00011862533692722371, 'epoch': 6.15}                                                                                                      
{'loss': 0.1523, 'learning_rate': 0.0001182210242587601, 'epoch': 6.17}                                                                                                       
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                 | 4700/7620 [8:29:50<2:41:28,  3.32s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2943221926689148, 'eval_wer': 0.3228723404255319, 'eval_cer': 0.08333443137048213, 'eval_runtime': 282.8671, 'eval_samples_per_second': 5.303, 'eval_steps_per_second': 0.665, 'epoch': 6.17}                                                                                                                                               
{'loss': 0.1665, 'learning_rate': 0.00011781671159029648, 'epoch': 6.18}                                                                                                      
{'loss': 0.1014, 'learning_rate': 0.00011741239892183288, 'epoch': 6.19}                                                                                                      
{'loss': 0.1855, 'learning_rate': 0.00011700808625336926, 'epoch': 6.21}                                                                                                      
{'loss': 0.1706, 'learning_rate': 0.00011660377358490566, 'epoch': 6.22}                                                                                                      
{'loss': 0.1324, 'learning_rate': 0.00011619946091644203, 'epoch': 6.23}                                                                                                      
{'loss': 0.1361, 'learning_rate': 0.00011579514824797843, 'epoch': 6.25}                                                                                                      
{'loss': 0.1191, 'learning_rate': 0.00011539083557951482, 'epoch': 6.26}                                                                                                      
{'loss': 0.1639, 'learning_rate': 0.0001149865229110512, 'epoch': 6.27}                                                                                                       
{'loss': 0.1624, 'learning_rate': 0.0001145822102425876, 'epoch': 6.29}                                                                                                       
{'loss': 0.1763, 'learning_rate': 0.00011417789757412398, 'epoch': 6.3}                                                                                                       
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                               | 4800/7620 [8:40:22<2:37:36,  3.35s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2846299111843109, 'eval_wer': 0.32539893617021276, 'eval_cer': 0.08293254977402395, 'eval_runtime': 295.4352, 'eval_samples_per_second': 5.077, 'eval_steps_per_second': 0.636, 'epoch': 6.3}                                                                                                                                               
{'loss': 0.1356, 'learning_rate': 0.00011377358490566037, 'epoch': 6.31}                                                                                                      
{'loss': 0.1237, 'learning_rate': 0.00011336927223719675, 'epoch': 6.33}                                                                                                      
{'loss': 0.1708, 'learning_rate': 0.00011296495956873313, 'epoch': 6.34}                                                                                                      
{'loss': 0.1548, 'learning_rate': 0.00011256064690026954, 'epoch': 6.35}                                                                                                      
{'loss': 0.1432, 'learning_rate': 0.00011215633423180592, 'epoch': 6.36}                                                                                                      
{'loss': 0.1907, 'learning_rate': 0.00011175202156334231, 'epoch': 6.38}                                                                                                      
{'loss': 0.1311, 'learning_rate': 0.0001113477088948787, 'epoch': 6.39}                                                                                                       
{'loss': 0.144, 'learning_rate': 0.00011094339622641508, 'epoch': 6.4}                                                                                                        
{'loss': 0.1539, 'learning_rate': 0.00011053908355795147, 'epoch': 6.42}                                                                                                      
{'loss': 0.1304, 'learning_rate': 0.00011013477088948785, 'epoch': 6.43}                                                                                                      
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                              | 4900/7620 [8:51:25<2:33:28,  3.39s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2808619439601898, 'eval_wer': 0.3236702127659574, 'eval_cer': 0.0817466696533277, 'eval_runtime': 282.4805, 'eval_samples_per_second': 5.31, 'eval_steps_per_second': 0.666, 'epoch': 6.43}                                                                                                                                                 
{'loss': 0.1413, 'learning_rate': 0.00010973045822102426, 'epoch': 6.44}                                                                                                      
{'loss': 0.0918, 'learning_rate': 0.00010932614555256064, 'epoch': 6.46}                                                                                                      
{'loss': 0.1589, 'learning_rate': 0.00010892183288409703, 'epoch': 6.47}                                                                                                      
{'loss': 0.185, 'learning_rate': 0.00010851752021563342, 'epoch': 6.48}                                                                                                       
{'loss': 0.1491, 'learning_rate': 0.0001081132075471698, 'epoch': 6.5}                                                                                                        
{'loss': 0.1504, 'learning_rate': 0.00010770889487870619, 'epoch': 6.51}                                                                                                      
{'loss': 0.1164, 'learning_rate': 0.00010730458221024257, 'epoch': 6.52}                                                                                                      
{'loss': 0.1523, 'learning_rate': 0.00010690026954177898, 'epoch': 6.54}                                                                                                      
{'loss': 0.157, 'learning_rate': 0.00010649595687331535, 'epoch': 6.55}                                                                                                       
{'loss': 0.1202, 'learning_rate': 0.00010609164420485175, 'epoch': 6.56}                                                                                                      
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                            | 5000/7620 [9:02:05<2:29:26,  3.42s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.30097299814224243, 'eval_wer': 0.32513297872340424, 'eval_cer': 0.0817796107677915, 'eval_runtime': 293.9745, 'eval_samples_per_second': 5.102, 'eval_steps_per_second': 0.64, 'epoch': 6.56}                                                                                                                                               
{'loss': 0.1859, 'learning_rate': 0.00010568733153638813, 'epoch': 6.57}                                                                                                      
{'loss': 0.1183, 'learning_rate': 0.00010528301886792452, 'epoch': 6.59}                                                                                                      
{'loss': 0.1489, 'learning_rate': 0.00010487870619946091, 'epoch': 6.6}                                                                                                       
{'loss': 0.1637, 'learning_rate': 0.00010447439353099729, 'epoch': 6.61}                                                                                                      
{'loss': 0.1517, 'learning_rate': 0.0001040700808625337, 'epoch': 6.63}                                                                                                       
{'loss': 0.1067, 'learning_rate': 0.00010366576819407007, 'epoch': 6.64}                                                                                                      
{'loss': 0.1162, 'learning_rate': 0.00010326145552560647, 'epoch': 6.65}                                                                                                      
{'loss': 0.1787, 'learning_rate': 0.00010285714285714284, 'epoch': 6.67}                                                                                                      
{'loss': 0.1853, 'learning_rate': 0.00010245283018867924, 'epoch': 6.68}                                                                                                      
{'loss': 0.1655, 'learning_rate': 0.00010204851752021563, 'epoch': 6.69}                                                                                                      
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                          | 5100/7620 [9:13:10<2:23:16,  3.41s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28884419798851013, 'eval_wer': 0.318218085106383, 'eval_cer': 0.08116031781587235, 'eval_runtime': 281.1569, 'eval_samples_per_second': 5.335, 'eval_steps_per_second': 0.669, 'epoch': 6.69}                                                                                                                                               
{'loss': 0.1519, 'learning_rate': 0.00010164420485175201, 'epoch': 6.71}                                                                                                      
{'loss': 0.1332, 'learning_rate': 0.00010123989218328841, 'epoch': 6.72}                                                                                                      
{'loss': 0.153, 'learning_rate': 0.00010083557951482479, 'epoch': 6.73}                                                                                                       
{'loss': 0.156, 'learning_rate': 0.00010043126684636117, 'epoch': 6.75}                                                                                                       
{'loss': 0.1448, 'learning_rate': 0.00010002695417789756, 'epoch': 6.76}                                                                                                      
{'loss': 0.1261, 'learning_rate': 9.962264150943394e-05, 'epoch': 6.77}                                                                                                       
{'loss': 0.109, 'learning_rate': 9.921832884097035e-05, 'epoch': 6.78}                                                                                                        
{'loss': 0.148, 'learning_rate': 9.881401617250673e-05, 'epoch': 6.8}                                                                                                         
{'loss': 0.1523, 'learning_rate': 9.840970350404312e-05, 'epoch': 6.81}                                                                                                       
{'loss': 0.1754, 'learning_rate': 9.800539083557951e-05, 'epoch': 6.82}                                                                                                       
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                         | 5200/7620 [9:23:49<2:22:27,  3.53s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.27702832221984863, 'eval_wer': 0.3182624113475177, 'eval_cer': 0.08127231760504922, 'eval_runtime': 284.4326, 'eval_samples_per_second': 5.274, 'eval_steps_per_second': 0.661, 'epoch': 6.82}                                                                                                                                              
{'loss': 0.155, 'learning_rate': 9.760107816711589e-05, 'epoch': 6.84}                                                                                                        
{'loss': 0.1094, 'learning_rate': 9.719676549865228e-05, 'epoch': 6.85}                                                                                                       
{'loss': 0.1396, 'learning_rate': 9.679245283018866e-05, 'epoch': 6.86}                                                                                                       
{'loss': 0.1336, 'learning_rate': 9.638814016172507e-05, 'epoch': 6.88}                                                                                                       
{'loss': 0.1352, 'learning_rate': 9.598382749326145e-05, 'epoch': 6.89}                                                                                                       
{'loss': 0.1395, 'learning_rate': 9.557951482479784e-05, 'epoch': 6.9}                                                                                                        
{'loss': 0.088, 'learning_rate': 9.517520215633423e-05, 'epoch': 6.92}                                                                                                        
{'loss': 0.1596, 'learning_rate': 9.477088948787061e-05, 'epoch': 6.93}                                                                                                       
{'loss': 0.1486, 'learning_rate': 9.4366576819407e-05, 'epoch': 6.94}                                                                                                         
{'loss': 0.1463, 'learning_rate': 9.396226415094338e-05, 'epoch': 6.96}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                       | 5300/7620 [9:34:35<2:17:19,  3.55s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2981168329715729, 'eval_wer': 0.3147163120567376, 'eval_cer': 0.08137772917133332, 'eval_runtime': 280.8335, 'eval_samples_per_second': 5.341, 'eval_steps_per_second': 0.669, 'epoch': 6.96}                                                                                                                                               
{'loss': 0.1541, 'learning_rate': 9.355795148247979e-05, 'epoch': 6.97}                                                                                                       
{'loss': 0.1335, 'learning_rate': 9.315363881401616e-05, 'epoch': 6.98}                                                                                                       
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                      | 5327/7620 [9:40:36<2:21:07,  3.69s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-5327
Configuration saved in russian_spanish_high_augmented/checkpoint-5327/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-5327/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-5327/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1325, 'learning_rate': 9.274932614555256e-05, 'epoch': 6.99}                                                                                                       
{'loss': 0.1437, 'learning_rate': 9.234501347708894e-05, 'epoch': 7.01}                                                                                                       
{'loss': 0.1404, 'learning_rate': 9.194070080862533e-05, 'epoch': 7.02}                                                                                                       
{'loss': 0.1479, 'learning_rate': 9.153638814016172e-05, 'epoch': 7.03}                                                                                                       
{'loss': 0.14, 'learning_rate': 9.11320754716981e-05, 'epoch': 7.05}                                                                                                          
{'loss': 0.0705, 'learning_rate': 9.07277628032345e-05, 'epoch': 7.06}                                                                                                        
{'loss': 0.1189, 'learning_rate': 9.032345013477088e-05, 'epoch': 7.07}                                                                                                       
{'loss': 0.1343, 'learning_rate': 8.991913746630726e-05, 'epoch': 7.09}                                                                                                       
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                     | 5400/7620 [9:45:14<2:27:36,  3.99s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.29188740253448486, 'eval_wer': 0.32061170212765955, 'eval_cer': 0.08125255293637094, 'eval_runtime': 278.5523, 'eval_samples_per_second': 5.385, 'eval_steps_per_second': 0.675, 'epoch': 7.09}                                                                                                                                             
{'loss': 0.1124, 'learning_rate': 8.951482479784365e-05, 'epoch': 7.1}                                                                                                        
{'loss': 0.143, 'learning_rate': 8.911051212938005e-05, 'epoch': 7.11}                                                                                                        
{'loss': 0.1214, 'learning_rate': 8.870619946091644e-05, 'epoch': 7.13}                                                                                                       
{'loss': 0.1136, 'learning_rate': 8.830188679245282e-05, 'epoch': 7.14}                                                                                                       
{'loss': 0.1304, 'learning_rate': 8.789757412398922e-05, 'epoch': 7.15}                                                                                                       
{'loss': 0.1317, 'learning_rate': 8.74932614555256e-05, 'epoch': 7.17}                                                                                                        
{'loss': 0.1243, 'learning_rate': 8.708894878706198e-05, 'epoch': 7.18}                                                                                                       
{'loss': 0.1065, 'learning_rate': 8.668463611859837e-05, 'epoch': 7.19}                                                                                                       
{'loss': 0.1136, 'learning_rate': 8.628032345013475e-05, 'epoch': 7.2}                                                                                                        
{'loss': 0.1399, 'learning_rate': 8.587601078167116e-05, 'epoch': 7.22}                                                                                                       
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                    | 5500/7620 [9:55:46<2:24:04,  4.08s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2867865264415741, 'eval_wer': 0.3181294326241135, 'eval_cer': 0.0813513762797623, 'eval_runtime': 280.4414, 'eval_samples_per_second': 5.349, 'eval_steps_per_second': 0.67, 'epoch': 7.22}                                                                                                                                                 
{'loss': 0.1484, 'learning_rate': 8.547169811320754e-05, 'epoch': 7.23}                                                                                                       
{'loss': 0.1269, 'learning_rate': 8.506738544474393e-05, 'epoch': 7.24}                                                                                                       
{'loss': 0.1172, 'learning_rate': 8.466307277628032e-05, 'epoch': 7.26}                                                                                                       
{'loss': 0.1401, 'learning_rate': 8.42587601078167e-05, 'epoch': 7.27}                                                                                                        
{'loss': 0.1319, 'learning_rate': 8.385444743935309e-05, 'epoch': 7.28}                                                                                                       
{'loss': 0.1154, 'learning_rate': 8.345013477088947e-05, 'epoch': 7.3}                                                                                                        
{'loss': 0.1332, 'learning_rate': 8.304582210242588e-05, 'epoch': 7.31}                                                                                                       
{'loss': 0.0941, 'learning_rate': 8.264150943396226e-05, 'epoch': 7.32}                                                                                                       
{'loss': 0.1108, 'learning_rate': 8.223719676549865e-05, 'epoch': 7.34}                                                                                                       
{'loss': 0.1454, 'learning_rate': 8.183288409703504e-05, 'epoch': 7.35}                                                                                                       
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                  | 5600/7620 [10:06:26<2:21:14,  4.20s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.29421213269233704, 'eval_wer': 0.3166223404255319, 'eval_cer': 0.08139749384001159, 'eval_runtime': 280.6393, 'eval_samples_per_second': 5.345, 'eval_steps_per_second': 0.67, 'epoch': 7.35}                                                                                                                                               
{'loss': 0.1448, 'learning_rate': 8.142857142857142e-05, 'epoch': 7.36}                                                                                                       
{'loss': 0.0978, 'learning_rate': 8.102425876010781e-05, 'epoch': 7.38}                                                                                                       
{'loss': 0.1068, 'learning_rate': 8.061994609164419e-05, 'epoch': 7.39}                                                                                                       
{'loss': 0.122, 'learning_rate': 8.02156334231806e-05, 'epoch': 7.4}                                                                                                          
{'loss': 0.1254, 'learning_rate': 7.981132075471698e-05, 'epoch': 7.41}                                                                                                       
{'loss': 0.1621, 'learning_rate': 7.940700808625335e-05, 'epoch': 7.43}                                                                                                       
{'loss': 0.1421, 'learning_rate': 7.900269541778975e-05, 'epoch': 7.44}                                                                                                       
{'loss': 0.1147, 'learning_rate': 7.859838274932614e-05, 'epoch': 7.45}                                                                                                       
{'loss': 0.1311, 'learning_rate': 7.819407008086253e-05, 'epoch': 7.47}                                                                                                       
{'loss': 0.1371, 'learning_rate': 7.778975741239891e-05, 'epoch': 7.48}                                                                                                       
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                | 5700/7620 [10:17:07<2:11:07,  4.10s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2885548174381256, 'eval_wer': 0.3081560283687943, 'eval_cer': 0.07951326209268313, 'eval_runtime': 285.5748, 'eval_samples_per_second': 5.253, 'eval_steps_per_second': 0.658, 'epoch': 7.48}                                                                                                                                               
{'loss': 0.1383, 'learning_rate': 7.738544474393532e-05, 'epoch': 7.49}                                                                                                       
{'loss': 0.1195, 'learning_rate': 7.69811320754717e-05, 'epoch': 7.51}                                                                                                        
{'loss': 0.1305, 'learning_rate': 7.657681940700807e-05, 'epoch': 7.52}                                                                                                       
{'loss': 0.1188, 'learning_rate': 7.617250673854447e-05, 'epoch': 7.53}                                                                                                       
{'loss': 0.1204, 'learning_rate': 7.576819407008086e-05, 'epoch': 7.55}                                                                                                       
{'loss': 0.1621, 'learning_rate': 7.536388140161725e-05, 'epoch': 7.56}                                                                                                       
{'loss': 0.1368, 'learning_rate': 7.495956873315363e-05, 'epoch': 7.57}                                                                                                       
{'loss': 0.1051, 'learning_rate': 7.455525606469002e-05, 'epoch': 7.59}                                                                                                       
{'loss': 0.126, 'learning_rate': 7.415094339622641e-05, 'epoch': 7.6}                                                                                                         
{'loss': 0.1593, 'learning_rate': 7.374663072776279e-05, 'epoch': 7.61}                                                                                                       
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                              | 5800/7620 [10:28:16<1:59:41,  3.95s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2807561159133911, 'eval_wer': 0.30979609929078017, 'eval_cer': 0.07915090983358149, 'eval_runtime': 283.095, 'eval_samples_per_second': 5.299, 'eval_steps_per_second': 0.664, 'epoch': 7.61}                                                                                                                                               
{'loss': 0.1158, 'learning_rate': 7.334231805929918e-05, 'epoch': 7.62}                                                                                                       
{'loss': 0.1108, 'learning_rate': 7.293800539083558e-05, 'epoch': 7.64}                                                                                                       
{'loss': 0.1216, 'learning_rate': 7.253369272237196e-05, 'epoch': 7.65}                                                                                                       
{'loss': 0.1025, 'learning_rate': 7.212938005390835e-05, 'epoch': 7.66}                                                                                                       
{'loss': 0.1318, 'learning_rate': 7.172506738544474e-05, 'epoch': 7.68}                                                                                                       
{'loss': 0.1231, 'learning_rate': 7.132075471698113e-05, 'epoch': 7.69}                                                                                                       
{'loss': 0.1312, 'learning_rate': 7.091644204851751e-05, 'epoch': 7.7}                                                                                                        
{'loss': 0.0996, 'learning_rate': 7.05121293800539e-05, 'epoch': 7.72}                                                                                                        
{'loss': 0.1319, 'learning_rate': 7.010781671159028e-05, 'epoch': 7.73}                                                                                                       
{'loss': 0.1436, 'learning_rate': 6.970350404312667e-05, 'epoch': 7.74}                                                                                                       
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 5900/7620 [10:38:57<2:02:06,  4.26s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.275015264749527, 'eval_wer': 0.3100177304964539, 'eval_cer': 0.07903891004440462, 'eval_runtime': 282.0703, 'eval_samples_per_second': 5.318, 'eval_steps_per_second': 0.667, 'epoch': 7.74}                                                                                                                                                
{'loss': 0.1229, 'learning_rate': 6.929919137466307e-05, 'epoch': 7.76}                                                                                                       
{'loss': 0.1352, 'learning_rate': 6.889487870619946e-05, 'epoch': 7.77}                                                                                                       
{'loss': 0.1011, 'learning_rate': 6.849056603773585e-05, 'epoch': 7.78}                                                                                                       
{'loss': 0.1248, 'learning_rate': 6.808625336927223e-05, 'epoch': 7.8}                                                                                                        
{'loss': 0.1195, 'learning_rate': 6.768194070080862e-05, 'epoch': 7.81}                                                                                                       
{'loss': 0.1595, 'learning_rate': 6.7277628032345e-05, 'epoch': 7.82}                                                                                                         
{'loss': 0.1326, 'learning_rate': 6.68733153638814e-05, 'epoch': 7.83}                                                                                                        
{'loss': 0.0722, 'learning_rate': 6.646900269541779e-05, 'epoch': 7.85}                                                                                                       
{'loss': 0.1081, 'learning_rate': 6.606469002695418e-05, 'epoch': 7.86}                                                                                                       
{'loss': 0.1337, 'learning_rate': 6.566037735849056e-05, 'epoch': 7.87}                                                                                                       
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 6000/7620 [10:49:44<1:54:32,  4.24s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2799704670906067, 'eval_wer': 0.3076684397163121, 'eval_cer': 0.07796502971288524, 'eval_runtime': 288.1867, 'eval_samples_per_second': 5.205, 'eval_steps_per_second': 0.652, 'epoch': 7.87}                                                                                                                                               
{'loss': 0.1243, 'learning_rate': 6.525606469002695e-05, 'epoch': 7.89}                                                                                                       
{'loss': 0.1135, 'learning_rate': 6.485175202156333e-05, 'epoch': 7.9}                                                                                                        
{'loss': 0.0828, 'learning_rate': 6.444743935309972e-05, 'epoch': 7.91}                                                                                                       
{'loss': 0.1021, 'learning_rate': 6.404312668463611e-05, 'epoch': 7.93}                                                                                                       
{'loss': 0.1512, 'learning_rate': 6.36388140161725e-05, 'epoch': 7.94}                                                                                                        
{'loss': 0.1042, 'learning_rate': 6.32345013477089e-05, 'epoch': 7.95}                                                                                                        
{'loss': 0.1276, 'learning_rate': 6.283018867924528e-05, 'epoch': 7.97}                                                                                                       
{'loss': 0.1025, 'learning_rate': 6.242587601078167e-05, 'epoch': 7.98}                                                                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                         | 6088/7620 [10:59:36<1:42:11,  4.00s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-6088
Configuration saved in russian_spanish_high_augmented/checkpoint-6088/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-6088/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-6088/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1184, 'learning_rate': 6.202156334231805e-05, 'epoch': 7.99}                                                                                                       
{'loss': 0.1152, 'learning_rate': 6.161725067385444e-05, 'epoch': 8.01}                                                                                                       
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                         | 6100/7620 [11:00:36<1:59:42,  4.73s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.27959027886390686, 'eval_wer': 0.3069148936170213, 'eval_cer': 0.07950667386979036, 'eval_runtime': 283.5393, 'eval_samples_per_second': 5.29, 'eval_steps_per_second': 0.663, 'epoch': 8.01}                                                                                                                                               
{'loss': 0.0898, 'learning_rate': 6.121293800539083e-05, 'epoch': 8.02}                                                                                                       
{'loss': 0.1323, 'learning_rate': 6.080862533692722e-05, 'epoch': 8.03}                                                                                                       
{'loss': 0.148, 'learning_rate': 6.040431266846361e-05, 'epoch': 8.04}                                                                                                        
{'loss': 0.135, 'learning_rate': 5.9999999999999995e-05, 'epoch': 8.06}                                                                                                       
{'loss': 0.12, 'learning_rate': 5.959568733153638e-05, 'epoch': 8.07}                                                                                                         
{'loss': 0.1646, 'learning_rate': 5.9191374663072766e-05, 'epoch': 8.08}                                                                                                      
{'loss': 0.1073, 'learning_rate': 5.878706199460916e-05, 'epoch': 8.1}                                                                                                        
{'loss': 0.1108, 'learning_rate': 5.838274932614555e-05, 'epoch': 8.11}                                                                                                       
{'loss': 0.1045, 'learning_rate': 5.7978436657681936e-05, 'epoch': 8.12}                                                                                                      
{'loss': 0.1065, 'learning_rate': 5.757412398921833e-05, 'epoch': 8.14}                                                                                                       
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 6200/7620 [11:11:16<1:48:04,  4.57s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28750845789909363, 'eval_wer': 0.30806737588652483, 'eval_cer': 0.07913114516490322, 'eval_runtime': 289.6921, 'eval_samples_per_second': 5.178, 'eval_steps_per_second': 0.649, 'epoch': 8.14}                                                                                                                                             
{'loss': 0.123, 'learning_rate': 5.7169811320754714e-05, 'epoch': 8.15}                                                                                                       
{'loss': 0.1012, 'learning_rate': 5.67654986522911e-05, 'epoch': 8.16}                                                                                                        
{'loss': 0.0975, 'learning_rate': 5.6361185983827485e-05, 'epoch': 8.18}                                                                                                      
{'loss': 0.0835, 'learning_rate': 5.595687331536388e-05, 'epoch': 8.19}                                                                                                       
{'loss': 0.0825, 'learning_rate': 5.555256064690026e-05, 'epoch': 8.2}                                                                                                        
{'loss': 0.109, 'learning_rate': 5.5148247978436655e-05, 'epoch': 8.22}                                                                                                       
{'loss': 0.1438, 'learning_rate': 5.474393530997305e-05, 'epoch': 8.23}                                                                                                       
{'loss': 0.1178, 'learning_rate': 5.4339622641509426e-05, 'epoch': 8.24}                                                                                                      
{'loss': 0.1121, 'learning_rate': 5.393530997304581e-05, 'epoch': 8.25}                                                                                                       
{'loss': 0.1061, 'learning_rate': 5.3530997304582204e-05, 'epoch': 8.27}                                                                                                      
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 6300/7620 [11:22:26<1:45:39,  4.80s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.292845755815506, 'eval_wer': 0.3010195035460993, 'eval_cer': 0.077727853688746, 'eval_runtime': 286.0159, 'eval_samples_per_second': 5.244, 'eval_steps_per_second': 0.657, 'epoch': 8.27}                                                                                                                                                  
{'loss': 0.1181, 'learning_rate': 5.3126684636118596e-05, 'epoch': 8.28}                                                                                                      
{'loss': 0.1189, 'learning_rate': 5.272237196765498e-05, 'epoch': 8.29}                                                                                                       
{'loss': 0.107, 'learning_rate': 5.2318059299191374e-05, 'epoch': 8.31}                                                                                                       
{'loss': 0.0978, 'learning_rate': 5.191374663072776e-05, 'epoch': 8.32}                                                                                                       
{'loss': 0.0782, 'learning_rate': 5.1509433962264145e-05, 'epoch': 8.33}                                                                                                      
{'loss': 0.1286, 'learning_rate': 5.110512129380053e-05, 'epoch': 8.35}                                                                                                       
{'loss': 0.1213, 'learning_rate': 5.070080862533692e-05, 'epoch': 8.36}                                                                                                       
{'loss': 0.1074, 'learning_rate': 5.029649595687331e-05, 'epoch': 8.37}                                                                                                       
{'loss': 0.0866, 'learning_rate': 4.98921832884097e-05, 'epoch': 8.39}                                                                                                        
{'loss': 0.0847, 'learning_rate': 4.948787061994609e-05, 'epoch': 8.4}                                                                                                        
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 6400/7620 [11:33:19<1:34:37,  4.65s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2949327528476715, 'eval_wer': 0.29902482269503544, 'eval_cer': 0.07735891320675162, 'eval_runtime': 293.0774, 'eval_samples_per_second': 5.118, 'eval_steps_per_second': 0.641, 'epoch': 8.4}                                                                                                                                               
{'loss': 0.1364, 'learning_rate': 4.908355795148247e-05, 'epoch': 8.41}                                                                                                       
{'loss': 0.0841, 'learning_rate': 4.8679245283018864e-05, 'epoch': 8.43}                                                                                                      
{'loss': 0.1117, 'learning_rate': 4.827493261455525e-05, 'epoch': 8.44}                                                                                                       
{'loss': 0.091, 'learning_rate': 4.787061994609164e-05, 'epoch': 8.45}                                                                                                        
{'loss': 0.1006, 'learning_rate': 4.746630727762803e-05, 'epoch': 8.46}                                                                                                       
{'loss': 0.1229, 'learning_rate': 4.706199460916442e-05, 'epoch': 8.48}                                                                                                       
{'loss': 0.1264, 'learning_rate': 4.6657681940700805e-05, 'epoch': 8.49}                                                                                                      
{'loss': 0.1238, 'learning_rate': 4.625336927223719e-05, 'epoch': 8.5}                                                                                                        
{'loss': 0.0833, 'learning_rate': 4.5849056603773576e-05, 'epoch': 8.52}                                                                                                      
{'loss': 0.1174, 'learning_rate': 4.544474393530997e-05, 'epoch': 8.53}                                                                                                       
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 6500/7620 [11:44:14<1:24:59,  4.55s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2842233180999756, 'eval_wer': 0.30031028368794327, 'eval_cer': 0.07847232287562753, 'eval_runtime': 296.6233, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 0.634, 'epoch': 8.53}                                                                                                                                              
{'loss': 0.1209, 'learning_rate': 4.504043126684636e-05, 'epoch': 8.54}                                                                                                       
{'loss': 0.1059, 'learning_rate': 4.4636118598382746e-05, 'epoch': 8.56}                                                                                                      
{'loss': 0.0888, 'learning_rate': 4.423180592991914e-05, 'epoch': 8.57}                                                                                                       
{'loss': 0.0936, 'learning_rate': 4.382749326145552e-05, 'epoch': 8.58}                                                                                                       
{'loss': 0.1004, 'learning_rate': 4.342318059299191e-05, 'epoch': 8.6}                                                                                                        
{'loss': 0.1094, 'learning_rate': 4.3018867924528295e-05, 'epoch': 8.61}                                                                                                      
{'loss': 0.1325, 'learning_rate': 4.261455525606469e-05, 'epoch': 8.62}                                                                                                       
{'loss': 0.1418, 'learning_rate': 4.221024258760107e-05, 'epoch': 8.64}                                                                                                       
{'loss': 0.0855, 'learning_rate': 4.1805929919137465e-05, 'epoch': 8.65}                                                                                                      
{'loss': 0.0887, 'learning_rate': 4.140161725067386e-05, 'epoch': 8.66}                                                                                                       
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                 | 6600/7620 [11:55:48<1:13:56,  4.35s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2893046736717224, 'eval_wer': 0.3022163120567376, 'eval_cer': 0.07844596998405651, 'eval_runtime': 293.8053, 'eval_samples_per_second': 5.105, 'eval_steps_per_second': 0.64, 'epoch': 8.66}                                                                                                                                                
{'loss': 0.1337, 'learning_rate': 4.0997304582210236e-05, 'epoch': 8.67}                                                                                                      
{'loss': 0.0872, 'learning_rate': 4.059299191374662e-05, 'epoch': 8.69}                                                                                                       
{'loss': 0.1065, 'learning_rate': 4.0188679245283014e-05, 'epoch': 8.7}                                                                                                       
{'loss': 0.0997, 'learning_rate': 3.978436657681941e-05, 'epoch': 8.71}                                                                                                       
{'loss': 0.1149, 'learning_rate': 3.938005390835579e-05, 'epoch': 8.73}                                                                                                       
{'loss': 0.1254, 'learning_rate': 3.8975741239892184e-05, 'epoch': 8.74}                                                                                                      
{'loss': 0.1543, 'learning_rate': 3.857142857142856e-05, 'epoch': 8.75}                                                                                                       
{'loss': 0.1055, 'learning_rate': 3.8167115902964956e-05, 'epoch': 8.77}                                                                                                      
{'loss': 0.0949, 'learning_rate': 3.776280323450134e-05, 'epoch': 8.78}                                                                                                       
{'loss': 0.0964, 'learning_rate': 3.735849056603773e-05, 'epoch': 8.79}                                                                                                       
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ               | 6700/7620 [12:06:58<1:12:51,  4.75s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28205406665802, 'eval_wer': 0.2995124113475177, 'eval_cer': 0.07758291278510535, 'eval_runtime': 311.0088, 'eval_samples_per_second': 4.823, 'eval_steps_per_second': 0.604, 'epoch': 8.79}                                                                                                                                                 
{'loss': 0.1169, 'learning_rate': 3.695417789757412e-05, 'epoch': 8.81}                                                                                                       
{'loss': 0.0868, 'learning_rate': 3.6549865229110504e-05, 'epoch': 8.82}                                                                                                      
{'loss': 0.0971, 'learning_rate': 3.61455525606469e-05, 'epoch': 8.83}                                                                                                        
{'loss': 0.1007, 'learning_rate': 3.574123989218329e-05, 'epoch': 8.85}                                                                                                       
{'loss': 0.0995, 'learning_rate': 3.5336927223719675e-05, 'epoch': 8.86}                                                                                                      
{'loss': 0.1123, 'learning_rate': 3.493261455525606e-05, 'epoch': 8.87}                                                                                                       
{'loss': 0.1293, 'learning_rate': 3.452830188679245e-05, 'epoch': 8.88}                                                                                                       
{'loss': 0.0925, 'learning_rate': 3.412398921832884e-05, 'epoch': 8.9}                                                                                                        
{'loss': 0.0972, 'learning_rate': 3.3719676549865223e-05, 'epoch': 8.91}                                                                                                      
{'loss': 0.0824, 'learning_rate': 3.3315363881401616e-05, 'epoch': 8.92}                                                                                                      
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 6800/7620 [12:18:19<1:05:36,  4.80s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2862670421600342, 'eval_wer': 0.29942375886524825, 'eval_cer': 0.07753679522485604, 'eval_runtime': 315.1802, 'eval_samples_per_second': 4.759, 'eval_steps_per_second': 0.596, 'epoch': 8.92}                                                                                                                                              
{'loss': 0.1194, 'learning_rate': 3.2911051212938e-05, 'epoch': 8.94}                                                                                                         
{'loss': 0.111, 'learning_rate': 3.250673854447439e-05, 'epoch': 8.95}                                                                                                        
{'loss': 0.1047, 'learning_rate': 3.210242587601078e-05, 'epoch': 8.96}                                                                                                       
{'loss': 0.0726, 'learning_rate': 3.169811320754717e-05, 'epoch': 8.98}                                                                                                       
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 6849/7620 [12:26:23<51:13,  3.99s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-6849
Configuration saved in russian_spanish_high_augmented/checkpoint-6849/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-6849/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-6849/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1127, 'learning_rate': 3.129380053908356e-05, 'epoch': 8.99}                                                                                                       
{'loss': 0.1019, 'learning_rate': 3.088948787061994e-05, 'epoch': 9.0}                                                                                                        
{'loss': 0.0923, 'learning_rate': 3.048517520215633e-05, 'epoch': 9.02}                                                                                                       
{'loss': 0.1108, 'learning_rate': 3.0080862533692717e-05, 'epoch': 9.03}                                                                                                      
{'loss': 0.0907, 'learning_rate': 2.9676549865229106e-05, 'epoch': 9.04}                                                                                                      
{'loss': 0.0921, 'learning_rate': 2.9272237196765498e-05, 'epoch': 9.06}                                                                                                      
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 6900/7620 [12:29:47<33:47,  2.82s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28098800778388977, 'eval_wer': 0.29902482269503544, 'eval_cer': 0.07714809007418338, 'eval_runtime': 312.9424, 'eval_samples_per_second': 4.793, 'eval_steps_per_second': 0.601, 'epoch': 9.06}                                                                                                                                             
{'loss': 0.0856, 'learning_rate': 2.8867924528301887e-05, 'epoch': 9.07}                                                                                                      
{'loss': 0.0967, 'learning_rate': 2.8463611859838273e-05, 'epoch': 9.08}                                                                                                      
{'loss': 0.1018, 'learning_rate': 2.805929919137466e-05, 'epoch': 9.09}                                                                                                       
{'loss': 0.1433, 'learning_rate': 2.765498652291105e-05, 'epoch': 9.11}                                                                                                       
{'loss': 0.1036, 'learning_rate': 2.7250673854447436e-05, 'epoch': 9.12}                                                                                                      
{'loss': 0.0865, 'learning_rate': 2.6846361185983825e-05, 'epoch': 9.13}                                                                                                      
{'loss': 0.1147, 'learning_rate': 2.6442048517520214e-05, 'epoch': 9.15}                                                                                                      
{'loss': 0.0895, 'learning_rate': 2.60377358490566e-05, 'epoch': 9.16}                                                                                                        
{'loss': 0.0687, 'learning_rate': 2.5633423180592988e-05, 'epoch': 9.17}                                                                                                      
{'loss': 0.0752, 'learning_rate': 2.522911051212938e-05, 'epoch': 9.19}                                                                                                       
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 7000/7620 [12:41:19<30:48,  2.98s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28934481739997864, 'eval_wer': 0.2961879432624113, 'eval_cer': 0.0768713847126876, 'eval_runtime': 307.4201, 'eval_samples_per_second': 4.879, 'eval_steps_per_second': 0.612, 'epoch': 9.19}                                                                                                                                               
{'loss': 0.0942, 'learning_rate': 2.4824797843665763e-05, 'epoch': 9.2}                                                                                                       
{'loss': 0.1066, 'learning_rate': 2.4420485175202155e-05, 'epoch': 9.21}                                                                                                      
{'loss': 0.0997, 'learning_rate': 2.4016172506738544e-05, 'epoch': 9.23}                                                                                                      
{'loss': 0.1077, 'learning_rate': 2.3611859838274933e-05, 'epoch': 9.24}                                                                                                      
{'loss': 0.092, 'learning_rate': 2.3207547169811318e-05, 'epoch': 9.25}                                                                                                       
{'loss': 0.086, 'learning_rate': 2.2803234501347707e-05, 'epoch': 9.27}                                                                                                       
{'loss': 0.0909, 'learning_rate': 2.2398921832884096e-05, 'epoch': 9.28}                                                                                                      
{'loss': 0.0911, 'learning_rate': 2.199460916442048e-05, 'epoch': 9.29}                                                                                                       
{'loss': 0.1376, 'learning_rate': 2.159029649595687e-05, 'epoch': 9.3}                                                                                                        
{'loss': 0.0946, 'learning_rate': 2.118598382749326e-05, 'epoch': 9.32}                                                                                                       
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 7100/7620 [12:52:45<26:30,  3.06s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2859542667865753, 'eval_wer': 0.2957890070921986, 'eval_cer': 0.07663420868854835, 'eval_runtime': 302.7353, 'eval_samples_per_second': 4.955, 'eval_steps_per_second': 0.621, 'epoch': 9.32}                                                                                                                                               
{'loss': 0.1085, 'learning_rate': 2.0781671159029645e-05, 'epoch': 9.33}                                                                                                      
{'loss': 0.1398, 'learning_rate': 2.0377358490566034e-05, 'epoch': 9.34}                                                                                                      
{'loss': 0.0763, 'learning_rate': 1.9973045822102426e-05, 'epoch': 9.36}                                                                                                      
{'loss': 0.095, 'learning_rate': 1.9568733153638812e-05, 'epoch': 9.37}                                                                                                       
{'loss': 0.0768, 'learning_rate': 1.91644204851752e-05, 'epoch': 9.38}                                                                                                        
{'loss': 0.0922, 'learning_rate': 1.876010781671159e-05, 'epoch': 9.4}                                                                                                        
{'loss': 0.1014, 'learning_rate': 1.8355795148247975e-05, 'epoch': 9.41}                                                                                                      
{'loss': 0.1047, 'learning_rate': 1.7951482479784364e-05, 'epoch': 9.42}                                                                                                      
{'loss': 0.1008, 'learning_rate': 1.7547169811320753e-05, 'epoch': 9.44}                                                                                                      
{'loss': 0.122, 'learning_rate': 1.7142857142857142e-05, 'epoch': 9.45}                                                                                                       
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 7200/7620 [13:03:59<20:31,  2.93s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28522422909736633, 'eval_wer': 0.29609929078014185, 'eval_cer': 0.07663420868854835, 'eval_runtime': 298.2754, 'eval_samples_per_second': 5.029, 'eval_steps_per_second': 0.63, 'epoch': 9.45}                                                                                                                                              
{'loss': 0.0772, 'learning_rate': 1.673854447439353e-05, 'epoch': 9.46}                                                                                                       
{'loss': 0.1111, 'learning_rate': 1.6334231805929916e-05, 'epoch': 9.48}                                                                                                      
{'loss': 0.1394, 'learning_rate': 1.5929919137466305e-05, 'epoch': 9.49}                                                                                                      
{'loss': 0.0966, 'learning_rate': 1.5525606469002694e-05, 'epoch': 9.5}                                                                                                       
{'loss': 0.0789, 'learning_rate': 1.5121293800539081e-05, 'epoch': 9.51}                                                                                                      
{'loss': 0.0738, 'learning_rate': 1.4716981132075472e-05, 'epoch': 9.53}                                                                                                      
{'loss': 0.1134, 'learning_rate': 1.431266846361186e-05, 'epoch': 9.54}                                                                                                       
{'loss': 0.1153, 'learning_rate': 1.3908355795148246e-05, 'epoch': 9.55}                                                                                                      
{'loss': 0.101, 'learning_rate': 1.3504043126684635e-05, 'epoch': 9.57}                                                                                                       
{'loss': 0.0616, 'learning_rate': 1.3099730458221023e-05, 'epoch': 9.58}                                                                                                      
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 7300/7620 [13:14:58<15:00,  2.81s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2891506254673004, 'eval_wer': 0.29326241134751774, 'eval_cer': 0.07612032730291331, 'eval_runtime': 311.1038, 'eval_samples_per_second': 4.822, 'eval_steps_per_second': 0.604, 'epoch': 9.58}                                                                                                                                              
{'loss': 0.087, 'learning_rate': 1.269541778975741e-05, 'epoch': 9.59}                                                                                                        
{'loss': 0.099, 'learning_rate': 1.22911051212938e-05, 'epoch': 9.61}                                                                                                         
{'loss': 0.1153, 'learning_rate': 1.1886792452830188e-05, 'epoch': 9.62}                                                                                                      
{'loss': 0.0966, 'learning_rate': 1.1482479784366576e-05, 'epoch': 9.63}                                                                                                      
{'loss': 0.1039, 'learning_rate': 1.1078167115902964e-05, 'epoch': 9.65}                                                                                                      
{'loss': 0.0856, 'learning_rate': 1.0673854447439351e-05, 'epoch': 9.66}                                                                                                      
{'loss': 0.0989, 'learning_rate': 1.0269541778975742e-05, 'epoch': 9.67}                                                                                                      
{'loss': 0.121, 'learning_rate': 9.865229110512129e-06, 'epoch': 9.69}                                                                                                        
{'loss': 0.1038, 'learning_rate': 9.460916442048518e-06, 'epoch': 9.7}                                                                                                        
{'loss': 0.0755, 'learning_rate': 9.056603773584905e-06, 'epoch': 9.71}                                                                                                       
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 7400/7620 [13:26:22<10:35,  2.89s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2825474739074707, 'eval_wer': 0.29490248226950355, 'eval_cer': 0.07643656200176564, 'eval_runtime': 323.1789, 'eval_samples_per_second': 4.641, 'eval_steps_per_second': 0.582, 'epoch': 9.71}                                                                                                                                              
{'loss': 0.1049, 'learning_rate': 8.652291105121294e-06, 'epoch': 9.72}                                                                                                       
{'loss': 0.1189, 'learning_rate': 8.247978436657681e-06, 'epoch': 9.74}                                                                                                       
{'loss': 0.1206, 'learning_rate': 7.84366576819407e-06, 'epoch': 9.75}                                                                                                        
{'loss': 0.1014, 'learning_rate': 7.439353099730457e-06, 'epoch': 9.76}                                                                                                       
{'loss': 0.0951, 'learning_rate': 7.035040431266846e-06, 'epoch': 9.78}                                                                                                       
{'loss': 0.0951, 'learning_rate': 6.630727762803234e-06, 'epoch': 9.79}                                                                                                       
{'loss': 0.128, 'learning_rate': 6.226415094339621e-06, 'epoch': 9.8}                                                                                                         
{'loss': 0.0987, 'learning_rate': 5.82210242587601e-06, 'epoch': 9.82}                                                                                                        
{'loss': 0.1267, 'learning_rate': 5.417789757412398e-06, 'epoch': 9.83}                                                                                                       
{'loss': 0.0743, 'learning_rate': 5.013477088948787e-06, 'epoch': 9.84}                                                                                                       
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 7500/7620 [13:38:16<06:02,  3.02s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.2812856137752533, 'eval_wer': 0.29521276595744683, 'eval_cer': 0.07659467935119181, 'eval_runtime': 343.5782, 'eval_samples_per_second': 4.366, 'eval_steps_per_second': 0.547, 'epoch': 9.84}                                                                                                                                              
{'loss': 0.091, 'learning_rate': 4.6091644204851745e-06, 'epoch': 9.86}                                                                                                       
{'loss': 0.1335, 'learning_rate': 4.2048517520215626e-06, 'epoch': 9.87}                                                                                                      
{'loss': 0.0872, 'learning_rate': 3.800539083557951e-06, 'epoch': 9.88}                                                                                                       
{'loss': 0.0943, 'learning_rate': 3.396226415094339e-06, 'epoch': 9.9}                                                                                                        
{'loss': 0.0914, 'learning_rate': 2.9919137466307276e-06, 'epoch': 9.91}                                                                                                      
{'loss': 0.0738, 'learning_rate': 2.587601078167116e-06, 'epoch': 9.92}                                                                                                       
{'loss': 0.116, 'learning_rate': 2.1832884097035038e-06, 'epoch': 9.93}                                                                                                       
{'loss': 0.0961, 'learning_rate': 1.778975741239892e-06, 'epoch': 9.95}                                                                                                       
{'loss': 0.1003, 'learning_rate': 1.37466307277628e-06, 'epoch': 9.96}                                                                                                        
{'loss': 0.0997, 'learning_rate': 9.703504043126684e-07, 'epoch': 9.97}                                                                                                       
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 7600/7620 [13:50:42<01:04,  3.20s/it]***** Running Evaluation *****
  Num examples = 1500
  Batch size = 8
{'eval_loss': 0.28061679005622864, 'eval_wer': 0.2949468085106383, 'eval_cer': 0.07652220889937149, 'eval_runtime': 329.089, 'eval_samples_per_second': 4.558, 'eval_steps_per_second': 0.571, 'epoch': 9.97}                                                                                                                                               
{'loss': 0.075, 'learning_rate': 5.660377358490566e-07, 'epoch': 9.99}                                                                                                        
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 7610/7620 [13:56:44<01:22,  8.25s/it]Saving model checkpoint to russian_spanish_high_augmented/checkpoint-7610
Configuration saved in russian_spanish_high_augmented/checkpoint-7610/config.json
Model weights saved in russian_spanish_high_augmented/checkpoint-7610/pytorch_model.bin
Feature extractor saved in russian_spanish_high_augmented/checkpoint-7610/preprocessor_config.json
/home/or/anaconda3/lib/python3.9/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
{'loss': 0.1053, 'learning_rate': 1.6172506738544476e-07, 'epoch': 10.0}                                                                                                      
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [13:57:34<00:00,  3.37s/it]

Training completed. Do not forget to share your model on huggingface.co/models =)


{'train_runtime': 50254.7302, 'train_samples_per_second': 2.425, 'train_steps_per_second': 0.152, 'train_loss': 0.6259916162396979, 'epoch': 10.0}                            
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7620/7620 [13:57:34<00:00,  6.60s/it]
----------------- Training complete. -----------------


(base) or@anidjar:~/Desktop/language-and-speaker-change-detection-based-on-automatic-speech-recognition-methods-$ 


